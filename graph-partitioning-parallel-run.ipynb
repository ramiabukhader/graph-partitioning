{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import platform\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from graph_partitioning import GraphPartitioning, utils\n",
    "\n",
    "algorithms = [\"FENNEL\", \"SCOTCH\", \"PATOH\"]\n",
    "\n",
    "cols = [\"WASTE\", \"CUT RATIO\", \"EDGES CUT\", \"TOTAL COMM VOLUME\", \"MODULARITY\", \"LONELINESS\", \"NETWORK PERMANENCE\", \"NORM. MUTUAL INFO\"]\n",
    "pwd = %pwd\n",
    "\n",
    "run_metrics = True\n",
    "dumpAssignments = True\n",
    "\n",
    "# TODO: copy PaToH & SCOTCH settings to FENNEL script\n",
    "\n",
    "config = {\n",
    "\n",
    "    \"DATA_FILENAME\": os.path.join(pwd, \"data\", \"predition_model_tests\", \"network\", \"network_1.txt\"),\n",
    "    \"OUTPUT_DIRECTORY\": os.path.join(pwd, \"output\"),\n",
    "\n",
    "    # Set which algorithm is run for the PREDICTION MODEL.\n",
    "    # Either: 'FENNEL' or 'SCOTCH'\n",
    "    \"PREDICTION_MODEL_ALGORITHM\": \"\",\n",
    "\n",
    "    # Alternativly, read input file for prediction model.\n",
    "    # Set to empty to generate prediction model using algorithm value above.\n",
    "    \"PREDICTION_MODEL\": \"\",\n",
    "\n",
    "    \n",
    "    \"PARTITIONER_ALGORITHM\": \"\",\n",
    "\n",
    "    # File containing simulated arrivals. This is used in simulating nodes\n",
    "    # arriving at the shelter. Nodes represented by line number; value of\n",
    "    # 1 represents a node as arrived; value of 0 represents the node as not\n",
    "    # arrived or needing a shelter.\n",
    "    \"SIMULATED_ARRIVAL_FILE\": os.path.join(pwd,\n",
    "                                           \"data\",\n",
    "                                           \"predition_model_tests\",\n",
    "                                           \"dataset_1_shift_rotate\",\n",
    "                                           \"simulated_arrival_list\",\n",
    "                                           \"percentage_of_prediction_correct_90\",\n",
    "                                           \"arrival_90_1.txt\"\n",
    "                                          ),\n",
    "    \n",
    "    # File containing the prediction of a node arriving. This is different to the\n",
    "    # simulated arrivals, the values in this file are known before the disaster.\n",
    "    \"PREDICTION_LIST_FILE\": os.path.join(pwd,\n",
    "                                         \"data\",\n",
    "                                         \"predition_model_tests\",\n",
    "                                         \"dataset_1_shift_rotate\",\n",
    "                                         \"prediction_list\",\n",
    "                                         \"prediction_1_norm.txt\"\n",
    "                                        ),\n",
    "\n",
    "    # File containing the geographic location of each node, in \"x,y\" format.\n",
    "    \"POPULATION_LOCATION_FILE\": os.path.join(pwd,\n",
    "                                             \"data\",\n",
    "                                             \"predition_model_tests\",\n",
    "                                             \"coordinates\",\n",
    "                                             \"coordinates_1.txt\"\n",
    "                                            ),\n",
    "\n",
    "    # Number of shelters\n",
    "    \"num_partitions\": 6,\n",
    "\n",
    "    # The number of iterations when making prediction model\n",
    "    \"num_iterations\": 1,\n",
    "\n",
    "    # Percentage of prediction model to use before discarding\n",
    "    # When set to 0, prediction model is discarded, useful for one-shot\n",
    "    \"prediction_model_cut_off\": 0.10,\n",
    "\n",
    "    # Alpha value used in one-shot (when restream_batches set to 1)\n",
    "    \"one_shot_alpha\": 0.5,\n",
    "\n",
    "    # Number of arrivals to batch before recalculating alpha and restreaming.\n",
    "    # When set to 1, one-shot is used with alpha value from above\n",
    "    \"restream_batches\": 10,\n",
    "\n",
    "    # When the batch size is reached: if set to True, each node is assigned\n",
    "    # individually as first in first out. If set to False, the entire batch\n",
    "    # is processed and empty before working on the next batch.\n",
    "    \"sliding_window\": False,\n",
    "\n",
    "    # Create virtual nodes based on prediction model\n",
    "    \"use_virtual_nodes\": False,\n",
    "\n",
    "    # Virtual nodes: edge weight\n",
    "    \"virtual_edge_weight\": 1.0,\n",
    "\n",
    "    # Loneliness score parameter. Used when scoring a partition by how many\n",
    "    # lonely nodes exist.\n",
    "    \"loneliness_score_param\": 1.2,\n",
    "\n",
    "    ####\n",
    "    # GRAPH MODIFICATION FUNCTIONS\n",
    "\n",
    "    # Also enables the edge calculation function.\n",
    "    \"graph_modification_functions\": False,\n",
    "\n",
    "    # If set, the node weight is set to 100 if the node arrives at the shelter,\n",
    "    # otherwise the node is removed from the graph.\n",
    "    \"alter_arrived_node_weight_to_100\": True,\n",
    "\n",
    "    # Uses generalized additive models from R to generate prediction of nodes not\n",
    "    # arrived. This sets the node weight on unarrived nodes the the prediction\n",
    "    # given by a GAM.\n",
    "    # Needs POPULATION_LOCATION_FILE to be set.\n",
    "    \"alter_node_weight_to_gam_prediction\": False,\n",
    "\n",
    "    # The value of 'k' used in the GAM will be the number of nodes arrived until\n",
    "    # it reaches this max value.\n",
    "    \"gam_k_value\": 100,\n",
    "\n",
    "    # Alter the edge weight for nodes that haven't arrived. This is a way to\n",
    "    # de-emphasise the prediction model for the unknown nodes.\n",
    "    \"prediction_model_emphasis\": 1.0,\n",
    "    \n",
    "    \n",
    "    # Path to the scotch shared library\n",
    "    \"SCOTCH_LIB_PATH\": os.path.join(pwd, \"libs/scotch/macOS/libscotch.dylib\")\n",
    "    if 'Darwin' in platform.system()\n",
    "    else \"/usr/local/lib/libscotch.so\",\n",
    "    \n",
    "    # Path to the PaToH shared library\n",
    "    \"PATOH_LIB_PATH\": os.path.join(pwd, \"libs/patoh/lib/macOS/libpatoh.dylib\")\n",
    "    if 'Darwin' in platform.system()\n",
    "    else os.path.join(pwd, \"libs/patoh/lib/linux/libpatoh.so\"),\n",
    "    \n",
    "    \"PATOH_ITERATIONS\": 5,\n",
    "\n",
    "    # Alters how much information to print. Keep it at 1 for this notebook.\n",
    "    # 0 - will print nothing, useful for batch operations.\n",
    "    # 1 - prints basic information on assignments and operations.\n",
    "    # 2 - prints more information as it batches arrivals.\n",
    "    \"verbose\": 1\n",
    "}\n",
    "\n",
    "#gp = GraphPartitioning(config)\n",
    "\n",
    "# Optional: shuffle the order of nodes arriving\n",
    "# Arrival order should not be shuffled if using GAM to alter node weights\n",
    "#random.shuffle(gp.arrival_order)\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNUNG ALGORITHM:  FENNEL\n",
      "Load Network\n",
      "Initialise Partitioner\n",
      "Compute prediction model\n",
      "Assign cut-off arrivals\n",
      "Batch arrival computation\n",
      "Finished in 2.593596935272217s\n",
      "\n",
      "RUNNUNG ALGORITHM:  SCOTCH\n",
      "Load Network\n",
      "Initialise Partitioner\n",
      "Compute prediction model\n",
      "Assign cut-off arrivals\n",
      "Batch arrival computation\n",
      "Finished in 8.320680141448975s\n",
      "\n",
      "RUNNUNG ALGORITHM:  PATOH\n",
      "Load Network\n",
      "Initialise Partitioner\n",
      "Compute prediction model\n",
      "Assign cut-off arrivals\n",
      "Batch arrival computation\n",
      "Finished in 3.145155906677246s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "output_graphs = {}\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    config['PREDICTION_MODEL_ALGORITHM'] = algorithm\n",
    "    config['PARTITIONER_ALGORITHM'] = algorithm\n",
    "    config['verbose'] = 0\n",
    "    \n",
    "    output_graphs[algorithm] = {}\n",
    "    \n",
    "    print('RUNNUNG ALGORITHM: ', algorithm)\n",
    "    start_time = time.time()\n",
    "    # create partitioner\n",
    "    gp = GraphPartitioning(config)\n",
    "    \n",
    "    # load network\n",
    "    print('Load Network')\n",
    "    gp.load_network()\n",
    "    \n",
    "    print('Initialise Partitioner')\n",
    "    gp.init_partitioner()\n",
    "    \n",
    "    print('Compute prediction model')\n",
    "    m = gp.prediction_model()\n",
    "    \n",
    "    if dumpAssignments:\n",
    "        output_graphs[algorithm]['prediction'] = gp.metrics_run_file_prefix_prediction + '-prediction-assignments.txt'\n",
    "        utils.write_assignment_file(gp.metrics_run_folder, gp.metrics_run_file_prefix_prediction + '-prediction-assignments.txt', gp.assignments)\n",
    "\n",
    "    print('Assign cut-off arrivals')\n",
    "    m = gp.assign_cut_off()\n",
    "    \n",
    "    if dumpAssignments:\n",
    "        output_graphs[algorithm]['cutoff'] = gp.metrics_run_file_prefix_prediction + '-cutoff-assignments.txt'\n",
    "        utils.write_assignment_file(gp.metrics_run_folder, gp.metrics_run_file_prefix_prediction + '-cutoff-assignments.txt', gp.assignments)\n",
    "    \n",
    "    print('Batch arrival computation')\n",
    "    m = gp.batch_arrival()\n",
    "    \n",
    "    if dumpAssignments:\n",
    "        output_graphs[algorithm]['batch'] = gp.metrics_run_file_prefix_prediction + '-batch-assignments.txt'\n",
    "        utils.write_assignment_file(gp.metrics_run_folder, gp.metrics_run_file_prefix_partitioner + '-batch-assignments.txt', gp.assignments)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    output_graphs[algorithm]['elapsed'] = str(end_time-start_time)\n",
    "    print('Finished in ' + str(end_time-start_time) + 's\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# store current run\n",
    "import datetime\n",
    "outfile = os.path.join(gp.metrics_run_folder, 'run_' + datetime.datetime.now().strftime('%y_%m_%d').replace(\"/\", \"\") + '.txt')\n",
    "with open(outfile, 'w+') as outF:\n",
    "    for alg in algorithms:\n",
    "        outF.write(output_graphs[alg]['prediction'] + '\\n')\n",
    "        outF.write(output_graphs[alg]['cutoff'] + '\\n')\n",
    "        outF.write(output_graphs[alg]['batch'] + '\\n')\n",
    "        outF.write(output_graphs[alg]['elapsed'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loadAssignments(path):\n",
    "    assignments = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            parts = line.split(\" \")\n",
    "            assignments.append(int(parts[1]))\n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# analyse prediction model\n",
    "fennel_pred_assignments = loadAssignments(output_graphs['FENNEL']['prediction'])\n",
    "scotch_pred_assignments = loadAssignments(output_graphs['SCOTCH']['prediction'])\n",
    "patoh_pred_assignments = loadAssignments(output_graphs['PATOH']['prediction'])\n",
    "\n",
    "fennel_batch_assignments = loadAssignments(output_graphs['FENNEL']['batch'])\n",
    "scotch_batch_assignments = loadAssignments(output_graphs['SCOTCH']['batch'])\n",
    "patoh_batch_assignments = loadAssignments(output_graphs['PATOH']['batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.14556242  0.15678145]\n",
      " [ 0.14556242  1.          0.33864059]\n",
      " [ 0.15678145  0.33864059  1.        ]]\n",
      "[[ 1.          0.65020998  0.64184705]\n",
      " [ 0.65020998  1.          0.72158337]\n",
      " [ 0.64184705  0.72158337  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#print(fennel_pred_assignments)\n",
    "#print(scotch_pred_assignments)\n",
    "#print(patoh_pred_assignments)\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmis\n",
    "\n",
    "fennel_nmi_prediction = [nmis(fennel_pred_assignments, fennel_pred_assignments)]\n",
    "fennel_nmi_prediction.append(nmis(fennel_pred_assignments, scotch_pred_assignments))\n",
    "fennel_nmi_prediction.append(nmis(fennel_pred_assignments, patoh_pred_assignments))\n",
    "\n",
    "scotch_nmi_prediction = [nmis(scotch_pred_assignments, fennel_pred_assignments)]\n",
    "scotch_nmi_prediction.append(nmis(scotch_pred_assignments, scotch_pred_assignments))\n",
    "scotch_nmi_prediction.append(nmis(scotch_pred_assignments, patoh_pred_assignments))\n",
    "\n",
    "patoh_nmi_prediction = [nmis(patoh_pred_assignments, fennel_pred_assignments)]\n",
    "patoh_nmi_prediction.append(nmis(patoh_pred_assignments, scotch_pred_assignments))\n",
    "patoh_nmi_prediction.append(nmis(patoh_pred_assignments, patoh_pred_assignments))\n",
    "\n",
    "nmi_prediction = np.array([fennel_nmi_prediction, scotch_nmi_prediction, patoh_nmi_prediction])\n",
    "\n",
    "print(nmi_prediction)\n",
    "\n",
    "fennel_nmi_batch = [nmis(fennel_batch_assignments, fennel_batch_assignments)]\n",
    "fennel_nmi_batch.append(nmis(fennel_batch_assignments, scotch_batch_assignments))\n",
    "fennel_nmi_batch.append(nmis(fennel_batch_assignments, patoh_batch_assignments))\n",
    "\n",
    "scotch_nmi_batch = [nmis(scotch_batch_assignments, fennel_batch_assignments)]\n",
    "scotch_nmi_batch.append(nmis(scotch_batch_assignments, scotch_batch_assignments))\n",
    "scotch_nmi_batch.append(nmis(scotch_batch_assignments, patoh_batch_assignments))\n",
    "\n",
    "patoh_nmi_batch = [nmis(patoh_batch_assignments, fennel_batch_assignments)]\n",
    "patoh_nmi_batch.append(nmis(patoh_batch_assignments, scotch_batch_assignments))\n",
    "patoh_nmi_batch.append(nmis(patoh_batch_assignments, patoh_batch_assignments))\n",
    "\n",
    "nmi_batch = np.array([fennel_nmi_batch, scotch_nmi_batch, patoh_nmi_batch])\n",
    "\n",
    "print(nmi_batch)\n",
    "\n",
    "fennel_nmi_self = [nmis(fennel_pred_assignments, fennel_batch_assignments)]\n",
    "scotch_nmi_self = [nmis(scotch_pred_assignments, scotch_batch_assignments)]\n",
    "patoh_nmi_self = [nmis(patoh_pred_assignments, patoh_batch_assignments)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 2, 4, 0, 2, 5, 0, 2, 5, 0, 4, 0, 1, 1, 4, 0, 0, 5, 0, 1, 1, 0, 3, 3, 5, 1, 5, 4, 3, 4, 2, 4, 1, 5, 2, 1, 4, 2, 0, 4, 3, 5, 2, 5, 5, 0, 0, 1, 3, 1, 4, 4, 1, 3, 3, 2, 4, 3, 1, 0, 2, 3, 5, 3, 5, 2, 2, 2, 0, 5, 4, 1, 5, 0, 2, 4, 3, 1, 5, 2, 1, 4, 5, 3, 0, 2, 3, 2, 1, 5, 5, 3, 1, 2, 1, 0, 4, 2, 3, 1, 5, 1, 1, 4, 4, 0, 5, 4, 2, 3, 3, 0, 1, 4, 1, 3, 2, 1, 2, 4, 3, 4, 4, 1, 3, 1, 4, 5, 5, 3, 2, 3, 0, 4, 0, 1, 2, 3, 0, 2, 0, 3, 4, 2, 1, 3, 3, 5, 1, 3, 0, 3, 1, 2, 0, 4, 3, 5, 0, 2, 3, 3, 4, 3, 4, 5, 5, 1, 0, 5, 5, 2, 3, 5, 4, 0, 3, 1, 0, 2, 5, 5, 0, 1, 1, 4, 3, 5, 1, 4, 2, 3, 1, 3, 1, 4, 0, 3, 0, 3, 0, 3, 4, 1, 0, 2, 4, 2, 3, 3, 3, 4, 2, 5, 0, 2, 4, 1, 3, 3, 2, 0, 5, 4, 0, 0, 3, 1, 1, 5, 3, 1, 3, 3, 2, 2, 2, 4, 1, 3, 0, 0, 3, 4, 4, 1, 5, 4, 1, 0, 2, 1, 1, 2, 4, 1, 1, 2, 1, 4, 3, 1, 1, 5, 1, 2, 4, 0, 2, 2, 2, 4, 4, 3, 4, 0, 3, 4, 5, 2, 0, 4, 5, 1, 2, 5, 5, 0, 2, 5, 0, 3, 3, 0, 3, 1, 5, 5, 3, 2, 0, 4, 5, 1, 4, 5, 1, 4, 1, 3, 3, 5, 5, 1, 0, 5, 3, 3, 5, 3, 3, 3, 4, 4, 2, 2, 0, 4, 2, 5, 3, 4, 5, 3, 1, 2, 5, 0, 4, 3, 1, 4, 3, 4, 3, 2, 0, 2, 3, 1, 1, 0, 4, 3, 5, 4, 1, 1, 3, 4, 0, 1, 0, 4, 2, 1, 4, 3, 3, 0, 5, 3, 4, 1, 5, 5, 1, 2, 0, 5, 1, 2, 2, 5, 3, 0, 4, 4, 3, 1, 0, 2, 4, 1, 3, 4, 4, 1, 1, 2, 4, 4, 3, 0, 4, 5, 0, 2, 1, 1, 4, 1, 1, 0, 3, 0, 2, 0, 2, 4, 0, 1, 5, 4, 5, 2, 3, 1, 2, 5, 1, 1, 5, 3, 1, 0, 5, 3, 4, 4, 1, 1, 1, 1, 3, 2, 5, 0, 4, 2, 4, 2, 2, 3, 0, 0, 2, 5, 2, 0, 2, 3, 4, 2, 3, 1, 0, 1, 1, 5, 4, 4, 5, 2, 0, 5, 3, 2, 4, 4, 5, 2, 0, 3, 1, 5, 3, 2, 2, 0, 4, 3, 0, 5, 0, 4, 4, 3, 3, 1, 1, 1, 3, 0, 2, 5, 4, 0, 2, 3, 4, 0, 5, 0, 4, 3, 3, 0, 1, 2, 1, 0, 2, 1, 0, 5, 3, 2, 3, 0, 2, 1, 4, 0, 4, 0, 2, 4, 5, 5, 5, 5, 2, 2, 2, 4, 1, 3, 1, 0, 4, 3, 5, 3, 3, 0, 1, 3, 2, 2, 4, 0, 3, 5, 1, 3, 1, 0, 3, 2, 5, 4, 0, 1, 4, 0, 3, 4, 3, 5, 0, 1, 0, 1, 1, 0, 2, 2, 1, 2, 5, 2, 0, 2, 2, 1, 0, 3, 2, 5, 3, 3, 5, 5, 4, 5, 0, 2, 0, 3, 5, 4, 5, 2, 5, 1, 2, 4, 3, 1, 4, 5, 5, 3, 0, 2, 2, 4, 5, 0, 5, 2, 2, 4, 1, 2, 5, 5, 4, 4, 5, 2, 0, 4, 1, 0, 5, 3, 3, 2, 1, 4, 2, 1, 1, 5, 5, 5, 2, 5, 5, 1, 3, 4, 2, 4, 3, 0, 2, 5, 3, 2, 4, 0, 1, 3, 4, 5, 4, 0, 0, 3, 5, 5, 4, 2, 0, 2, 2, 5, 0, 0, 1, 3, 5, 5, 0, 0, 5, 5, 5, 4, 2, 4, 2, 2, 4, 5, 5, 2, 1, 1, 0, 5, 0, 5, 0, 4, 0, 4, 5, 2, 1, 0, 5, 0, 4, 3, 2, 1, 2, 4, 0, 2, 5, 0, 0, 0, 1, 0, 4, 4, 1, 3, 3, 2, 5, 1, 0, 1, 4, 1, 0, 0, 0, 3, 0, 5, 4, 3, 5, 3, 2, 5, 4, 3, 5, 5, 1, 2, 5, 4, 3, 5, 0, 4, 1, 5, 4, 1, 2, 1, 0, 5, 1, 5, 2, 0, 3, 4, 2, 5, 2, 0, 4, 3, 4, 0, 3, 1, 4, 2, 1, 1, 3, 2, 3, 5, 0, 1, 4, 0, 2, 5, 3, 2, 1, 1, 4, 4, 0, 3, 3, 0, 4, 0, 5, 0, 3, 5, 0, 4, 3, 2, 5, 4, 1, 2, 1, 2, 2, 1, 2, 4, 0, 4, 5, 2, 2, 3, 5, 5, 0, 5, 4, 0, 1, 3, 2, 4, 3, 5, 4, 5, 4, 1, 5, 1, 0, 0, 4, 0, 4, 0, 0, 0, 3, 1, 4, 1, 4, 1, 2, 2, 1, 3, 4, 4, 4, 5, 2, 5, 2, 4, 4, 5, 1, 1, 1, 3, 0, 1, 1, 3, 5, 3, 5, 0, 0, 3, 4, 3, 2, 1, 3, 3, 0, 4, 1, 5, 1, 4, 3, 5, 2, 1, 0, 0, 0, 4, 3, 0, 3, 2, 5, 5, 1, 3, 5, 4, 0, 0, 0, 0, 0, 0, 5, 3, 2, 4, 2, 3, 5, 5, 4, 5, 3, 2, 1, 5, 3, 0, 3, 0, 2, 3, 0, 2, 1, 2, 1, 4, 5, 5, 0, 5, 5, 5, 2, 1, 2, 2, 4, 3, 0, 0, 2, 2, 1, 3, 2, 1, 5, 1, 2, 3, 4, 2]\n",
      "[-1, -1, -1, -1, 4, 0, -1, -1, -1, -1, -1, -1, 4, 0, -1, -1, -1, 0, 0, -1, -1, -1, -1, -1, 3, 3, -1, -1, -1, 4, -1, 4, -1, 4, -1, -1, -1, -1, 4, -1, 0, 4, 3, -1, -1, -1, -1, 0, -1, -1, 3, -1, -1, 4, -1, 3, 3, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, 0, 2, 4, -1, -1, -1, -1, -1, 4, -1, 3, 0, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, 0, 4, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, 4, -1, -1, 3, -1, -1, 4, -1, 3, -1, -1, -1, 4, 3, 4, -1, -1, -1, -1, 4, -1, -1, 3, -1, 3, -1, 4, -1, -1, -1, -1, -1, -1, -1, 3, 4, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, 0, 4, -1, -1, -1, -1, 3, -1, 4, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 4, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, 3, -1, -1, -1, 4, -1, -1, -1, 3, -1, -1, 4, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, 3, -1, 0, -1, 4, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, 0, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, 4, 3, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, 4, 4, -1, 4, 0, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 3, 0, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, 4, -1, -1, -1, -1, -1, 3, -1, -1, -1, 0, -1, 3, -1, -1, -1, 3, -1, 4, 4, -1, -1, 0, 4, -1, -1, 3, 4, -1, -1, -1, -1, -1, -1, 4, 3, -1, -1, 3, 4, 3, -1, -1, -1, -1, -1, -1, 0, 4, 3, -1, 5, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 5, -1, -1, 2, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, 5, -1, 1, -1, -1, -1, 2, -1, -1, 1, -1, 2, -1, -1, -1, 5, 1, -1, -1, 5, -1, -1, 5, -1, -1, 2, -1, -1, -1, 1, -1, -1, 2, 5, 5, 5, -1, -1, -1, -1, -1, -1, 2, -1, 5, -1, -1, -1, -1, 5, 1, -1, -1, -1, -1, -1, -1, 5, 5, -1, -1, -1, 1, -1, -1, -1, -1, 5, -1, -1, 2, -1, 3, -1, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 5, -1, 1, -1, -1, -1, 5, -1, 5, -1, -1, -1, -1, -1, -1, -1, 5, 1, 2, -1, 3, 2, -1, 2, 5, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, 5, 2, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, 5, -1, -1, -1, 1, 5, 3, 5, 1, -1, 2, -1, -1, -1, -1, -1, 1, 3, -1, -1, -1, -1, 2, 5, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, 2, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 2, -1, -1, 3, -1, -1, -1, -1, 2, -1, 1, 5, -1, 1, 2, -1, -1, -1, -1, 5, 3, -1, 5, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 5, 5, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, 2, 1, -1, -1, 5, -1, -1, -1, 0, -1, -1, -1, 5, -1, 1, -1, -1, -1, 0, -1, -1, 3, -1, -1, 0, 1, -1, -1, -1, 5, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, 0, -1, 2, -1, -1, 2, -1, -1, -1, 0, -1, 1, 1, -1, -1, -1, -1, 2, 0, -1, -1, 1, 1, 0, -1, -1, 5, 5, -1, -1, 3, -1, -1, -1, 2, -1, -1, -1, 0, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 0, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, 3, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, 0, 5, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 5, -1, -1, -1, 3, -1, -1, -1, 5, 5, 0, 2, -1, 0, 5, -1, -1, -1, 1, -1, -1, 2, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3, -1, 2, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 2, -1, 0, -1, -1, 3, 5, 1, 2, -1, -1, -1, -1, 2, 1, -1, -1, -1, -1, 1, 0, -1, -1, 5, -1, -1, -1, 0, 0, 3, 1, 3, -1, -1, 3, -1, -1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4, -1, 4, -1, -1, 3, -1, -1, -1, -1, -1, -1, 2, 0, 1, 1, 1, 0, 0, -1, -1, -1, 2, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, 3, 1, -1, 0, -1, 5, -1, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2, -1, -1, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1, -1, 4, -1]\n"
     ]
    }
   ],
   "source": [
    "print(patoh_pred_assignments)\n",
    "print(patoh_batch_assignments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
