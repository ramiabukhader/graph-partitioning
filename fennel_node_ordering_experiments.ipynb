{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import platform\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from graph_partitioning import GraphPartitioning, utils\n",
    "\n",
    "cols = [\"WASTE\", \"CUT RATIO\", \"EDGES CUT\", \"TOTAL COMM VOLUME\", \"Qds\", \"CONDUCTANCE\", \"MAXPERM\", \"RBSE\", \"NMI\", \"FSCORE\", \"FSCORE RELABEL IMPROVEMENT\", \"LONELINESS\"]\n",
    "\n",
    "pwd = %pwd\n",
    "\n",
    "\n",
    "ORDERED_ARRIVALS_DIR = os.path.join(pwd, \"data\", \"ideal_node_ordering\", \"ordered_centralities\")\n",
    "\n",
    "analysisOnly = True\n",
    "\n",
    "\n",
    "# [] 15 rankings - minimal binning\n",
    "# [] \n",
    "\n",
    "\n",
    "# parametrized config\n",
    "parametrized_config = {\n",
    "    \"DATA_FILENAME\": os.path.join(pwd, \"data\", \"ideal_node_ordering\", \"edgelist\", \"nn#networkID#.txt\"),\n",
    "    \"OUTPUT_DIRECTORY\": os.path.join(pwd, \"output\", \"ideal_node_ordering\"),\n",
    "\n",
    "    # Set which algorithm is run for the PREDICTION MODEL.\n",
    "    # Either: 'FENNEL' or 'SCOTCH'\n",
    "    \"PREDICTION_MODEL_ALGORITHM\": \"PATOH\",\n",
    "\n",
    "    # Alternativly, read input file for prediction model.\n",
    "    # Set to empty to generate prediction model using algorithm value above.\n",
    "    \"PREDICTION_MODEL\": \"\",\n",
    "\n",
    "    \n",
    "    \"PARTITIONER_ALGORITHM\": \"PATOH\",\n",
    "\n",
    "    # File containing simulated arrivals. This is used in simulating nodes\n",
    "    # arriving at the shelter. Nodes represented by line number; value of\n",
    "    # 1 represents a node as arrived; value of 0 represents the node as not\n",
    "    # arrived or needing a shelter.\n",
    "    \"SIMULATED_ARRIVAL_FILE\": os.path.join(pwd,\n",
    "                                           \"data\",\n",
    "                                           \"predition_model_tests\",\n",
    "                                           \"dataset_1_shift_rotate\",\n",
    "                                           \"simulated_arrival_list\",\n",
    "                                           \"percentage_of_prediction_correct_#correctedness#\",\n",
    "                                           \"arrival_#correctedness#_#networkID#.txt\"\n",
    "                                          ),\n",
    "    \n",
    "    # File containing the prediction of a node arriving. This is different to the\n",
    "    # simulated arrivals, the values in this file are known before the disaster.\n",
    "    \"PREDICTION_LIST_FILE\": os.path.join(pwd,\n",
    "                                         \"data\",\n",
    "                                         \"predition_model_tests\",\n",
    "                                         \"dataset_1_shift_rotate\",\n",
    "                                         \"prediction_list\",\n",
    "                                         \"prediction_#networkID#.txt\"\n",
    "                                        ),\n",
    "\n",
    "    # File containing the geographic location of each node, in \"x,y\" format.\n",
    "    \"POPULATION_LOCATION_FILE\": os.path.join(pwd,\n",
    "                                             \"data\",\n",
    "                                             \"predition_model_tests\",\n",
    "                                             \"coordinates\",\n",
    "                                             \"coordinates_#networkID#.txt\"\n",
    "                                            ),\n",
    "\n",
    "    # Number of shelters\n",
    "    \"num_partitions\": 4,\n",
    "\n",
    "    # The number of iterations when making prediction model\n",
    "    \"num_iterations\": 12,\n",
    "\n",
    "    # Percentage of prediction model to use before discarding\n",
    "    # When set to 0, prediction model is discarded, useful for one-shot\n",
    "    \"prediction_model_cut_off\": 0.0,\n",
    "\n",
    "    # Alpha value used in one-shot (when restream_batches set to 1)\n",
    "    \"one_shot_alpha\": 0.5,\n",
    "\n",
    "    \"use_one_shot_alpha\" : False,\n",
    "\n",
    "    # Number of arrivals to batch before recalculating alpha and restreaming.\n",
    "    # When set to 1, one-shot is used with alpha value from above\n",
    "    \"restream_batches\": 50,\n",
    "\n",
    "    # When the batch size is reached: if set to True, each node is assigned\n",
    "    # individually as first in first out. If set to False, the entire batch\n",
    "    # is processed and empty before working on the next batch.\n",
    "    \"sliding_window\": False,\n",
    "\n",
    "    # Create virtual nodes based on prediction model\n",
    "    \"use_virtual_nodes\": False,\n",
    "\n",
    "    # Virtual nodes: edge weight\n",
    "    \"virtual_edge_weight\": 1.0,\n",
    "\n",
    "    # Loneliness score parameter. Used when scoring a partition by how many\n",
    "    # lonely nodes exist.\n",
    "    \"loneliness_score_param\": 1.2,\n",
    "    \n",
    "    \n",
    "    \"compute_metrics_enabled\": True,\n",
    "\n",
    "    ####\n",
    "    # GRAPH MODIFICATION FUNCTIONS\n",
    "\n",
    "    # Also enables the edge calculation function.\n",
    "    \"graph_modification_functions\": True,\n",
    "\n",
    "    # If set, the node weight is set to 100 if the node arrives at the shelter,\n",
    "    # otherwise the node is removed from the graph.\n",
    "    \"alter_arrived_node_weight_to_100\": False,\n",
    "\n",
    "    # Uses generalized additive models from R to generate prediction of nodes not\n",
    "    # arrived. This sets the node weight on unarrived nodes the the prediction\n",
    "    # given by a GAM.\n",
    "    # Needs POPULATION_LOCATION_FILE to be set.\n",
    "    \"alter_node_weight_to_gam_prediction\": False,\n",
    "\n",
    "    # The value of 'k' used in the GAM will be the number of nodes arrived until\n",
    "    # it reaches this max value.\n",
    "    \"gam_k_value\": 100,\n",
    "\n",
    "    # Alter the edge weight for nodes that haven't arrived. This is a way to\n",
    "    # de-emphasise the prediction model for the unknown nodes.\n",
    "    \"prediction_model_emphasis\": 1.0,\n",
    "    \n",
    "    # This applies the prediction_list_file node weights onto the nodes in the graph\n",
    "    # when the prediction model is being computed and then removes the weights\n",
    "    # for the cutoff and batch arrival modes\n",
    "    \"apply_prediction_model_weights\": True,\n",
    "    \n",
    "    # Path to the scotch shared library\n",
    "    \"SCOTCH_LIB_PATH\": os.path.join(pwd, \"libs/scotch/macOS/libscotch.dylib\")\n",
    "    if 'Darwin' in platform.system()\n",
    "    else \"/usr/local/lib/libscotch.so\",\n",
    "    \n",
    "    # Path to the PaToH shared library\n",
    "    \"PATOH_LIB_PATH\": os.path.join(pwd, \"libs/patoh/lib/macOS/libpatoh.dylib\")\n",
    "    if 'Darwin' in platform.system()\n",
    "    else os.path.join(pwd, \"libs/patoh/lib/linux/libpatoh.so\"),\n",
    "    \n",
    "    \"PATOH_ITERATIONS\": 5,\n",
    "        \n",
    "    # Expansion modes: 'avg_node_weight', 'total_node_weight', 'smallest_node_weight'\n",
    "    # 'largest_node_weight'\n",
    "    # add '_squared' or '_sqrt' at the end of any of the above for ^2 or sqrt(weight)\n",
    "    # i.e. 'avg_node_weight_squared\n",
    "    \"PATOH_HYPEREDGE_EXPANSION_MODE\": 'no_expansion',\n",
    "    \n",
    "    # Edge Expansion: average, total, minimum, maximum, product, product_squared, sqrt_product\n",
    "    \"EDGE_EXPANSION_MODE\" : 'total',\n",
    "    \n",
    "    # Whether nodes should be reordered using a centrality metric for optimal node assignments in batch mode\n",
    "    # This is specific to FENNEL and at the moment Leverage Centrality is used to compute new noder orders\n",
    "    \"FENNEL_NODE_REORDERING_ENABLED\": False,\n",
    "    \n",
    "    # Whether the Friend of a Friend scoring system is active during FENNEL partitioning.\n",
    "    # FOAF employs information about a node's friends to determine the best partition when\n",
    "    # this node arrives at a shelter and no shelter has friends already arrived\n",
    "    \"FENNEL_FRIEND_OF_A_FRIEND_ENABLED\": False,\n",
    "    \n",
    "    # Alters how much information to print. Keep it at 1 for this notebook.\n",
    "    # 0 - will print nothing, useful for batch operations.\n",
    "    # 1 - prints basic information on assignments and operations.\n",
    "    # 2 - prints more information as it batches arrivals.\n",
    "    \"verbose\": 0\n",
    "}\n",
    "\n",
    "#gp = GraphPartitioning(config)\n",
    "\n",
    "# Optional: shuffle the order of nodes arriving\n",
    "# Arrival order should not be shuffled if using GAM to alter node weights\n",
    "#random.shuffle(gp.arrival_order)\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA centrality, random ordering n.40 experiments\n",
      "Alpha centrality, HL ordering n.40 experiments\n",
      "Alpha centrality, LH ordering n.40 experiments\n",
      "Average distance centrality, HL ordering n.40 experiments\n",
      "Average distance centrality, LH ordering n.40 experiments\n",
      "Barycenter centrality centrality, HL ordering n.40 experiments\n",
      "Barycenter centrality centrality, LH ordering n.40 experiments\n",
      "Betweenness centrality, HL ordering n.40 experiments\n",
      "Betweenness centrality, LH ordering n.40 experiments\n",
      "BottleNeck centrality centrality, HL ordering n.40 experiments\n",
      "BottleNeck centrality centrality, LH ordering n.40 experiments\n",
      "Bridging centrality centrality, HL ordering n.40 experiments\n",
      "Bridging centrality centrality, LH ordering n.40 experiments\n",
      "Centroid centrality centrality, HL ordering n.40 experiments\n",
      "Centroid centrality centrality, LH ordering n.40 experiments\n",
      "Closeness Freeman centrality, HL ordering n.40 experiments\n",
      "Closeness Freeman centrality, LH ordering n.40 experiments\n",
      "Closeness VariantLatora centrality, HL ordering n.40 experiments\n",
      "Closeness VariantLatora centrality, LH ordering n.40 experiments\n",
      "ClusterRank centrality, HL ordering n.40 experiments\n",
      "ClusterRank centrality, LH ordering n.40 experiments\n",
      "Communicability betweenness centrality centrality, HL ordering n.40 experiments\n",
      "Communicability betweenness centrality centrality, LH ordering n.40 experiments\n",
      "Community centrality centrality, HL ordering n.40 experiments\n",
      "Community centrality centrality, LH ordering n.40 experiments\n",
      "Core decomposition centrality, HL ordering n.40 experiments\n",
      "Core decomposition centrality, LH ordering n.40 experiments\n",
      "Cross clique centrality centrality, LH ordering n.40 experiments\n",
      "Cross clique connectivity centrality, HL ordering n.40 experiments\n",
      "Current flow closeness centrality centrality, HL ordering n.40 experiments\n",
      "Current flow closeness centrality centrality, LH ordering n.40 experiments\n",
      "Dangalchev closeness centrality centrality, HL ordering n.40 experiments\n",
      "Dangalchev closeness centrality centrality, LH ordering n.40 experiments\n",
      "Decay centrality centrality, HL ordering n.40 experiments\n",
      "Decay centrality centrality, LH ordering n.40 experiments\n",
      "Degree centrality centrality, HL ordering n.40 experiments\n",
      "Degree centrality centrality, LH ordering n.40 experiments\n",
      "Diffusion degree centrality, HL ordering n.40 experiments\n",
      "Diffusion degree centrality, LH ordering n.40 experiments\n",
      "DMNC centrality centrality, HL ordering n.40 experiments\n",
      "DMNC centrality centrality, LH ordering n.40 experiments\n",
      "Eccentricity centrality, HL ordering n.40 experiments\n",
      "Eccentricity centrality, LH ordering n.40 experiments\n",
      "Effectiveness centrality centrality, HL ordering n.40 experiments\n",
      "Effectiveness centrality centrality, LH ordering n.40 experiments\n",
      "Eigenvector centrality, HL ordering n.40 experiments\n",
      "Eigenvector centrality, LH ordering n.40 experiments\n",
      "Entropy centrality centrality, HL ordering n.40 experiments\n",
      "Entropy centrality centrality, LH ordering n.40 experiments\n",
      "EPC centrality, HL ordering n.40 experiments\n",
      "EPC centrality, LH ordering n.40 experiments\n",
      "Flow betweenness centrality centrality, HL ordering n.40 experiments\n",
      "Flow betweenness centrality centrality, LH ordering n.40 experiments\n",
      "Information centrality centrality, HL ordering n.40 experiments\n",
      "Information centrality centrality, LH ordering n.40 experiments\n",
      "Kleinbergs centrality HITS centrality, HL ordering n.40 experiments\n",
      "Kleinbergs centrality HITS centrality, LH ordering n.40 experiments\n",
      "LAC centrality, HL ordering n.40 experiments\n",
      "LAC centrality, LH ordering n.40 experiments\n",
      "Lapacian centrality centrality, HL ordering n.40 experiments\n",
      "Lapacian centrality centrality, LH ordering n.40 experiments\n",
      "Leverage centrality centrality, HL ordering n.40 experiments\n",
      "Leverage centrality centrality, LH ordering n.40 experiments\n",
      "Lin centrality centrality, HL ordering n.40 experiments\n",
      "Lin centrality centrality, LH ordering n.40 experiments\n",
      "Load centrality centrality, HL ordering n.40 experiments\n",
      "Load centrality centrality, LH ordering n.40 experiments\n",
      "Lobby index centrality, HL ordering n.40 experiments\n",
      "Lobby index centrality, LH ordering n.40 experiments\n",
      "Local assortativity centrality, HL ordering n.40 experiments\n",
      "Local assortativity centrality, LH ordering n.40 experiments\n",
      "Local clustering coefficients centrality, HL ordering n.40 experiments\n",
      "Local clustering coefficients centrality, LH ordering n.40 experiments\n",
      "Markov centrality centrality, HL ordering n.40 experiments\n",
      "Markov centrality centrality, LH ordering n.40 experiments\n",
      "MCC centrality centrality, HL ordering n.40 experiments\n",
      "MCC centrality centrality, LH ordering n.40 experiments\n",
      "MNC centrality centrality, HL ordering n.40 experiments\n",
      "MNC centrality centrality, LH ordering n.40 experiments\n",
      "Neighborhood connectivity centrality, HL ordering n.40 experiments\n",
      "Neighborhood connectivity centrality, LH ordering n.40 experiments\n",
      "Network centrality centrality, HL ordering n.40 experiments\n",
      "Network centrality centrality, LH ordering n.40 experiments\n",
      "Network fragmentation GeodesicDistanceWeighted centrality, HL ordering n.40 experiments\n",
      "Network fragmentation GeodesicDistanceWeighted centrality, LH ordering n.40 experiments\n",
      "Network fragmentation centrality, HL ordering n.40 experiments\n",
      "Network fragmentation centrality, LH ordering n.40 experiments\n",
      "Path centrality centrality, HL ordering n.40 experiments\n",
      "Path centrality centrality, LH ordering n.40 experiments\n",
      "Political independence index centrality, HL ordering n.40 experiments\n",
      "Political independence index centrality, LH ordering n.40 experiments\n",
      "Radiality centrality centrality, HL ordering n.40 experiments\n",
      "Radiality centrality centrality, LH ordering n.40 experiments\n",
      "Random walk betweenness centrality, HL ordering n.40 experiments\n",
      "Random walk betweenness centrality, LH ordering n.40 experiments\n",
      "Random walk closeness centrality, HL ordering n.40 experiments\n",
      "Random walk closeness centrality, LH ordering n.40 experiments\n",
      "SALSA centrality, HL ordering n.40 experiments\n",
      "SALSA centrality, LH ordering n.40 experiments\n",
      "Semi local centrality centrality, HL ordering n.40 experiments\n",
      "Semi local centrality centrality, LH ordering n.40 experiments\n",
      "Shortest path betweenness centrality, HL ordering n.40 experiments\n",
      "Shortest path betweenness centrality, LH ordering n.40 experiments\n",
      "Shortest path closeness centrality, HL ordering n.40 experiments\n",
      "Shortest path closeness centrality, LH ordering n.40 experiments\n",
      "Shortest path degree centrality, HL ordering n.40 experiments\n",
      "Shortest path degree centrality, LH ordering n.40 experiments\n",
      "Strength weighted vertex degree centrality, HL ordering n.40 experiments\n",
      "Strength weighted vertex degree centrality, LH ordering n.40 experiments\n",
      "Stress centrality centrality, HL ordering n.40 experiments\n",
      "Stress centrality centrality, LH ordering n.40 experiments\n",
      "Subgraph centrality, HL ordering n.40 experiments\n",
      "Subgraph centrality, LH ordering n.40 experiments\n",
      "Topological coefficient centrality, HL ordering n.40 experiments\n",
      "Topological coefficient centrality, LH ordering n.40 experiments\n"
     ]
    }
   ],
   "source": [
    "# load the centralities files\n",
    "import scipy.stats as sstats\n",
    "centralities = {}\n",
    "\n",
    "class CentralitiesExperiment:\n",
    "    def __init__(self, dirName, dataPath):\n",
    "        self.dirName = dirName\n",
    "        self.dataPath = dataPath\n",
    "        self.outputPath = os.path.join(parametrized_config[\"OUTPUT_DIRECTORY\"], dirName)\n",
    "                \n",
    "        parts = dirName.split(\"_\")\n",
    "        \n",
    "        self.orderType = parts[len(parts) - 1]\n",
    "        \n",
    "        name = dirName.replace('_' + self.orderType, \"\")\n",
    "        self.centralityType = name.replace(\"_\", \" \")\n",
    "\n",
    "        self.experimentFileNames = []\n",
    "        self.experimentFilePaths = []\n",
    "        \n",
    "        self.scores = []\n",
    "        self.avgScores = []\n",
    "        self.varScores = []\n",
    "        self.stdScores = []\n",
    "        self.skewnessScores = []\n",
    "        self.modeScores = []\n",
    "        \n",
    "        self.totalScore = 0.0\n",
    "\n",
    "    def computeStatsScore(self):\n",
    "        if(len(self.scores) == 0):\n",
    "            return\n",
    "        \n",
    "        scores = []\n",
    "        \n",
    "        self.avgScores = []\n",
    "        self.varScores = []\n",
    "        self.stdScores = []\n",
    "        self.skewnessScores = []\n",
    "        self.modeScores = []\n",
    "\n",
    "        for i in range(0, len(self.scores[0])):\n",
    "            scores.append([])\n",
    "            self.avgScores.append(0.0)\n",
    "            self.varScores.append(0.0)\n",
    "            self.stdScores.append(0.0)\n",
    "            self.skewnessScores.append(0.0)\n",
    "            self.modeScores.append(0.0)\n",
    "        \n",
    "        for score in self.scores:\n",
    "            for i, val in enumerate(score):\n",
    "                scores[i].append(float(val))\n",
    "        \n",
    "        for i, data in enumerate(scores):\n",
    "            data = np.array(data)\n",
    "            self.avgScores[i] = sstats.tmean(data)\n",
    "            self.varScores[i] = sstats.tvar(data)\n",
    "            self.stdScores[i] = sstats.tstd(data)\n",
    "            self.skewnessScores[i] = sstats.skew(data)\n",
    "            mode = sstats.mode(data)\n",
    "            self.modeScores[i] = str(mode[0][0]) + \":\" + str(mode[1][0])\n",
    "                \n",
    "    def _computeStatsScore(self):\n",
    "        if(len(self.scores) == 0):\n",
    "            return\n",
    "        \n",
    "        self.avgScores = []\n",
    "        self.varScores = []\n",
    "        self.stdScores = []\n",
    "        \n",
    "        for i in range(0, len(self.scores[0])):\n",
    "            self.avgScores.append(0.0)\n",
    "            self.varScores.append(0.0)\n",
    "        \n",
    "        for score in self.scores:\n",
    "            for i, val in enumerate(score):\n",
    "                self.avgScores[i] = self.avgScores[i] + float(val)\n",
    "        \n",
    "        for i, total in enumerate(self.avgScores):\n",
    "            self.avgScores[i] = total / len(self.scores)\n",
    "            \n",
    "        # compute variance\n",
    "        for score in self.scores:\n",
    "            for i, val in enumerate(score):\n",
    "                mean = self.avgScores[i]\n",
    "                diffsquared = (float(val) - mean) ** 2\n",
    "                self.varScores[i] = self.varScores[i] + diffsquared\n",
    "        \n",
    "        for i, total in enumerate(self.varScores):\n",
    "            self.varScores[i] = total / len(self.scores)\n",
    "            self.stdScores.append(self.varScores[i] ** 0.5)\n",
    "            \n",
    "    def printScoreline(self, scoreline):\n",
    "        print(\"{0:.5f}\\t{1:.10f}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\".format(scoreline[0],scoreline[1],scoreline[2],scoreline[3],scoreline[4],scoreline[5],scoreline[6]))\n",
    "            \n",
    "    def saveScores(self):\n",
    "        try:\n",
    "            os.makedirs(self.outputPath)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        fName = os.path.join(self.outputPath, \"scores.txt\")\n",
    "        with open(fName, 'w+') as f:\n",
    "            f.write(self.scoreStr(self.avgScores) + \"\\n\")\n",
    "            f.write(self.scoreStr(self.varScores) + \"\\n\")\n",
    "            f.write(self.scoreStr(self.stdScores) + \"\\n\")\n",
    "            f.write(self.scoreStr(self.modeScores) + \"\\n\")\n",
    "            f.write(self.scoreStr(self.skewnessScores) + \"\\n\")\n",
    "            \n",
    "            for score in self.scores:\n",
    "                f.write(self.scoreStr(score) + \"\\n\")\n",
    "\n",
    "    def loadScores(self):\n",
    "        self.scores = []\n",
    "        fName = os.path.join(self.outputPath, \"scores.txt\")\n",
    "        with open(fName, 'r') as f:\n",
    "            count = 0\n",
    "            for line in f:\n",
    "                if(count < 5):\n",
    "                    count += 1\n",
    "                    continue\n",
    "                line = line.strip()\n",
    "                parts = line.split(',')\n",
    "                score = []\n",
    "                for part in parts:\n",
    "                    score.append(float(part))\n",
    "                self.scores.append(score)\n",
    "                \n",
    "    def scoreStr(self, score):\n",
    "        s = \"\"\n",
    "        for val in score:\n",
    "            if len(s) > 0:\n",
    "                s = s + \",\"\n",
    "            s = s + str(val)\n",
    "        return s\n",
    "            \n",
    "    def centrality(self):\n",
    "        return self.centralityType\n",
    "    \n",
    "    def ordering(self):\n",
    "        return self.orderType\n",
    "    \n",
    "    def metadata(self):\n",
    "        return self.centralityType + \" centrality, \" + self.orderType + \" ordering n.\" + str(self.numExperiments()) + \" experiments\"\n",
    "    \n",
    "    def loadExperimentFiles(self):\n",
    "        for root, dirs, files in os.walk(self.dataPath):\n",
    "            for file in files:\n",
    "                if(file.endswith(\".txt\")):\n",
    "                    self.experimentFileNames.append(file.split(\".txt\")[0])\n",
    "        centrality.sortExperiments()\n",
    "\n",
    "    def sortExperiments(self):\n",
    "        ordered = []\n",
    "        indeces = {}\n",
    "        for f in self.experimentFileNames:\n",
    "            parts = f.split(\"_\")\n",
    "            index = int(parts[len(parts) - 1])\n",
    "            indeces[index] = f\n",
    "        \n",
    "        self.experimentFileNames = []\n",
    "\n",
    "        for i, idx in enumerate(sorted(list(indeces.keys()))):\n",
    "            fn = indeces[idx]\n",
    "            self.experimentFileNames.append(fn)\n",
    "            self.experimentFilePaths.append(os.path.join(self.dataPath, fn) + \".txt\")\n",
    "\n",
    "    def numExperiments(self):\n",
    "        return len(self.experimentFilePaths)\n",
    "            \n",
    "    def getDataExperimentPath(self, experimentNumber):\n",
    "        '''must go from 0 - n'''\n",
    "        if(experimentNumber >= 0 and experimentNumber < len(self.experimentFilePaths)):\n",
    "            return self.experimentFilePaths[experimentNumber]\n",
    "        return \"\"\n",
    "    \n",
    "    def getOutputExperimentPath(self, experimentNumber):\n",
    "        '''must go from 0 - n'''\n",
    "        if(experimentNumber >= 0 and experimentNumber < len(self.experimentFileNames)):\n",
    "            experiment = self.experimentFileNames[experimentNumber].split(\".txt\")\n",
    "            outFile = experiment[0] + \"_out.txt\"\n",
    "            return os.path.join(self.outputPath, outFile)\n",
    "        return \"\"\n",
    "        \n",
    "    def print(self):\n",
    "        print(self.dataPath)\n",
    "        for i, f in enumerate(self.experimentFileNames):\n",
    "            print(i,\" \", f)\n",
    "            print(self.experimentFilePaths[i])\n",
    "\n",
    "dataFiles = []\n",
    "for i in range(1, 41):\n",
    "    dataFiles.append(parametrized_config['DATA_FILENAME'].replace(\"#networkID#\", str(i)))\n",
    "# traverse root directory, and list directories as dirs and files as files\n",
    "for root, dirs, files in os.walk(ORDERED_ARRIVALS_DIR):\n",
    "    for directory in dirs:\n",
    "        centrality = CentralitiesExperiment(directory, os.path.join(ORDERED_ARRIVALS_DIR, directory))\n",
    "        centrality.loadExperimentFiles()\n",
    "        centralities[directory] = centrality\n",
    "        print(centrality.metadata())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished experiments.\n"
     ]
    }
   ],
   "source": [
    "# run the experiments here\n",
    "import pyximport\n",
    "pyximport.install()\n",
    "from graph_partitioning import fennel as fnl\n",
    "from graph_partitioning import scotch_partitioner as sctch\n",
    "from graph_partitioning import patoh_partitioner as ptoh\n",
    "from graph_partitioning import GraphPartitioning, utils\n",
    "\n",
    "fennel = fnl.FennelPartitioner(0.5)\n",
    "scotch = sctch.ScotchPartitioner(parametrized_config['SCOTCH_LIB_PATH'])\n",
    "patoh = ptoh.PatohPartitioner(parametrized_config['PATOH_LIB_PATH'], hyperedgeExpansionMode=parametrized_config['PATOH_HYPEREDGE_EXPANSION_MODE'])\n",
    "\n",
    "def loadGraph(edgeFile):\n",
    "    G = nx.Graph()\n",
    "    edges = []\n",
    "    with open(edgeFile, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            line = line.split(\" \")\n",
    "            n1 = int(line[0])\n",
    "            n2 = int(line[1])\n",
    "            \n",
    "            G.add_node(n1)\n",
    "            G.add_node(n2)\n",
    "            \n",
    "            edges.append((n1, n2))\n",
    "        for edge in edges:\n",
    "            G.add_edge(edge[0], edge[1])\n",
    "    nx.set_node_attributes(G, 'weight', 1.0)\n",
    "    nx.set_edge_attributes(G, 'weight', 1.0)\n",
    "    return G\n",
    "\n",
    "def loadArrivals(arrivalFile):\n",
    "    arrivals = []\n",
    "    with open(arrivalFile, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            arrivals.append(int(line))\n",
    "    return np.array(arrivals, dtype=np.int32)\n",
    "\n",
    "def generateArray(num, value):\n",
    "    arr = []\n",
    "    for i in range(0, num):\n",
    "        arr.append(value)\n",
    "    return np.array(arr, dtype=np.int32)\n",
    "\n",
    "def checkInputData(graph, arrivals):\n",
    "    if(graph.number_of_nodes() == 0):\n",
    "        print(\"Error, no nodes\")\n",
    "        return False\n",
    "    if(graph.number_of_edges() == 0):\n",
    "        print(\"Error, no edges\")\n",
    "        return False\n",
    "        \n",
    "    arr = np.array(arrivals)\n",
    "    if(np.min(arr) > 0):\n",
    "        print(\"Error arrival file has minimum node ID > 0:\", np.min(arr))\n",
    "        return False\n",
    "    if(np.max(arr) >= graph.number_of_nodes()):\n",
    "        print(\"Error arrival file has maximum node ID >= number_of_nodes():\", np.max(arr))\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def computeAlpha(graph, num_partitions):\n",
    "    numedges = graph.number_of_edges()\n",
    "    if(graph.is_directed()):\n",
    "        numedges = numedges * 0.5\n",
    "    return numedges * (num_partitions / (graph.number_of_nodes()**2))\n",
    "    \n",
    "def printScore(graph, assignments, num_partitions, loneliness_score_param, verbose = 1):\n",
    "        x = utils.score(graph, assignments, num_partitions)\n",
    "        edges_cut, steps, cut_edges = utils.base_metrics(graph, assignments)\n",
    "\n",
    "        q_qds_conductance = utils.infomapModularityComQuality(graph, assignments, num_partitions)\n",
    "        #old: mod = utils.modularity_wavg(graph, assignments, num_partitions)\n",
    "        loneliness = utils.loneliness_score_wavg(graph, loneliness_score_param, assignments, num_partitions)\n",
    "        max_perm = utils.wavg_max_perm(graph, assignments, num_partitions)\n",
    "        #old: max_perm = utils.run_max_perm(graph)\n",
    "\n",
    "        #nmi_score = nmi_metrics.nmi(np.array([self.assignments_prediction_model, self.assignments]))\n",
    "        #nmi_score = normalized_mutual_info_score(self.assignments_prediction_model.tolist(), self.assignments.tolist())\n",
    "        if verbose > 1:\n",
    "            print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\\t\\t{3}\\t\\t\\t{4}\\t{5}\\t{6}\".format(x[0], x[1], edges_cut, steps, q_qds_conductance[0], loneliness, max_perm))\n",
    "            #print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\\t\\t{3}\\t\\t\\t{4}\\t{5}\\t{6}\".format(x[0], x[1], edges_cut, steps, mod, loneliness, max_perm))\n",
    "            #print(\"{0:.5f}\\t\\t{1:.10f}\\t{2}\\t\\t{3}\\t\\t\\t{4}\\t{5}\\t{6}\\t{7:.10f}\".format(x[0], x[1], edges_cut, steps, mod, loneliness, max_perm, nmi_score))\n",
    "        # waste, cut_ratio, edges_cut, TCV (steps), Qds, loneliness, max_perm\n",
    "        return [x[0], x[1], edges_cut, steps, q_qds_conductance[0], loneliness, max_perm]\n",
    "\n",
    "\n",
    "    \n",
    "# Run the centralities experiment for eachdatapoint\n",
    "'''for key in list(centralities.keys()):\n",
    "    if analysisOnly == True:\n",
    "        break\n",
    "\n",
    "\n",
    "    centrality = centralities[key]\n",
    "\n",
    "    print(\"Running experiment:\", centrality.metadata())\n",
    "\n",
    "    for i in range(0, 40):\n",
    "        with GraphPartitioning(parametrized_config) as gp:\n",
    "            gp.verbose = 0\n",
    "            gp.DATA_FILENAME = dataFiles[i]\n",
    "            print(gp.DATA_FILENAME)\n",
    "            \n",
    "            gp.load_network()\n",
    "            gp.init_partitioner()\n",
    "    \n",
    "            gp.arrival_order = loadArrivals(centrality.getDataExperimentPath(i))\n",
    "    \n",
    "            m = gp.prediction_model()\n",
    "            m = gp.assign_cut_off()\n",
    "            m = gp.batch_arrival()\n",
    "            \n",
    "            print(m)\n",
    "        break\n",
    "\n",
    "analysisOnly = True\n",
    "'''\n",
    "\n",
    "# FORMAT OF SAVED scores.txt files\n",
    "\n",
    "# average (scores)\n",
    "# variance (scores)\n",
    "# std (scores)\n",
    "# mode(scores)\n",
    "# skewness (scores)\n",
    "# this is then followed by each experiment's scores over which the stats above are computed\n",
    "# waste, cut_ratio, edges_cut, TCV (steps), Qds, loneliness, max_perm\n",
    "\n",
    "for key in list(centralities.keys()):\n",
    "    if analysisOnly == True:\n",
    "        break\n",
    "    \n",
    "    centrality = centralities[key]\n",
    "\n",
    "    print(\"Running experiment:\", centrality.metadata())\n",
    "\n",
    "    for i in range(0, 40):\n",
    "        edgeFile = dataFiles[i]\n",
    "        \n",
    "        G = loadGraph(edgeFile)\n",
    "        arrival_list = loadArrivals(centrality.getDataExperimentPath(i))\n",
    "        GSub = G.subgraph(arrival_list)\n",
    "        \n",
    "        if checkInputData(G, arrival_list):\n",
    "            # ok, can proceed\n",
    "            assignments = generateArray(G.number_of_nodes(), -1)\n",
    "            fixed = generateArray(G.number_of_nodes(), -1)\n",
    "            \n",
    "            if parametrized_config['PARTITIONER_ALGORITHM'] == 'FENNEL':\n",
    "                assignments = fennel.generate_prediction_model(GSub, parametrized_config['num_iterations'], parametrized_config['num_partitions'], assignments, fixed)\n",
    "\n",
    "            elif parametrized_config['PARTITIONER_ALGORITHM'] == 'SCOTCH':\n",
    "                assignments = scotch.generate_prediction_model(GSub, parametrized_config['num_iterations'], parametrized_config['num_partitions'], assignments, fixed)\n",
    "\n",
    "            elif parametrized_config['PARTITIONER_ALGORITHM'] == 'PATOH':\n",
    "                assignments = patoh.generate_prediction_model(GSub, parametrized_config['num_iterations'], parametrized_config['num_partitions'], assignments, fixed)\n",
    "\n",
    "            # score contains: x[0], x[1], edges_cut, steps, mod, loneliness, max_perm\n",
    "            score = printScore(GSub, assignments, parametrized_config['num_partitions'], parametrized_config['loneliness_score_param'])\n",
    "            centrality.scores.append(score)\n",
    "    centrality.computeStatsScore()\n",
    "    centrality.saveScores()\n",
    "print(\"Finished experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: AA:random\n",
      "0.00000\t0.3642223887\t90.15\t95.075\t0.40797893778021416\t0.7452021271808\t0.015190637500000001\n",
      "Experiment: Alpha:HL\n",
      "0.00000\t0.3647740181\t90.275\t95.075\t0.41115159179477806\t0.744545604013975\t0.0088029375\n",
      "Experiment: Alpha:LH\n",
      "0.00000\t0.3658334816\t90.525\t95.375\t0.4053231887936006\t0.74230364451105\t0.0037204749999999983\n",
      "Experiment: Average distance:HL\n",
      "0.00000\t0.3645310507\t90.2\t95.05\t0.4075215286242746\t0.744011746651\t0.0018389312500000012\n",
      "Experiment: Average distance:LH\n",
      "0.00000\t0.3636613102\t89.975\t94.7\t0.40908385545430875\t0.74508042203465\t0.017410981249999995\n",
      "Experiment: Barycenter centrality:HL\n",
      "0.00000\t0.3640772634\t90.125\t94.9\t0.4069757202140485\t0.7438894779868999\t0.013572856249999996\n",
      "Experiment: Barycenter centrality:LH\n",
      "0.00000\t0.3654111274\t90.425\t94.625\t0.406124519912213\t0.7452016174462999\t0.00829180625\n",
      "Experiment: Betweenness:HL\n",
      "0.00000\t0.3631679285\t89.875\t94.7\t0.40810236534105326\t0.7457118069159749\t0.006608412499999999\n",
      "Experiment: Betweenness:LH\n",
      "0.00000\t0.3644296037\t90.225\t94.75\t0.41196966832966525\t0.74575883253165\t0.0141436125\n",
      "Experiment: BottleNeck centrality:HL\n",
      "0.00000\t0.3637777807\t90.075\t94.475\t0.4074312854289065\t0.7448311965858501\t0.009125637499999997\n",
      "Experiment: BottleNeck centrality:LH\n",
      "0.00000\t0.3665493721\t90.75\t94.725\t0.40878761929261725\t0.744916795950625\t0.010943999999999999\n",
      "Experiment: Bridging centrality:HL\n",
      "0.00000\t0.3630582954\t89.85\t94.6\t0.405038752836108\t0.744653098729825\t0.018392743750000003\n",
      "Experiment: Bridging centrality:LH\n",
      "0.00000\t0.3661760897\t90.625\t95.2\t0.4132103597993465\t0.7436538852024499\t0.011136356249999996\n",
      "Experiment: Centroid centrality:HL\n",
      "0.00000\t0.3631942368\t89.875\t94.725\t0.4078742255644219\t0.74505991745195\t0.00382379375\n",
      "Experiment: Centroid centrality:LH\n",
      "0.00000\t0.3646248756\t90.225\t94.75\t0.40783214774226506\t0.745769724602975\t0.007270837500000002\n",
      "Experiment: Closeness Freeman:HL\n",
      "0.00000\t0.3622272691\t89.65\t94.75\t0.4069251558361838\t0.7447687813746249\t0.01101601875\n",
      "Experiment: Closeness Freeman:LH\n",
      "0.00000\t0.3653765749\t90.45\t94.375\t0.40444879425402547\t0.7461429551382\t0.008509056249999999\n",
      "Experiment: Closeness VariantLatora:HL\n",
      "0.00000\t0.3627372153\t89.775\t94.625\t0.4040367621764364\t0.7455223685652751\t0.0034830187499999997\n",
      "Experiment: Closeness VariantLatora:LH\n",
      "0.00000\t0.3664906961\t90.675\t95.0\t0.4001835987690533\t0.7448012702693501\t0.001678956249999998\n",
      "Experiment: ClusterRank:HL\n",
      "0.00000\t0.3647183291\t90.275\t94.8\t0.40524555025825515\t0.744677566647775\t0.012811\n",
      "Experiment: ClusterRank:LH\n",
      "0.00000\t0.3670355496\t90.875\t94.65\t0.4096574398534285\t0.7444846868678751\t0.005112787500000002\n",
      "Experiment: Communicability betweenness centrality:HL\n",
      "0.00000\t0.3629078215\t89.825\t94.8\t0.40582438402328513\t0.7447219906149251\t0.005961899999999998\n",
      "Experiment: Communicability betweenness centrality:LH\n",
      "0.00000\t0.3658318603\t90.55\t94.8\t0.40904961125216605\t0.7457664749913251\t0.018212306249999997\n",
      "Experiment: Community centrality:HL\n",
      "0.00000\t0.3660644933\t90.6\t95.0\t0.40572822598050423\t0.74401823542805\t0.007256137499999996\n",
      "Experiment: Community centrality:LH\n",
      "0.00000\t0.3628615713\t89.8\t94.175\t0.4080974516929941\t0.745545226373325\t0.007228931249999998\n",
      "Experiment: Core decomposition:HL\n",
      "0.00000\t0.3670329851\t90.85\t95.5\t0.4052856199455884\t0.744483173648225\t0.010877650000000003\n",
      "Experiment: Core decomposition:LH\n",
      "0.00000\t0.3668683821\t90.8\t94.8\t0.40667458432682724\t0.7453089241844\t0.01582134375\n",
      "Experiment: Cross clique centrality:LH\n",
      "0.00000\t0.3639672022\t90.075\t94.75\t0.4104435251933757\t0.7455975857198499\t0.006680674999999997\n",
      "Experiment: Cross clique connectivity:HL\n",
      "0.00000\t0.3645385265\t90.225\t95.325\t0.4034093425395275\t0.743349920419375\t0.0057636187499999995\n",
      "Experiment: Current flow closeness centrality:HL\n",
      "0.00000\t0.3641996225\t90.175\t94.4\t0.40451672525076515\t0.7450303964074501\t0.004267712499999998\n",
      "Experiment: Current flow closeness centrality:LH\n",
      "0.00000\t0.3655081529\t90.45\t95.15\t0.41321945306681124\t0.743743345632625\t0.007594706250000002\n",
      "Experiment: Dangalchev closeness centrality:HL\n",
      "0.00000\t0.3672944817\t90.875\t94.5\t0.4076005332703268\t0.7434291324959499\t0.010649112499999999\n",
      "Experiment: Dangalchev closeness centrality:LH\n",
      "0.00000\t0.3675968132\t91.025\t94.625\t0.4092778378666055\t0.744916057973275\t0.01017416875\n",
      "Experiment: Decay centrality:HL\n",
      "0.00000\t0.3590076096\t88.875\t94.225\t0.39965308611044803\t0.74524099770665\t0.011372756250000001\n",
      "Experiment: Decay centrality:LH\n",
      "0.00000\t0.3655529964\t90.475\t94.975\t0.40247783768193884\t0.744450013061575\t0.007395674999999999\n",
      "Experiment: Degree centrality:HL\n",
      "0.00000\t0.3647216909\t90.25\t94.675\t0.4006595107972729\t0.7441225174054751\t0.0116496625\n",
      "Experiment: Degree centrality:LH\n",
      "0.00000\t0.3674526250\t90.925\t95.525\t0.41270631168813204\t0.7446733139656001\t0.0126161\n",
      "Experiment: Diffusion degree:HL\n",
      "0.00000\t0.3644917288\t90.175\t94.975\t0.4071546437660297\t0.7450511132502751\t0.001985337499999995\n",
      "Experiment: Diffusion degree:LH\n",
      "0.00000\t0.3659146239\t90.6\t94.65\t0.40922018820185535\t0.7442862642762751\t0.009801600000000002\n",
      "Experiment: DMNC centrality:HL\n",
      "0.00000\t0.3627969334\t89.775\t94.825\t0.4071594680594764\t0.7445875435493\t0.0016898499999999997\n",
      "Experiment: DMNC centrality:LH\n",
      "0.00000\t0.3667127968\t90.775\t94.8\t0.4082493225539869\t0.745812061676\t0.01243820625\n",
      "Experiment: Eccentricity:HL\n",
      "0.00000\t0.3632311553\t89.9\t94.425\t0.4043407180582018\t0.7450767129071749\t0.003916043749999998\n",
      "Experiment: Eccentricity:LH\n",
      "0.00000\t0.3645576814\t90.225\t94.35\t0.4030604593296955\t0.74432757309925\t-0.007772662500000002\n",
      "Experiment: Effectiveness centrality:HL\n",
      "0.00000\t0.3613131771\t89.425\t94.8\t0.40641586322637024\t0.744634549831725\t0.01774888125\n",
      "Experiment: Effectiveness centrality:LH\n",
      "0.00000\t0.3680917884\t91.075\t95.25\t0.403844906534968\t0.744407778986225\t0.0013982937499999986\n",
      "Experiment: Eigenvector:HL\n",
      "0.00000\t0.3640107775\t90.075\t94.6\t0.404636567693838\t0.7437899916320999\t0.0036827812500000016\n",
      "Experiment: Eigenvector:LH\n",
      "0.00000\t0.3705339234\t91.75\t94.875\t0.4112157749378351\t0.743728665228075\t0.0006732562499999993\n",
      "Experiment: Entropy centrality:HL\n",
      "0.00000\t0.3645231316\t90.225\t94.7\t0.40464849899995314\t0.7455508286539001\t0.008042893749999998\n",
      "Experiment: Entropy centrality:LH\n",
      "0.00000\t0.3662869224\t90.675\t94.85\t0.41065132617505207\t0.744494319104125\t0.004462237499999996\n",
      "Experiment: EPC:HL\n",
      "0.00000\t0.3649660887\t90.325\t94.85\t0.40537244300716646\t0.744043487179175\t0.005503799999999998\n",
      "Experiment: EPC:LH\n",
      "0.00000\t0.3681021627\t91.125\t94.5\t0.40839313458453325\t0.744640106208425\t0.007887331249999999\n",
      "Experiment: Flow betweenness centrality:HL\n",
      "0.00000\t0.3631762932\t89.875\t94.7\t0.3990590484666755\t0.7456794018325\t0.005472499999999998\n",
      "Experiment: Flow betweenness centrality:LH\n",
      "0.00000\t0.3670037421\t90.85\t94.95\t0.4107419445425404\t0.7451467153747999\t0.007689062500000001\n",
      "Experiment: Information centrality:HL\n",
      "0.00000\t0.3622525327\t89.675\t94.4\t0.4030490112289595\t0.74414691448825\t0.006413618749999997\n",
      "Experiment: Information centrality:LH\n",
      "0.00000\t0.3629195524\t89.8\t94.725\t0.40824255903825346\t0.7455164394426751\t0.006005024999999997\n",
      "Experiment: Kleinbergs centrality HITS:HL\n",
      "0.00000\t0.3634840753\t89.95\t94.7\t0.406024610153645\t0.7446517949545\t0.012528862499999998\n",
      "Experiment: Kleinbergs centrality HITS:LH\n",
      "0.00000\t0.3686085256\t91.25\t95.45\t0.4081550913290902\t0.744311100229725\t0.013055737500000001\n",
      "Experiment: LAC:HL\n",
      "0.00000\t0.3649141573\t90.3\t94.875\t0.40084989174042357\t0.744902984211875\t0.010347424999999999\n",
      "Experiment: LAC:LH\n",
      "0.00000\t0.3671967625\t90.925\t94.5\t0.41763712321281365\t0.74404203492385\t0.002832006249999999\n",
      "Experiment: Lapacian centrality:HL\n",
      "0.00000\t0.3632961332\t89.9\t94.575\t0.4067596307165718\t0.7453328548437501\t0.015099731250000002\n",
      "Experiment: Lapacian centrality:LH\n",
      "0.00000\t0.3631144463\t89.875\t94.8\t0.40827850687283984\t0.745402024488925\t0.0140508125\n",
      "Experiment: Leverage centrality:HL\n",
      "0.00000\t0.3625166910\t89.725\t95.075\t0.4088664710330484\t0.74444560633805\t0.013239037499999998\n",
      "Experiment: Leverage centrality:LH\n",
      "0.00000\t0.3637256101\t90.0\t94.925\t0.4094942204409781\t0.745264324760425\t0.0068871062499999995\n",
      "Experiment: Lin centrality:HL\n",
      "0.00000\t0.3640257993\t90.1\t94.45\t0.40132127816367846\t0.744773304787375\t-0.0014220312500000027\n",
      "Experiment: Lin centrality:LH\n",
      "0.00000\t0.3659003136\t90.575\t94.675\t0.406208191873071\t0.7448713974357501\t0.00826160625\n",
      "Experiment: Load centrality:HL\n",
      "0.00000\t0.3641178375\t90.125\t94.475\t0.4089689737035059\t0.746338934960025\t0.0034134875000000017\n",
      "Experiment: Load centrality:LH\n",
      "0.00000\t0.3660285623\t90.575\t94.675\t0.4086545905684028\t0.7447562527178251\t-0.007584812500000001\n",
      "Experiment: Lobby index:HL\n",
      "0.00000\t0.3619087277\t89.575\t94.725\t0.40692375631886346\t0.74489264278705\t0.00886863125\n",
      "Experiment: Lobby index:LH\n",
      "0.00000\t0.3658573795\t90.575\t94.95\t0.413686806453801\t0.7451795748016499\t0.010596425000000001\n",
      "Experiment: Local assortativity:HL\n",
      "0.00000\t0.3660302515\t90.6\t94.825\t0.41146435795543956\t0.743560136442475\t0.006895568750000002\n",
      "Experiment: Local assortativity:LH\n",
      "0.00000\t0.3616080106\t89.475\t94.75\t0.4046544486037124\t0.745625476338725\t0.007852056249999998\n",
      "Experiment: Local clustering coefficients:HL\n",
      "0.00000\t0.3621304554\t89.65\t94.8\t0.40754108637741204\t0.745264391769\t0.012475131249999999\n",
      "Experiment: Local clustering coefficients:LH\n",
      "0.00000\t0.3660018069\t90.575\t94.8\t0.41149021186542073\t0.7451110974218\t0.01053450625\n",
      "Experiment: Markov centrality:HL\n",
      "0.00000\t0.3653153886\t90.425\t94.85\t0.40502354391857426\t0.744169999253425\t0.010258543749999998\n",
      "Experiment: Markov centrality:LH\n",
      "0.00000\t0.3660962129\t90.625\t94.7\t0.4105529701938691\t0.7443545373370251\t-0.00047551875000000006\n",
      "Experiment: MCC centrality:HL\n",
      "0.00000\t0.3630751565\t89.85\t94.675\t0.4035640765897174\t0.7435313117307499\t0.0059221375\n",
      "Experiment: MCC centrality:LH\n",
      "0.00000\t0.3598174990\t89.025\t94.35\t0.40268011794937575\t0.7465249795838\t0.011803675\n",
      "Experiment: MNC centrality:HL\n",
      "0.00000\t0.3654984778\t90.475\t95.175\t0.40751459163287657\t0.745079188147225\t0.015487518750000002\n",
      "Experiment: MNC centrality:LH\n",
      "0.00000\t0.3636133276\t90.025\t94.425\t0.40976985964957535\t0.7458369890288\t0.0187926375\n",
      "Experiment: Neighborhood connectivity:HL\n",
      "0.00000\t0.3618962610\t89.575\t94.9\t0.40887945007019233\t0.743987952893125\t0.009243231249999997\n",
      "Experiment: Neighborhood connectivity:LH\n",
      "0.00000\t0.3652870832\t90.4\t95.2\t0.409766678412013\t0.7438377718132501\t0.00985805625\n",
      "Experiment: Network centrality:HL\n",
      "0.00000\t0.3605575012\t89.225\t94.675\t0.39919839894546194\t0.7445001077797501\t-0.0037855375000000017\n",
      "Experiment: Network centrality:LH\n",
      "0.00000\t0.3671154963\t90.9\t93.95\t0.4131866605433627\t0.745381439279325\t-0.0016027125000000024\n",
      "Experiment: Network fragmentation GeodesicDistanceWeighted:HL\n",
      "0.00000\t0.3662881429\t90.675\t94.525\t0.4068867664114781\t0.743706800055125\t0.0009822499999999983\n",
      "Experiment: Network fragmentation GeodesicDistanceWeighted:LH\n",
      "0.00000\t0.3627255821\t89.775\t94.925\t0.40539396183169957\t0.7450581399167999\t0.01011550625\n",
      "Experiment: Network fragmentation:HL\n",
      "0.00000\t0.3670125810\t90.85\t94.175\t0.40826688455892574\t0.7452541473019251\t0.008974293749999997\n",
      "Experiment: Network fragmentation:LH\n",
      "0.00000\t0.3663757369\t90.675\t95.025\t0.4105638012552844\t0.744414495382775\t0.01740784375\n",
      "Experiment: Path centrality:HL\n",
      "0.00000\t0.3664587255\t90.675\t94.925\t0.40490343316240623\t0.7442492170914\t0.0036195249999999984\n",
      "Experiment: Path centrality:LH\n",
      "0.00000\t0.3659786465\t90.575\t94.85\t0.40920863059767615\t0.74524067303175\t0.010507806250000001\n",
      "Experiment: Political independence index:HL\n",
      "0.00000\t0.3655583406\t90.525\t94.85\t0.40939836466993773\t0.7443638312009501\t0.0164090875\n",
      "Experiment: Political independence index:LH\n",
      "0.00000\t0.3643131614\t90.2\t95.25\t0.40637739339130263\t0.7448237398582\t0.011263849999999999\n",
      "Experiment: Radiality centrality:HL\n",
      "0.00000\t0.3670685798\t90.875\t94.975\t0.4079072206208723\t0.7451585848389\t0.014046568749999998\n",
      "Experiment: Radiality centrality:LH\n",
      "0.00000\t0.3671927433\t90.9\t95.2\t0.4058981977557784\t0.74546165731575\t0.00346495\n",
      "Experiment: Random walk betweenness:HL\n",
      "0.00000\t0.3629168378\t89.85\t94.2\t0.4052305134861898\t0.7448085019982\t0.003599631249999999\n",
      "Experiment: Random walk betweenness:LH\n",
      "0.00000\t0.3659761856\t90.575\t95.325\t0.40505653288041865\t0.74553413658445\t0.011020174999999998\n",
      "Experiment: Random walk closeness:HL\n",
      "0.00000\t0.3652502156\t90.4\t95.125\t0.40583788712969593\t0.7433442552807501\t0.012752924999999998\n",
      "Experiment: Random walk closeness:LH\n",
      "0.00000\t0.3679728303\t91.075\t94.8\t0.4141288173503866\t0.7447131753127001\t-0.0024356187500000014\n",
      "Experiment: SALSA:HL\n",
      "0.00000\t0.3627530186\t89.8\t94.25\t0.4071647137849963\t0.744096826173575\t0.006998075000000001\n",
      "Experiment: SALSA:LH\n",
      "0.00000\t0.3702659473\t91.65\t94.75\t0.4120075835672732\t0.744732096132825\t8.749999999974057e-08\n",
      "Experiment: Semi local centrality:HL\n",
      "0.00000\t0.3636054521\t90.025\t94.425\t0.4050772508091269\t0.74461761910655\t0.02027639375\n",
      "Experiment: Semi local centrality:LH\n",
      "0.00000\t0.3638689874\t90.075\t94.8\t0.4111395442576983\t0.746228357875725\t0.01591230625\n",
      "Experiment: Shortest path betweenness:HL\n",
      "0.00000\t0.3634099480\t89.95\t94.325\t0.408153339349243\t0.74508403261655\t0.012279156250000001\n",
      "Experiment: Shortest path betweenness:LH\n",
      "0.00000\t0.3636258989\t90.0\t94.775\t0.4083512290076115\t0.744775248226625\t0.0018482750000000017\n",
      "Experiment: Shortest path closeness:HL\n",
      "0.00000\t0.3621622707\t89.625\t94.925\t0.4085792087038646\t0.7445485772140501\t-0.0033176875000000003\n",
      "Experiment: Shortest path closeness:LH\n",
      "0.00000\t0.3667686729\t90.75\t95.1\t0.4033911490576615\t0.7441642823393501\t0.003531843749999998\n",
      "Experiment: Shortest path degree:HL\n",
      "0.00000\t0.3621497482\t89.625\t94.9\t0.4030995357592307\t0.7440691532092251\t0.01931814375\n",
      "Experiment: Shortest path degree:LH\n",
      "0.00000\t0.3671948073\t90.9\t94.825\t0.4133097487711659\t0.74464976647555\t0.008904224999999998\n",
      "Experiment: Strength weighted vertex degree:HL\n",
      "0.00000\t0.3624594856\t89.75\t94.75\t0.4060035567319361\t0.744943773833325\t0.0006749062499999999\n",
      "Experiment: Strength weighted vertex degree:LH\n",
      "0.00000\t0.3644839002\t90.225\t94.9\t0.40959176000684705\t0.74554421367095\t0.01107195\n",
      "Experiment: Stress centrality:HL\n",
      "0.00000\t0.3646810500\t90.25\t95.225\t0.40399807725026093\t0.74392353832755\t0.003663693749999998\n",
      "Experiment: Stress centrality:LH\n",
      "0.00000\t0.3636650594\t90.0\t94.775\t0.4133957536671541\t0.745203098929525\t0.014747431250000002\n",
      "Experiment: Subgraph:HL\n",
      "0.00000\t0.3653359529\t90.4\t95.1\t0.40287760415769275\t0.744436258128825\t-0.0003905812500000023\n",
      "Experiment: Subgraph:LH\n",
      "0.00000\t0.3632535536\t89.9\t94.75\t0.40039592773759525\t0.7442525688605001\t0.015896437500000003\n",
      "Experiment: Topological coefficient:HL\n",
      "0.00000\t0.3662593921\t90.65\t94.65\t0.4070810474067483\t0.744006041745725\t0.01073934375\n",
      "Experiment: Topological coefficient:LH\n",
      "0.00000\t0.3644630571\t90.25\t94.8\t0.4077147725982678\t0.7447327528211749\t0.002824893749999998\n",
      "WASTE metric\n",
      "   average = 0.0\n",
      "   min, max = 0.0 0.0\n",
      "   AA:random || \n",
      "CUT RATIO metric\n",
      "   average = 0.364770424037\n",
      "   min, max = 0.359007609588 0.370533923429\n",
      "   Decay centrality:HL || Eigenvector:LH\n",
      "EDGES CUT metric\n",
      "   average = 90.2843478261\n",
      "   min, max = 88.875 91.75\n",
      "   Decay centrality:HL || Eigenvector:LH\n",
      "TOTAL COMM VOLUME metric\n",
      "   average = 94.7867391304\n",
      "   min, max = 93.95 95.525\n",
      "   Network centrality:LH || Degree centrality:LH\n",
      "Qds metric\n",
      "   average = 0.407204250349\n",
      "   min, max = 0.399059048467 0.417637123213\n",
      "   Flow betweenness centrality:HL || LAC:LH\n",
      "LONELINESS metric\n",
      "   average = 0.744751087577\n",
      "   min, max = 0.742303644511 0.746524979584\n",
      "   Alpha:LH || MCC centrality:LH\n",
      "MAXPERM metric\n",
      "   average = 0.0081181423913\n",
      "   min, max = -0.0077726625 0.02027639375\n",
      "   Eccentricity:LH || Semi local centrality:HL\n"
     ]
    }
   ],
   "source": [
    "# analyse the results\n",
    "\n",
    "# find min/max for each score\n",
    "metrics = [\"WASTE\", \"CUT RATIO\", \"EDGES CUT\", \"TOTAL COMM VOLUME\", \"Qds\", \"LONELINESS\", \"MAXPERM\"]\n",
    "\n",
    "max_metric_centrality=[]\n",
    "min_metric_centrality=[]\n",
    "max_metric = []\n",
    "min_metric = []\n",
    "avg_metric = []\n",
    "#metric_sort_dataset = []\n",
    "for metric in metrics:\n",
    "    max_metric_centrality.append(\"\")\n",
    "    min_metric_centrality.append(\"\")\n",
    "    max_metric.append(0.0)\n",
    "    min_metric.append(10000000.0)\n",
    "    avg_metric.append(0.0)\n",
    "    metric_sort_dataset = {}\n",
    "\n",
    "avg_results = {}    \n",
    "for key in list(centralities.keys()):\n",
    "    centrality = centralities[key]\n",
    "    centralityCode = centrality.centralityType + \":\" + centrality.orderType\n",
    "    print(\"Experiment:\", centralityCode)\n",
    "\n",
    "    centrality.loadScores()\n",
    "    centrality.computeStatsScore()\n",
    "    avg_results[centralityCode] = centrality.avgScores\n",
    "\n",
    "    centrality.printScoreline(centrality.avgScores)\n",
    "\n",
    "    for i, metric in enumerate(centrality.avgScores):\n",
    "        if(max_metric[i] < metric):\n",
    "            max_metric[i] = metric\n",
    "            max_metric_centrality[i] = centralityCode\n",
    "        if(min_metric[i] > metric):\n",
    "            min_metric[i] = metric\n",
    "            min_metric_centrality[i] = centralityCode\n",
    "        avg_metric[i] = avg_metric[i] + metric\n",
    "        # index the score\n",
    "        #if metric in metric_sort_dataset[i]:\n",
    "        #    metric_sort_dataset[i][metric].append()\n",
    "\n",
    "with open(os.path.join(parametrized_config['OUTPUT_DIRECTORY'], \"centrality_scores.csv\"), 'w+') as f:\n",
    "    s = \"centrality\"\n",
    "    for metric in metrics:\n",
    "        s = s + \",\" + metric\n",
    "    f.write(s + \"\\n\")\n",
    "    \n",
    "    for key in list(avg_results.keys()):\n",
    "        line = key\n",
    "        for score in avg_results[key]:\n",
    "            line = line + \",\" + str(score)\n",
    "        f.write(line + \"\\n\")\n",
    "        \n",
    "for i, avg in enumerate(avg_metric):\n",
    "    avg_metric[i] = avg / len(centralities)\n",
    "            \n",
    "for i, metric in enumerate(metrics):\n",
    "    print(metric, \"metric\")\n",
    "    print(\"   average =\", avg_metric[i])\n",
    "    print(\"   min, max =\", min_metric[i], max_metric[i])\n",
    "    print(\"  \", min_metric_centrality[i], \"||\", max_metric_centrality[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y <- c(87.0,89.0,80.0,77.0,94.0,92.0,78.0,90.0,82.0,66.0,86.0,82.0,85.0,96.0,87.0,80.0,86.0,75.0,83.0,88.0,94.0,86.0,75.0,94.0,92.0,89.0,84.0,68.0,102.0,80.0,77.0,99.0,86.0,79.0,95.0,77.0,98.0,77.0,77.0,79.0,87.0,89.0,80.0,77.0,94.0,92.0,78.0,90.0,82.0,66.0,86.0,82.0,85.0,96.0,87.0,80.0,86.0,75.0,83.0,88.0,94.0,86.0,75.0,94.0,92.0,89.0,84.0,68.0,102.0,80.0,77.0,99.0,86.0,79.0,95.0,77.0,98.0,77.0,77.0,79.0,87.0,89.0,80.0,77.0,94.0,92.0,78.0,90.0,82.0,66.0,86.0,87.0,89.0,80.0,77.0,94.0,92.0,78.0,90.0,82.0,66.0,86.0,82.0,85.0,96.0,87.0,89.0,87.0,89.0,80.0,77.0,94.0,92.0,78.0,90.0,82.0,66.0,86.0,82.0,85.0,96.0,87.0,80.0,86.0,75.0,83.0,88.0,94.0,86.0,75.0,94.0,92.0,89.0,84.0,68.0,102.0,80.0,77.0,99.0,86.0,79.0,95.0,77.0,98.0,77.0,77.0,79.0,74.0,83.0,79.0,82.0,103.0,107.0,80.0,91.0,85.0,74.0,80.0,85.0,83.0,90.0,68.0,92.0,88.0,85.0,91.0,79.0,87.0,98.0,86.0,86.0,89.0,99.0,83.0,81.0,96.0,81.0,73.0,88.0,87.0,82.0,83.0,88.0,94.0,76.0,86.0,100.0,74.0,86.0,71.0,86.0,75.0,91.0,91.0,76.0,87.0,90.0,73.0,84.0,83.0,76.0,89.0,72.0,80.0,83.0,74.0,87.0,80.0,75.0,96.0,77.0,86.0,82.0,85.0,85.0,77.0,99.0,88.0,78.0,90.0,71.0,82.0,81.0,76.0,87.0,77.0,78.0,81.0,86.0,80.0,78.0,96.0,87.0,99.0,99.0,92.0,97.0,79.0,65.0,75.0,99.0,78.0,101.0,84.0,91.0,89.0,85.0,93.0,79.0,97.0,88.0,77.0,92.0,96.0,102.0,87.0,76.0,99.0,81.0,103.0,104.0,85.0,90.0,88.0,82.0,99.0,81.0,92.0,99.0,80.0,87.0,85.0,78.0,76.0,91.0,87.0,74.0,86.0,94.0,64.0,86.0,89.0,82.0,86.0,71.0,81.0,95.0,87.0,85.0,81.0,76.0,84.0,83.0,85.0,90.0,84.0,92.0,86.0,100.0,81.0,86.0,91.0,79.0,79.0,81.0,82.0,89.0,78.0,78.0,80.0,87.0,80.0,87.0,83.0,74.0,97.0,87.0,76.0,89.0,94.0,69.0,86.0,89.0,80.0,88.0,71.0,79.0,98.0,73.0,87.0,85.0,75.0,84.0,79.0,88.0,90.0,84.0,78.0,78.0,105.0,82.0,85.0,91.0,83.0,76.0,82.0,78.0,89.0,91.0,77.0,94.0,80.0,77.0,81.0,90.0,92.0,109.0,98.0,77.0,90.0,92.0,86.0,78.0,80.0,84.0,87.0,75.0,86.0,93.0,88.0,98.0,84.0,90.0,86.0,81.0,96.0,87.0,99.0,94.0,77.0,106.0,104.0,88.0,97.0,91.0,81.0,85.0,85.0,106.0,81.0,86.0,84.0,77.0,84.0,77.0,79.0,74.0,93.0,93.0,81.0,83.0,96.0,67.0,77.0,82.0,78.0,91.0,65.0,86.0,89.0,74.0,83.0,85.0,77.0,89.0,78.0,83.0,86.0,86.0,77.0,75.0,88.0,89.0,82.0,92.0,85.0,82.0,90.0,86.0,92.0,72.0,78.0,81.0,84.0,76.0,91.0,78.0,79.0,105.0,97.0,93.0,96.0,93.0,74.0,83.0,87.0,90.0,91.0,82.0,76.0,84.0,86.0,99.0,82.0,85.0,82.0,80.0,92.0,91.0,109.0,79.0,75.0,98.0,79.0,105.0,95.0,87.0,88.0,86.0,96.0,97.0,99.0,77.0,80.0,76.0,79.0,75.0,76.0,75.0,97.0,94.0,75.0,81.0,81.0,67.0,76.0,84.0,76.0,92.0,67.0,71.0,96.0,71.0,87.0,83.0,73.0,84.0,82.0,93.0,87.0,87.0,82.0,70.0,92.0,81.0,69.0,90.0,70.0,85.0,77.0,72.0,97.0,90.0,74.0,78.0,79.0,82.0,72.0,83.0,79.0,89.0,94.0,91.0,85.0,96.0,73.0,86.0,96.0,82.0,94.0,72.0,76.0,91.0,87.0,93.0,97.0,87.0,90.0,88.0,93.0,81.0,91.0,84.0,79.0,96.0,87.0,86.0,90.0,75.0,82.0,98.0,85.0,92.0,91.0,75.0,79.0,82.0,79.0,79.0,89.0,73.0,112.0,96.0,76.0,87.0,96.0,75.0,78.0,93.0,84.0,91.0,73.0,87.0,95.0,79.0,89.0,77.0,87.0,87.0,77.0,84.0,94.0,96.0,82.0,72.0,102.0,79.0,74.0,95.0,82.0,86.0,86.0,87.0,94.0,91.0,79.0,80.0,79.0,76.0,77.0,86.0,78.0,91.0,102.0,88.0,85.0,90.0,64.0,77.0,84.0,81.0,88.0,62.0,83.0,88.0,75.0,95.0,87.0,81.0,98.0,82.0,87.0,90.0,95.0,84.0,80.0,101.0,76.0,81.0,99.0,74.0,85.0,81.0,84.0,96.0,82.0,81.0,84.0,76.0,86.0,74.0,87.0,78.0,97.0,97.0,84.0,84.0,79.0,68.0,85.0,87.0,80.0,87.0,69.0,84.0,81.0,81.0,92.0,95.0,72.0,83.0,76.0,87.0,98.0,85.0,83.0,81.0,101.0,87.0,84.0,87.0,72.0,88.0,84.0,81.0,87.0,82.0,82.0,89.0,86.0,85.0,74.0,79.0,70.0,111.0,99.0,71.0,103.0,97.0,100.0,77.0,93.0,79.0,97.0,65.0,90.0,97.0,76.0,91.0,93.0,78.0,90.0,84.0,93.0,86.0,96.0,91.0,98.0,107.0,78.0,76.0,108.0,72.0,96.0,100.0,91.0,101.0,77.0,79.0,90.0,85.0,80.0,87.0,83.0,74.0,97.0,87.0,76.0,89.0,94.0,69.0,86.0,89.0,80.0,88.0,71.0,79.0,98.0,73.0,87.0,85.0,75.0,84.0,79.0,88.0,90.0,84.0,78.0,78.0,105.0,82.0,85.0,91.0,83.0,76.0,82.0,78.0,89.0,91.0,77.0,94.0,80.0,77.0,81.0,90.0,92.0,109.0,98.0,77.0,90.0,92.0,86.0,78.0,80.0,84.0,87.0,75.0,86.0,93.0,88.0,98.0,84.0,90.0,86.0,81.0,96.0,87.0,99.0,94.0,77.0,106.0,104.0,88.0,97.0,91.0,81.0,85.0,85.0,106.0,81.0,86.0,84.0,77.0,92.0,78.0,87.0,74.0,92.0,89.0,81.0,83.0,95.0,63.0,86.0,92.0,77.0,86.0,74.0,79.0,92.0,86.0,86.0,84.0,74.0,88.0,80.0,84.0,90.0,86.0,80.0,84.0,88.0,79.0,83.0,96.0,80.0,82.0,76.0,81.0,87.0,76.0,75.0,86.0,92.0,91.0,94.0,89.0,80.0,95.0,95.0,85.0,87.0,95.0,77.0,81.0,90.0,94.0,89.0,70.0,84.0,97.0,75.0,88.0,86.0,86.0,91.0,79.0,106.0,81.0,97.0,111.0,84.0,106.0,88.0,94.0,96.0,73.0,89.0,87.0,83.0,91.0,98.0,84.0,82.0,91.0,80.0,89.0,90.0,71.0,98.0,94.0,82.0,91.0,90.0,72.0,82.0,87.0,82.0,89.0,70.0,88.0,91.0,83.0,91.0,87.0,93.0,93.0,76.0,94.0,88.0,85.0,82.0,76.0,94.0,85.0,79.0,98.0,74.0,92.0,84.0,79.0,93.0,85.0,78.0,92.0,80.0,87.0,93.0,83.0,87.0,108.0,97.0,104.0,82.0,88.0,93.0,95.0,94.0,88.0,88.0,76.0,90.0,92.0,75.0,99.0,93.0,88.0,90.0,75.0,97.0,85.0,99.0,100.0,72.0,97.0,100.0,77.0,89.0,76.0,78.0,101.0,90.0,97.0,99.0,81.0,98.0,87.0,82.0,76.0,99.0,70.0,101.0,91.0,82.0,91.0,83.0,67.0,84.0,94.0,78.0,89.0,68.0,85.0,94.0,81.0,86.0,82.0,78.0,83.0,71.0,89.0,82.0,84.0,80.0,74.0,86.0,76.0,77.0,98.0,78.0,82.0,80.0,79.0,94.0,84.0,77.0,79.0,82.0,81.0,79.0,99.0,78.0,93.0,94.0,87.0,96.0,92.0,94.0,92.0,94.0,79.0,90.0,65.0,90.0,97.0,72.0,102.0,89.0,96.0,92.0,75.0,89.0,93.0,90.0,96.0,104.0,89.0,86.0,73.0,96.0,79.0,93.0,77.0,80.0,92.0,80.0,82.0,98.0,81.0,72.0,75.0,85.0,70.0,93.0,95.0,82.0,84.0,82.0,88.0,84.0,94.0,81.0,89.0,71.0,75.0,91.0,82.0,94.0,88.0,80.0,83.0,68.0,91.0,90.0,96.0,86.0,78.0,97.0,81.0,80.0,92.0,81.0,87.0,80.0,79.0,94.0,84.0,76.0,89.0,72.0,80.0,72.0,98.0,79.0,101.0,101.0,93.0,85.0,88.0,77.0,88.0,92.0,79.0,94.0,71.0,90.0,97.0,82.0,92.0,91.0,105.0,89.0,88.0,98.0,100.0,94.0,96.0,89.0,94.0,80.0,97.0,103.0,72.0,76.0,79.0,79.0,98.0,91.0,82.0,80.0,80.0,88.0,85.0,99.0,88.0,108.0,88.0,85.0,95.0,83.0,69.0,87.0,94.0,79.0,94.0,90.0,95.0,84.0,83.0,97.0,96.0,91.0,83.0,83.0,96.0,90.0,90.0,91.0,83.0,93.0,100.0,105.0,95.0,78.0,86.0,84.0,88.0,102.0,82.0,72.0,85.0,88.0,80.0,74.0,79.0,77.0,105.0,87.0,91.0,89.0,88.0,75.0,83.0,86.0,92.0,87.0,67.0,85.0,90.0,87.0,82.0,84.0,90.0,84.0,80.0,93.0,111.0,95.0,87.0,77.0,106.0,82.0,89.0,103.0,73.0,88.0,91.0,87.0,92.0,77.0,83.0,84.0,80.0,87.0,81.0,95.0,70.0,111.0,98.0,86.0,95.0,86.0,86.0,81.0,90.0,88.0,105.0,68.0,93.0,94.0,92.0,96.0,87.0,99.0,88.0,87.0,96.0,95.0,99.0,80.0,85.0,97.0,87.0,76.0,98.0,84.0,95.0,93.0,99.0,106.0,84.0,87.0,95.0,87.0,81.0,74.0,98.0,79.0,90.0,97.0,88.0,85.0,88.0,77.0,89.0,89.0,81.0,92.0,63.0,84.0,83.0,82.0,88.0,86.0,75.0,83.0,79.0,85.0,89.0,91.0,97.0,78.0,89.0,78.0,89.0,86.0,81.0,78.0,85.0,84.0,92.0,78.0,78.0,81.0,81.0,83.0,79.0,75.0,77.0,97.0,88.0,76.0,83.0,93.0,73.0,79.0,89.0,79.0,95.0,67.0,84.0,92.0,75.0,78.0,94.0,79.0,86.0,78.0,93.0,95.0,87.0,99.0,82.0,92.0,78.0,79.0,102.0,77.0,95.0,76.0,91.0,91.0,91.0,83.0,84.0,83.0,89.0,94.0,91.0,83.0,111.0,100.0,82.0,97.0,91.0,95.0,87.0,90.0,81.0,99.0,75.0,81.0,83.0,82.0,89.0,79.0,95.0,97.0,81.0,88.0,87.0,85.0,85.0,83.0,93.0,90.0,74.0,93.0,78.0,96.0,88.0,85.0,93.0,96.0,88.0,86.0,89.0,87.0,79.0,97.0,78.0,92.0,90.0,75.0,81.0,89.0,64.0,86.0,88.0,83.0,88.0,70.0,89.0,89.0,68.0,92.0,93.0,75.0,80.0,80.0,82.0,91.0,96.0,89.0,79.0,88.0,76.0,82.0,91.0,81.0,81.0,85.0,83.0,83.0,95.0,75.0,89.0,87.0,79.0,78.0,78.0,83.0,109.0,98.0,83.0,89.0,98.0,66.0,79.0,91.0,93.0,93.0,64.0,94.0,94.0,91.0,89.0,81.0,93.0,86.0,82.0,99.0,95.0,94.0,85.0,88.0,90.0,99.0,82.0,104.0,75.0,91.0,92.0,84.0,91.0,96.0,81.0,92.0,79.0,87.0,79.0,97.0,78.0,92.0,90.0,75.0,81.0,89.0,64.0,86.0,88.0,83.0,88.0,70.0,89.0,89.0,68.0,92.0,93.0,75.0,80.0,80.0,82.0,91.0,96.0,89.0,79.0,88.0,76.0,82.0,91.0,81.0,81.0,85.0,83.0,83.0,95.0,75.0,89.0,87.0,79.0,78.0,78.0,83.0,109.0,98.0,83.0,89.0,98.0,66.0,79.0,91.0,93.0,93.0,64.0,94.0,94.0,91.0,89.0,81.0,93.0,86.0,82.0,99.0,95.0,94.0,85.0,88.0,90.0,99.0,82.0,104.0,75.0,91.0,92.0,84.0,91.0,96.0,81.0,92.0,79.0,85.0,77.0,83.0,74.0,101.0,89.0,81.0,82.0,92.0,75.0,83.0,85.0,74.0,86.0,65.0,87.0,96.0,79.0,87.0,89.0,75.0,84.0,75.0,92.0,95.0,90.0,91.0,90.0,90.0,79.0,80.0,98.0,71.0,81.0,93.0,84.0,93.0,83.0,86.0,82.0,85.0,75.0,95.0,86.0,93.0,92.0,94.0,89.0,92.0,92.0,68.0,82.0,96.0,86.0,89.0,69.0,79.0,94.0,94.0,87.0,84.0,85.0,81.0,85.0,92.0,88.0,104.0,85.0,91.0,102.0,80.0,74.0,96.0,70.0,89.0,86.0,78.0,93.0,91.0,79.0,80.0,75.0,86.0,78.0,91.0,73.0,85.0,94.0,81.0,90.0,96.0,63.0,80.0,93.0,85.0,85.0,65.0,87.0,92.0,85.0,92.0,92.0,79.0,82.0,80.0,86.0,98.0,87.0,94.0,80.0,99.0,90.0,83.0,88.0,82.0,86.0,79.0,77.0,94.0,87.0,86.0,83.0,86.0,71.0,89.0,83.0,73.0,89.0,97.0,102.0,85.0,92.0,73.0,94.0,88.0,93.0,101.0,76.0,96.0,89.0,92.0,98.0,89.0,96.0,95.0,80.0,84.0,88.0,101.0,97.0,80.0,95.0,76.0,85.0,91.0,71.0,95.0,93.0,86.0,95.0,76.0,87.0,85.0,71.0,76.0,77.0,80.0,77.0,102.0,98.0,82.0,90.0,85.0,69.0,77.0,88.0,96.0,88.0,67.0,83.0,91.0,76.0,88.0,91.0,92.0,89.0,79.0,94.0,86.0,91.0,100.0,72.0,95.0,78.0,97.0,96.0,78.0,92.0,85.0,87.0,91.0,90.0,88.0,91.0,76.0,89.0,77.0,76.0,78.0,97.0,86.0,87.0,95.0,87.0,67.0,86.0,86.0,89.0,88.0,71.0,87.0,95.0,84.0,92.0,78.0,73.0,87.0,82.0,86.0,90.0,83.0,82.0,92.0,92.0,92.0,92.0,100.0,76.0,87.0,106.0,80.0,98.0,82.0,82.0,90.0,89.0,95.0,77.0,82.0,86.0,111.0,101.0,81.0,94.0,94.0,71.0,95.0,86.0,86.0,91.0,66.0,76.0,90.0,82.0,81.0,79.0,87.0,98.0,84.0,86.0,90.0,94.0,102.0,73.0,91.0,91.0,78.0,88.0,88.0,93.0,106.0,85.0,92.0,77.0,80.0,93.0,95.0,90.0,74.0,94.0,84.0,96.0,99.0,83.0,88.0,88.0,63.0,88.0,93.0,81.0,100.0,74.0,83.0,89.0,79.0,93.0,89.0,78.0,83.0,69.0,94.0,96.0,93.0,94.0,74.0,89.0,99.0,76.0,87.0,85.0,81.0,86.0,83.0,97.0,71.0,89.0,83.0,90.0,80.0,72.0,89.0,77.0,97.0,93.0,79.0,84.0,82.0,73.0,77.0,89.0,80.0,87.0,63.0,78.0,90.0,81.0,83.0,87.0,85.0,85.0,76.0,91.0,82.0,87.0,83.0,78.0,87.0,80.0,86.0,99.0,83.0,80.0,83.0,77.0,91.0,86.0,84.0,78.0,80.0,83.0,81.0,91.0,82.0,110.0,107.0,90.0,90.0,81.0,71.0,92.0,88.0,87.0,81.0,72.0,84.0,92.0,94.0,84.0,80.0,91.0,85.0,80.0,86.0,88.0,95.0,94.0,79.0,106.0,76.0,75.0,100.0,73.0,91.0,93.0,88.0,91.0,83.0,75.0,98.0,83.0,84.0,89.0,94.0,72.0,91.0,93.0,89.0,83.0,96.0,69.0,82.0,86.0,84.0,87.0,66.0,71.0,85.0,85.0,94.0,87.0,75.0,82.0,75.0,82.0,91.0,84.0,77.0,71.0,89.0,77.0,88.0,88.0,71.0,85.0,77.0,81.0,87.0,76.0,76.0,84.0,84.0,88.0,90.0,102.0,95.0,106.0,98.0,86.0,92.0,101.0,71.0,86.0,95.0,88.0,98.0,65.0,86.0,88.0,97.0,98.0,98.0,86.0,87.0,81.0,89.0,101.0,103.0,90.0,76.0,99.0,96.0,93.0,96.0,82.0,94.0,105.0,88.0,109.0,102.0,90.0,87.0,88.0,74.0,81.0,88.0,81.0,97.0,93.0,92.0,92.0,87.0,79.0,90.0,100.0,78.0,97.0,81.0,78.0,95.0,84.0,84.0,85.0,84.0,94.0,78.0,99.0,103.0,89.0,97.0,90.0,98.0,87.0,87.0,96.0,75.0,81.0,84.0,87.0,91.0,81.0,76.0,94.0,74.0,88.0,80.0,81.0,80.0,98.0,98.0,79.0,91.0,75.0,80.0,81.0,92.0,89.0,95.0,67.0,86.0,82.0,78.0,90.0,87.0,82.0,84.0,78.0,91.0,85.0,93.0,85.0,76.0,92.0,80.0,76.0,91.0,75.0,91.0,92.0,83.0,95.0,95.0,83.0,104.0,88.0,88.0,86.0,76.0,87.0,95.0,94.0,85.0,82.0,82.0,63.0,88.0,91.0,74.0,94.0,70.0,78.0,90.0,78.0,89.0,94.0,86.0,88.0,80.0,94.0,83.0,90.0,88.0,75.0,98.0,90.0,84.0,95.0,77.0,83.0,81.0,90.0,91.0,92.0,80.0,96.0,88.0,79.0,81.0,91.0,80.0,117.0,97.0,91.0,87.0,99.0,68.0,96.0,87.0,85.0,94.0,70.0,93.0,94.0,85.0,97.0,99.0,85.0,89.0,79.0,111.0,95.0,83.0,80.0,83.0,93.0,91.0,95.0,95.0,72.0,89.0,92.0,82.0,99.0,87.0,81.0,85.0,79.0,77.0,76.0,89.0,72.0,87.0,97.0,77.0,87.0,88.0,76.0,84.0,88.0,82.0,92.0,69.0,80.0,85.0,77.0,90.0,92.0,92.0,98.0,80.0,81.0,80.0,84.0,86.0,73.0,91.0,89.0,82.0,89.0,75.0,90.0,84.0,86.0,91.0,77.0,78.0,83.0,77.0,86.0,82.0,83.0,75.0,100.0,95.0,75.0,95.0,80.0,79.0,94.0,95.0,82.0,93.0,71.0,84.0,90.0,81.0,98.0,86.0,73.0,85.0,71.0,94.0,90.0,86.0,82.0,88.0,96.0,81.0,85.0,103.0,92.0,100.0,85.0,88.0,91.0,80.0,72.0,85.0,86.0,83.0,79.0,75.0,77.0,97.0,88.0,76.0,83.0,93.0,73.0,79.0,89.0,79.0,95.0,67.0,84.0,92.0,75.0,78.0,94.0,79.0,86.0,78.0,93.0,95.0,87.0,99.0,82.0,92.0,78.0,79.0,102.0,77.0,95.0,76.0,91.0,91.0,91.0,83.0,84.0,83.0,89.0,94.0,91.0,83.0,111.0,100.0,82.0,97.0,91.0,95.0,87.0,90.0,81.0,99.0,75.0,81.0,83.0,82.0,89.0,79.0,95.0,97.0,81.0,88.0,87.0,85.0,85.0,83.0,93.0,90.0,74.0,93.0,78.0,96.0,88.0,85.0,93.0,96.0,88.0,86.0,89.0,84.0,89.0,94.0,72.0,91.0,93.0,89.0,83.0,96.0,69.0,82.0,86.0,84.0,87.0,66.0,71.0,85.0,85.0,94.0,87.0,75.0,82.0,75.0,82.0,91.0,84.0,77.0,71.0,89.0,77.0,88.0,88.0,71.0,85.0,77.0,81.0,87.0,76.0,76.0,84.0,84.0,88.0,90.0,102.0,95.0,106.0,98.0,86.0,92.0,101.0,71.0,86.0,95.0,88.0,98.0,65.0,86.0,88.0,97.0,98.0,98.0,86.0,87.0,81.0,89.0,101.0,103.0,90.0,76.0,99.0,96.0,93.0,96.0,82.0,94.0,105.0,88.0,109.0,94.0,90.0,87.0,88.0,76.0,74.0,92.0,73.0,100.0,93.0,82.0,82.0,86.0,79.0,86.0,89.0,86.0,91.0,66.0,85.0,86.0,76.0,84.0,84.0,79.0,88.0,78.0,92.0,92.0,94.0,94.0,86.0,90.0,85.0,81.0,85.0,75.0,79.0,92.0,77.0,99.0,89.0,78.0,83.0,76.0,79.0,97.0,81.0,81.0,100.0,91.0,86.0,90.0,87.0,88.0,90.0,102.0,82.0,92.0,84.0,88.0,84.0,93.0,90.0,90.0,89.0,97.0,85.0,93.0,101.0,91.0,106.0,91.0,93.0,93.0,98.0,97.0,71.0,85.0,93.0,83.0,98.0,90.0,86.0,86.0,79.0,85.0,80.0,72.0,74.0,89.0,105.0,81.0,87.0,94.0,78.0,90.0,89.0,77.0,86.0,68.0,80.0,94.0,80.0,86.0,90.0,74.0,85.0,80.0,80.0,96.0,86.0,79.0,69.0,90.0,79.0,80.0,94.0,80.0,87.0,76.0,82.0,95.0,86.0,79.0,83.0,85.0,81.0,82.0,88.0,71.0,106.0,92.0,88.0,90.0,95.0,70.0,79.0,89.0,73.0,88.0,67.0,93.0,105.0,90.0,92.0,93.0,73.0,85.0,87.0,98.0,95.0,92.0,87.0,87.0,97.0,88.0,88.0,105.0,84.0,101.0,81.0,83.0,92.0,94.0,76.0,94.0,81.0,82.0,79.0,77.0,72.0,97.0,93.0,76.0,85.0,83.0,65.0,80.0,89.0,74.0,89.0,63.0,78.0,90.0,78.0,86.0,87.0,76.0,94.0,77.0,88.0,86.0,84.0,84.0,77.0,87.0,80.0,85.0,94.0,78.0,90.0,86.0,86.0,92.0,94.0,88.0,81.0,82.0,92.0,74.0,97.0,80.0,100.0,89.0,84.0,87.0,83.0,74.0,86.0,86.0,79.0,91.0,67.0,95.0,84.0,71.0,93.0,85.0,83.0,88.0,72.0,98.0,83.0,93.0,101.0,77.0,94.0,87.0,86.0,87.0,70.0,93.0,87.0,80.0,93.0,88.0,83.0,84.0,92.0,80.0,87.0,83.0,74.0,97.0,87.0,76.0,89.0,94.0,69.0,86.0,89.0,80.0,88.0,71.0,79.0,98.0,73.0,87.0,85.0,75.0,84.0,79.0,88.0,90.0,84.0,78.0,78.0,105.0,82.0,85.0,91.0,83.0,76.0,82.0,78.0,89.0,91.0,77.0,94.0,80.0,77.0,81.0,90.0,92.0,109.0,98.0,77.0,90.0,92.0,86.0,78.0,80.0,84.0,87.0,75.0,86.0,93.0,88.0,98.0,84.0,90.0,86.0,81.0,96.0,87.0,99.0,94.0,77.0,106.0,104.0,88.0,97.0,91.0,81.0,85.0,85.0,106.0,81.0,86.0,84.0,77.0,89.0,73.0,82.0,69.0,96.0,87.0,86.0,82.0,94.0,68.0,76.0,85.0,82.0,97.0,65.0,91.0,90.0,85.0,85.0,89.0,75.0,85.0,81.0,87.0,85.0,86.0,78.0,69.0,84.0,86.0,89.0,99.0,86.0,82.0,80.0,87.0,93.0,88.0,82.0,78.0,89.0,82.0,87.0,95.0,90.0,96.0,83.0,76.0,100.0,93.0,68.0,86.0,86.0,86.0,85.0,90.0,84.0,95.0,79.0,87.0,81.0,87.0,84.0,81.0,97.0,85.0,100.0,100.0,86.0,110.0,81.0,99.0,95.0,83.0,83.0,89.0,83.0,93.0,93.0,80.0,82.0,82.0,87.0,76.0,88.0,82.0,93.0,92.0,82.0,87.0,87.0,79.0,84.0,89.0,75.0,92.0,64.0,85.0,87.0,73.0,91.0,88.0,76.0,92.0,77.0,84.0,86.0,85.0,96.0,89.0,99.0,76.0,74.0,91.0,74.0,92.0,83.0,89.0,94.0,81.0,84.0,87.0,87.0,97.0,83.0,80.0,83.0,102.0,103.0,93.0,90.0,103.0,61.0,89.0,90.0,87.0,90.0,64.0,86.0,90.0,81.0,86.0,96.0,94.0,99.0,76.0,96.0,90.0,92.0,86.0,100.0,92.0,94.0,81.0,93.0,80.0,97.0,83.0,80.0,83.0,102.0,103.0,93.0,90.0,86.0,88.0,82.0,82.0,100.0,96.0,93.0,86.0,89.0,79.0,86.0,86.0,76.0,92.0,71.0,81.0,97.0,83.0,83.0,79.0,81.0,97.0,77.0,109.0,84.0,95.0,88.0,69.0,93.0,79.0,81.0,101.0,84.0,81.0,88.0,84.0,93.0,80.0,86.0,83.0,80.0,75.0,82.0,89.0,105.0,100.0,86.0,89.0,88.0,65.0,82.0,92.0,92.0,92.0,65.0,83.0,90.0,78.0,87.0,88.0,81.0,96.0,80.0,89.0,90.0,87.0,89.0,77.0,91.0,86.0,73.0,95.0,85.0,92.0,93.0,85.0,98.0,76.0,78.0,84.0,79.0,90.0,82.0,84.0,106.0,102.0,86.0,91.0,84.0,71.0,76.0,92.0,77.0,86.0,62.0,88.0,89.0,86.0,80.0,89.0,89.0,100.0,77.0,100.0,89.0,98.0,88.0,92.0,102.0,79.0,76.0,101.0,78.0,91.0,77.0,75.0,97.0,90.0,78.0,93.0,91.0,69.0,91.0,68.0,98.0,105.0,81.0,89.0,78.0,70.0,83.0,92.0,83.0,97.0,70.0,87.0,93.0,93.0,90.0,75.0,75.0,84.0,74.0,104.0,84.0,95.0,82.0,94.0,98.0,88.0,97.0,98.0,76.0,93.0,92.0,89.0,105.0,90.0,73.0,89.0,83.0,79.0,79.0,77.0,97.0,87.0,76.0,84.0,93.0,69.0,85.0,87.0,80.0,92.0,67.0,81.0,91.0,83.0,87.0,93.0,80.0,85.0,83.0,93.0,98.0,87.0,97.0,81.0,89.0,78.0,86.0,102.0,77.0,95.0,74.0,86.0,91.0,91.0,78.0,84.0,75.0,77.0,89.0,85.0,105.0,94.0,82.0,100.0,91.0,82.0,82.0,86.0,83.0,92.0,67.0,92.0,82.0,86.0,86.0,97.0,95.0,87.0,72.0,95.0,81.0,93.0,99.0,94.0,93.0,91.0,79.0,99.0,76.0,96.0,76.0,79.0,89.0,85.0,85.0,86.0,81.0,82.0,89.0,72.0,93.0,97.0,84.0,84.0,86.0,63.0,82.0,94.0,81.0,87.0,64.0,78.0,85.0,77.0,83.0,89.0,77.0,82.0,76.0,95.0,88.0,81.0,92.0,92.0,90.0,80.0,88.0,85.0,75.0,80.0,88.0,89.0,93.0,73.0,77.0,80.0,87.0,73.0,99.0,84.0,106.0,94.0,91.0,96.0,89.0,66.0,75.0,90.0,90.0,92.0,65.0,83.0,106.0,80.0,91.0,96.0,99.0,101.0,67.0,89.0,97.0,93.0,85.0,85.0,98.0,89.0,88.0,99.0,87.0,93.0,93.0,83.0,101.0,80.0,83.0,102.0,85.0,76.0,80.0,71.0,88.0,89.0,88.0,84.0,91.0,64.0,85.0,86.0,80.0,90.0,75.0,83.0,82.0,73.0,89.0,84.0,89.0,83.0,68.0,91.0,91.0,81.0,81.0,83.0,97.0,81.0,78.0,96.0,72.0,91.0,75.0,82.0,89.0,77.0,75.0,79.0,88.0,98.0,87.0,79.0,102.0,92.0,91.0,96.0,93.0,70.0,78.0,96.0,89.0,98.0,77.0,86.0,89.0,81.0,89.0,92.0,92.0,89.0,75.0,96.0,88.0,104.0,108.0,90.0,104.0,93.0,84.0,97.0,82.0,84.0,85.0,85.0,97.0,79.0,80.0,86.0,80.0,81.0,95.0,95.0,110.0,96.0,75.0,90.0,89.0,73.0,87.0,91.0,97.0,93.0,80.0,84.0,97.0,79.0,96.0,83.0,90.0,97.0,85.0,87.0,99.0,92.0,99.0,85.0,102.0,91.0,96.0,98.0,78.0,90.0,93.0,89.0,96.0,85.0,81.0,84.0,83.0,73.0,93.0,95.0,101.0,89.0,99.0,92.0,80.0,69.0,88.0,85.0,83.0,104.0,69.0,84.0,91.0,91.0,89.0,78.0,84.0,81.0,72.0,99.0,100.0,103.0,90.0,83.0,91.0,95.0,71.0,92.0,76.0,91.0,85.0,85.0,95.0,90.0,76.0,82.0,71.0,81.0,80.0,75.0,90.0,99.0,76.0,85.0,88.0,68.0,79.0,94.0,75.0,86.0,64.0,86.0,95.0,84.0,88.0,83.0,79.0,82.0,79.0,84.0,89.0,93.0,90.0,80.0,91.0,78.0,92.0,97.0,72.0,78.0,87.0,80.0,96.0,76.0,79.0,74.0,83.0,90.0,88.0,71.0,120.0,101.0,100.0,104.0,98.0,67.0,82.0,89.0,89.0,87.0,99.0,89.0,92.0,89.0,95.0,75.0,101.0,90.0,76.0,100.0,95.0,98.0,77.0,75.0,107.0,80.0,107.0,96.0,76.0,91.0,91.0,90.0,96.0,96.0,84.0,102.0,86.0,80.0,86.0,71.0,92.0,99.0,82.0,87.0,81.0,74.0,79.0,90.0,78.0,91.0,70.0,88.0,82.0,75.0,91.0,94.0,75.0,86.0,68.0,86.0,85.0,92.0,83.0,81.0,98.0,87.0,84.0,98.0,72.0,91.0,84.0,76.0,101.0,87.0,80.0,83.0,90.0,86.0,93.0,76.0,96.0,93.0,85.0,91.0,95.0,76.0,82.0,98.0,91.0,93.0,80.0,78.0,96.0,78.0,93.0,83.0,90.0,87.0,66.0,94.0,86.0,88.0,107.0,81.0,102.0,83.0,78.0,95.0,74.0,85.0,88.0,91.0,93.0,84.0,71.0,79.0,90.0,88.0,85.0,79.0,93.0,88.0,86.0,87.0,84.0,73.0,72.0,91.0,80.0,88.0,64.0,81.0,85.0,80.0,89.0,78.0,76.0,83.0,69.0,96.0,84.0,90.0,88.0,73.0,95.0,79.0,98.0,99.0,93.0,94.0,84.0,80.0,106.0,89.0,86.0,81.0,87.0,87.0,82.0,85.0,97.0,95.0,88.0,92.0,79.0,79.0,78.0,87.0,88.0,87.0,78.0,83.0,89.0,87.0,95.0,86.0,101.0,98.0,74.0,96.0,91.0,101.0,82.0,76.0,100.0,78.0,88.0,91.0,67.0,86.0,98.0,88.0,102.0,92.0,78.0,81.0,83.0,76.0,80.0,68.0,90.0,97.0,85.0,88.0,90.0,69.0,79.0,87.0,79.0,89.0,65.0,79.0,91.0,72.0,89.0,81.0,78.0,82.0,84.0,88.0,91.0,88.0,79.0,72.0,96.0,76.0,81.0,81.0,70.0,75.0,89.0,90.0,99.0,85.0,83.0,90.0,81.0,81.0,100.0,84.0,95.0,99.0,91.0,88.0,81.0,93.0,95.0,88.0,92.0,96.0,72.0,80.0,82.0,94.0,81.0,91.0,87.0,85.0,86.0,90.0,83.0,101.0,97.0,91.0,102.0,79.0,75.0,102.0,74.0,83.0,99.0,87.0,103.0,91.0,70.0,93.0,84.0,82.0,91.0,77.0,103.0,98.0,76.0,86.0,86.0,70.0,87.0,88.0,82.0,85.0,74.0,88.0,97.0,93.0,81.0,78.0,97.0,87.0,80.0,95.0,82.0,84.0,102.0,82.0,95.0,91.0,85.0,98.0,78.0,91.0,80.0,85.0,96.0,89.0,75.0,77.0,82.0,71.0,86.0,73.0,96.0,90.0,80.0,82.0,79.0,68.0,81.0,95.0,77.0,84.0,82.0,77.0,93.0,69.0,100.0,74.0,76.0,85.0,72.0,87.0,99.0,89.0,80.0,73.0,98.0,81.0,79.0,94.0,73.0,90.0,88.0,79.0,88.0,77.0,84.0,83.0,80.0,87.0,83.0,74.0,97.0,87.0,76.0,89.0,94.0,69.0,86.0,89.0,80.0,88.0,71.0,79.0,98.0,73.0,87.0,85.0,75.0,84.0,79.0,88.0,90.0,84.0,78.0,78.0,105.0,82.0,85.0,91.0,83.0,76.0,82.0,78.0,89.0,91.0,77.0,94.0,77.0,81.0,90.0,92.0,109.0,98.0,77.0,90.0,92.0,86.0,78.0,80.0,84.0,87.0,75.0,86.0,93.0,88.0,98.0,84.0,90.0,86.0,81.0,96.0,87.0,99.0,94.0,77.0,106.0,104.0,88.0,97.0,91.0,81.0,85.0,85.0,106.0,81.0,86.0,84.0,85.0,82.0,77.0,79.0,101.0,92.0,77.0,81.0,90.0,64.0,83.0,95.0,81.0,94.0,64.0,81.0,94.0,80.0,92.0,86.0,86.0,86.0,75.0,92.0,85.0,87.0,87.0,80.0,92.0,82.0,90.0,89.0,68.0,84.0,81.0,87.0,94.0,86.0,80.0,79.0,78.0,74.0,99.0,70.0,104.0,94.0,75.0,89.0,91.0,86.0,88.0,96.0,79.0,95.0,70.0,92.0,102.0,89.0,88.0,93.0,88.0,85.0,84.0,99.0,90.0,100.0,96.0,76.0,96.0,90.0,79.0,93.0,87.0,87.0,79.0,91.0,90.0,82.0,77.0,88.0,83.0,79.0,79.0,77.0,97.0,87.0,76.0,84.0,93.0,69.0,85.0,87.0,80.0,92.0,67.0,81.0,91.0,83.0,87.0,93.0,80.0,85.0,83.0,93.0,98.0,87.0,97.0,81.0,89.0,78.0,86.0,102.0,77.0,95.0,74.0,86.0,91.0,91.0,78.0,84.0,75.0,77.0,89.0,85.0,105.0,94.0,82.0,100.0,91.0,82.0,82.0,86.0,83.0,92.0,67.0,92.0,82.0,86.0,86.0,97.0,95.0,87.0,72.0,95.0,81.0,93.0,99.0,94.0,93.0,91.0,79.0,99.0,76.0,96.0,76.0,79.0,89.0,85.0,85.0,86.0,78.0,74.0,88.0,71.0,99.0,99.0,75.0,87.0,83.0,65.0,77.0,93.0,87.0,87.0,72.0,82.0,91.0,89.0,86.0,93.0,85.0,83.0,79.0,97.0,87.0,89.0,89.0,76.0,92.0,87.0,71.0,101.0,80.0,79.0,89.0,80.0,99.0,93.0,81.0,82.0,87.0,74.0,93.0,89.0,90.0,98.0,81.0,95.0,79.0,65.0,89.0,92.0,77.0,96.0,65.0,88.0,92.0,89.0,92.0,84.0,97.0,86.0,74.0,97.0,83.0,91.0,87.0,75.0,93.0,88.0,91.0,97.0,93.0,83.0,77.0,82.0,88.0,78.0,81.0,96.0,82.0,74.0,81.0,78.0,93.0,99.0,85.0,86.0,101.0,69.0,86.0,92.0,77.0,85.0,70.0,76.0,85.0,76.0,86.0,89.0,75.0,82.0,75.0,91.0,102.0,86.0,92.0,76.0,93.0,86.0,87.0,96.0,74.0,85.0,85.0,83.0,90.0,79.0,81.0,82.0,77.0,82.0,90.0,74.0,106.0,94.0,90.0,89.0,83.0,73.0,92.0,87.0,73.0,97.0,90.0,91.0,89.0,80.0,92.0,95.0,89.0,90.0,81.0,93.0,112.0,89.0,86.0,98.0,97.0,78.0,110.0,98.0,89.0,90.0,78.0,89.0,102.0,85.0,76.0,86.0,84.0,77.0,79.0,74.0,93.0,93.0,81.0,83.0,96.0,67.0,77.0,82.0,78.0,91.0,65.0,86.0,89.0,74.0,83.0,85.0,77.0,89.0,78.0,83.0,86.0,86.0,77.0,75.0,88.0,89.0,82.0,92.0,85.0,82.0,90.0,86.0,92.0,72.0,78.0,81.0,76.0,91.0,78.0,79.0,105.0,97.0,93.0,96.0,93.0,74.0,83.0,87.0,90.0,91.0,82.0,76.0,84.0,86.0,99.0,82.0,85.0,82.0,80.0,92.0,91.0,109.0,79.0,75.0,98.0,79.0,105.0,95.0,87.0,88.0,86.0,96.0,97.0,99.0,77.0,80.0,80.0,87.0,83.0,74.0,97.0,87.0,76.0,89.0,94.0,69.0,86.0,89.0,80.0,88.0,71.0,79.0,98.0,73.0,87.0,85.0,75.0,84.0,79.0,88.0,90.0,84.0,78.0,78.0,105.0,82.0,85.0,91.0,83.0,76.0,82.0,78.0,89.0,91.0,77.0,94.0,77.0,81.0,90.0,92.0,109.0,98.0,77.0,90.0,92.0,86.0,78.0,80.0,84.0,87.0,75.0,86.0,93.0,88.0,98.0,84.0,90.0,86.0,81.0,96.0,87.0,99.0,94.0,77.0,106.0,104.0,88.0,97.0,91.0,81.0,85.0,85.0,106.0,81.0,86.0,84.0,85.0,77.0,83.0,74.0,101.0,89.0,81.0,82.0,92.0,75.0,83.0,85.0,74.0,86.0,65.0,87.0,96.0,79.0,87.0,89.0,75.0,84.0,75.0,92.0,95.0,90.0,91.0,90.0,90.0,79.0,80.0,98.0,71.0,81.0,93.0,84.0,93.0,83.0,86.0,82.0,75.0,95.0,86.0,93.0,92.0,94.0,89.0,92.0,92.0,68.0,82.0,96.0,86.0,89.0,69.0,79.0,94.0,94.0,87.0,84.0,85.0,81.0,85.0,92.0,88.0,104.0,85.0,91.0,102.0,80.0,74.0,96.0,70.0,89.0,86.0,78.0,93.0,91.0,79.0,80.0,85.0,77.0,83.0,74.0,101.0,89.0,81.0,82.0,92.0,75.0,83.0,85.0,74.0,86.0,65.0,87.0,96.0,79.0,87.0,89.0,75.0,84.0,75.0,92.0,95.0,90.0,91.0,90.0,90.0,79.0,80.0,98.0,71.0,81.0,93.0,84.0,93.0,83.0,86.0,82.0,75.0,95.0,86.0,93.0,92.0,94.0,89.0,92.0,92.0,68.0,82.0,96.0,86.0,89.0,69.0,79.0,94.0,94.0,87.0,84.0,85.0,81.0,85.0,92.0,88.0,104.0,85.0,91.0,102.0,80.0,74.0,96.0,70.0,89.0,86.0,78.0,93.0,91.0,79.0,80.0,86.0,74.0,82.0,73.0,94.0,85.0,82.0,82.0,83.0,72.0,81.0,88.0,81.0,85.0,71.0,87.0,89.0,82.0,82.0,93.0,71.0,84.0,77.0,83.0,86.0,85.0,78.0,82.0,87.0,86.0,71.0,92.0,83.0,83.0,81.0,81.0,91.0,93.0,82.0,85.0,75.0,78.0,91.0,81.0,98.0,92.0,80.0,85.0,82.0,70.0,75.0,85.0,92.0,96.0,69.0,73.0,88.0,82.0,86.0,83.0,85.0,82.0,74.0,96.0,104.0,100.0,85.0,75.0,101.0,99.0,75.0,97.0,82.0,91.0,84.0,83.0,90.0,82.0,78.0,90.0,86.0,79.0,95.0,88.0,102.0,96.0,87.0,96.0,96.0,66.0,80.0,92.0,82.0,84.0,70.0,80.0,92.0,92.0,89.0,87.0,74.0,81.0,75.0,82.0,86.0,85.0,89.0,77.0,89.0,80.0,85.0,93.0,77.0,79.0,79.0,82.0,101.0,75.0,75.0,82.0,80.0,83.0,96.0,81.0,104.0,98.0,90.0,94.0,87.0,72.0,93.0,89.0,87.0,97.0,87.0,90.0,102.0,84.0,103.0,86.0,88.0,97.0,68.0,103.0,85.0,88.0,94.0,85.0,97.0,97.0,86.0,103.0,82.0,91.0,78.0,82.0,103.0,78.0,83.0,83.0,97.0,71.0,82.0,84.0,110.0,94.0,91.0,93.0,93.0,68.0,77.0,96.0,84.0,91.0,73.0,78.0,88.0,83.0,102.0,88.0,84.0,91.0,75.0,92.0,103.0,90.0,106.0,75.0,100.0,92.0,78.0,98.0,89.0,95.0,96.0,83.0,107.0,96.0,78.0,87.0,77.0,72.0,84.0,68.0,90.0,94.0,82.0,89.0,89.0,75.0,85.0,85.0,80.0,85.0,64.0,87.0,95.0,79.0,94.0,84.0,93.0,83.0,82.0,85.0,85.0,96.0,92.0,73.0,104.0,88.0,82.0,95.0,87.0,92.0,86.0,86.0,98.0,84.0,80.0,84.0)\n",
      "\n",
      "g <- as.factor(c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114))\n"
     ]
    }
   ],
   "source": [
    "# Extract variables for R analysis\n",
    "y = ''\n",
    "g = ''\n",
    "\n",
    "tmpY = ''\n",
    "tmpG = ''\n",
    "\n",
    "\n",
    "gkey = {}\n",
    "\n",
    "modeScore = {} # list of centralities for each modal edges cut value\n",
    "\n",
    "# this is to set the CONTROL for the R statistical tests (control = first centrality data that has to go in)\n",
    "\n",
    "# not sure - this would probably be the Leverage_Centrality_HL which has technically\n",
    "# the best modal score\n",
    "whichIDToKeepAsZero = 0 #leverage # 90 for Political_independence_index_LH # 0 for random \n",
    "\n",
    "for i_key, key in enumerate(list(centralities.keys())):\n",
    "    if(i_key < whichIDToKeepAsZero):\n",
    "        gkey[i_key + 1] = key\n",
    "    elif(i_key == whichIDToKeepAsZero):\n",
    "        gkey[0] = key\n",
    "    else:\n",
    "        gkey[i_key] = key\n",
    "        \n",
    "    centrality = centralities[key]\n",
    "\n",
    "    # extract Edges Cut mode value\n",
    "    #UNCOMMENT THESE TO ENABLE MODE SCORE\n",
    "    #modescore = centrality.modeScores[2].split(':')\n",
    "    #mecut = float(modescore[0]) # value of mode of edges cut\n",
    "    #mcount = int(modescore[1]) # number of experiments with this modal value of edges cut\n",
    "    \n",
    "        \n",
    "    # store each centrality based on their modal value of edges cut\n",
    "    #overallmodescore = mecut / mcount\n",
    "    \n",
    "    # UNCOMMENT THIS TO ENABLE MODE SCORE\n",
    "    #overallmodescore = mecut\n",
    "\n",
    "    ## COMMENT THIS OUT IF WE DON?T WANT AVERAGE!!\n",
    "    centrality.loadScores()\n",
    "    centrality.computeStatsScore()\n",
    "    overallmodescore = centrality.avgScores[2]\n",
    "    \n",
    "    if overallmodescore in modeScore:\n",
    "        modeScore[overallmodescore].append(key)\n",
    "    else:\n",
    "        modeScore[overallmodescore] = [key]\n",
    "\n",
    "    \n",
    "    \n",
    "    for i, score in enumerate(centrality.scores):\n",
    "        edges_cut = score[2]\n",
    "        \n",
    "        if(i_key == whichIDToKeepAsZero):\n",
    "            if(len(tmpY)):\n",
    "                tmpY += ','\n",
    "            tmpY += str(edges_cut)\n",
    "            if(len(tmpG)):\n",
    "                tmpG += ','\n",
    "            tmpG += str(0)\n",
    "            \n",
    "        else:        \n",
    "            if(len(y)):\n",
    "                y += ','\n",
    "            y += str(edges_cut)\n",
    "            if(len(g)):\n",
    "                g += ','\n",
    "            g += str(i_key)\n",
    "            #g += '\"' + str(i_key) + '\"'\n",
    "            if(i == 40):\n",
    "                break\n",
    "\n",
    "y = \"Y <- c(\" + tmpY + ',' + y + \")\"\n",
    "g = \"g <- as.factor(c(\" + tmpG + ',' + g + \"))\"\n",
    "print(y)\n",
    "print(\"\")\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.9 BottleNeck_centrality_HL\n",
      "82.125 Alpha_LH\n",
      "82.55 MNC_centrality_HL\n",
      "82.575 Eigenvector_HL, Kleinbergs_centrality_HITS_HL\n",
      "82.625 Betweenness_HL, Shortest_path_betweenness_HL\n",
      "82.825 Stress_centrality_HL\n",
      "82.85 Communicability_betweenness_centrality_HL, Path_centrality_HL, Political_independence_index_LH\n",
      "83.05 Effectiveness_centrality_HL\n",
      "83.075 Network_centrality_HL\n",
      "83.25 Leverage_centrality_HL\n",
      "83.275 Closeness_VariantLatora_HL\n",
      "83.3 MCC_centrality_HL\n",
      "83.625 Lapacian_centrality_HL\n",
      "83.725 Average_distance_LH\n",
      "83.775 Load_centrality_HL\n",
      "83.85 Flow_betweenness_centrality_HL\n",
      "83.975 Dangalchev_closeness_centrality_HL, Decay_centrality_HL\n",
      "84.025 Barycenter_centrality_HL, Closeness_Freeman_HL, Lin_centrality_HL, Radiality_centrality_HL, Shortest_path_closeness_HL\n",
      "84.1 Centroid_centrality_HL\n",
      "84.175 Community_centrality_HL\n",
      "84.2 Random_walk_betweenness_HL\n",
      "84.25 Cross_clique_connectivity_HL, Semi_local_centrality_HL\n",
      "84.325 Network_fragmentation_GeodesicDistanceWeighted_HL\n",
      "84.45 Bridging_centrality_LH\n",
      "84.55 Degree_centrality_HL, Shortest_path_degree_HL, Strength_weighted_vertex_degree_HL\n",
      "84.625 Subgraph_HL\n",
      "84.65 LAC_HL\n",
      "84.7210884354 AA_random\n",
      "84.75 Lobby_index_HL\n",
      "84.85 Current_flow_closeness_centrality_HL, Information_centrality_HL\n",
      "84.875 SALSA_HL\n",
      "85.1 Network_fragmentation_HL\n",
      "85.125 Markov_centrality_HL, Random_walk_closeness_HL\n",
      "85.325 Diffusion_degree_HL, Topological_coefficient_LH\n",
      "85.35 Stress_centrality_LH\n",
      "85.55 Bridging_centrality_HL\n",
      "85.6 Leverage_centrality_LH\n",
      "85.625 EPC_HL\n",
      "85.675 ClusterRank_HL\n",
      "85.7 Entropy_centrality_LH\n",
      "85.825 Local_assortativity_LH\n",
      "85.875 Eccentricity_LH\n",
      "86.05 Alpha_HL\n",
      "86.175 BottleNeck_centrality_LH, DMNC_centrality_LH\n",
      "86.2 Local_assortativity_HL\n",
      "86.275 Flow_betweenness_centrality_LH\n",
      "86.3 DMNC_centrality_HL, SALSA_LH\n",
      "86.375 Political_independence_index_HL\n",
      "86.5 Core_decomposition_LH\n",
      "86.625 Degree_centrality_LH, Shortest_path_degree_LH, Strength_weighted_vertex_degree_LH\n",
      "86.75 Local_clustering_coefficients_HL\n",
      "86.875 Network_fragmentation_GeodesicDistanceWeighted_LH\n",
      "86.925 Neighborhood_connectivity_LH\n",
      "87.075 Local_clustering_coefficients_LH, Markov_centrality_LH, Random_walk_closeness_LH\n",
      "87.175 Effectiveness_centrality_LH\n",
      "87.425 Network_fragmentation_LH\n",
      "87.5 Eccentricity_HL\n",
      "87.675 Entropy_centrality_HL\n",
      "87.725 Random_walk_betweenness_LH\n",
      "87.975 Lapacian_centrality_LH\n",
      "88.0 Load_centrality_LH\n",
      "88.05 Betweenness_LH, Shortest_path_betweenness_LH\n",
      "88.075 Communicability_betweenness_centrality_LH\n",
      "88.15 Diffusion_degree_LH\n",
      "88.225 Dangalchev_closeness_centrality_LH, Decay_centrality_LH\n",
      "88.45 Centroid_centrality_LH\n",
      "88.5 Community_centrality_LH, Current_flow_closeness_centrality_LH, Information_centrality_LH\n",
      "88.55 Path_centrality_LH\n",
      "88.7 Closeness_VariantLatora_LH\n",
      "88.725 Barycenter_centrality_LH, Closeness_Freeman_LH, Lin_centrality_LH, Radiality_centrality_LH, Shortest_path_closeness_LH\n",
      "88.9 EPC_LH\n",
      "88.9452054795 Lobby_index_LH\n",
      "88.95 Topological_coefficient_HL\n",
      "89.0 Semi_local_centrality_LH\n",
      "89.1 Average_distance_HL, Core_decomposition_HL\n",
      "89.125 MCC_centrality_LH\n",
      "89.225 MNC_centrality_LH\n",
      "89.35 Subgraph_LH\n",
      "89.7 Neighborhood_connectivity_HL\n",
      "90.025 ClusterRank_LH, LAC_LH\n",
      "90.475 Cross_clique_centrality_LH\n",
      "90.9 Network_centrality_LH\n",
      "91.85 Kleinbergs_centrality_HITS_LH\n",
      "92.05 Eigenvector_LH\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(modeScore.keys()):\n",
    "    s = ''\n",
    "    for c in modeScore[key]:\n",
    "        if len(s):\n",
    "            s += ', '\n",
    "        s += c\n",
    "    print(key, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target best mode centrality: 10\n",
      "k <- c(\"Leverage_centrality_HL\",\"AA_random\",\"Alpha_HL\",\"Alpha_LH\",\"Average_distance_HL\",\"Average_distance_LH\",\"Barycenter_centrality_HL\",\"Barycenter_centrality_LH\",\"Betweenness_HL\",\"Betweenness_LH\",\"BottleNeck_centrality_HL\",\"BottleNeck_centrality_LH\",\"Bridging_centrality_HL\",\"Bridging_centrality_LH\",\"Centroid_centrality_HL\",\"Centroid_centrality_LH\",\"Closeness_Freeman_HL\",\"Closeness_Freeman_LH\",\"Closeness_VariantLatora_HL\",\"Closeness_VariantLatora_LH\",\"ClusterRank_HL\",\"ClusterRank_LH\",\"Communicability_betweenness_centrality_HL\",\"Communicability_betweenness_centrality_LH\",\"Community_centrality_HL\",\"Community_centrality_LH\",\"Core_decomposition_HL\",\"Core_decomposition_LH\",\"Cross_clique_centrality_LH\",\"Cross_clique_connectivity_HL\",\"Current_flow_closeness_centrality_HL\",\"Current_flow_closeness_centrality_LH\",\"Dangalchev_closeness_centrality_HL\",\"Dangalchev_closeness_centrality_LH\",\"Decay_centrality_HL\",\"Decay_centrality_LH\",\"Degree_centrality_HL\",\"Degree_centrality_LH\",\"Diffusion_degree_HL\",\"Diffusion_degree_LH\",\"DMNC_centrality_HL\",\"DMNC_centrality_LH\",\"Eccentricity_HL\",\"Eccentricity_LH\",\"Effectiveness_centrality_HL\",\"Effectiveness_centrality_LH\",\"Eigenvector_HL\",\"Eigenvector_LH\",\"Entropy_centrality_HL\",\"Entropy_centrality_LH\",\"EPC_HL\",\"EPC_LH\",\"Flow_betweenness_centrality_HL\",\"Flow_betweenness_centrality_LH\",\"Information_centrality_HL\",\"Information_centrality_LH\",\"Kleinbergs_centrality_HITS_HL\",\"Kleinbergs_centrality_HITS_LH\",\"LAC_HL\",\"LAC_LH\",\"Lapacian_centrality_HL\",\"Lapacian_centrality_LH\",\"Leverage_centrality_LH\",\"Lin_centrality_HL\",\"Lin_centrality_LH\",\"Load_centrality_HL\",\"Load_centrality_LH\",\"Lobby_index_HL\",\"Lobby_index_LH\",\"Local_assortativity_HL\",\"Local_assortativity_LH\",\"Local_clustering_coefficients_HL\",\"Local_clustering_coefficients_LH\",\"Markov_centrality_HL\",\"Markov_centrality_LH\",\"MCC_centrality_HL\",\"MCC_centrality_LH\",\"MNC_centrality_HL\",\"MNC_centrality_LH\",\"Neighborhood_connectivity_HL\",\"Neighborhood_connectivity_LH\",\"Network_centrality_HL\",\"Network_centrality_LH\",\"Network_fragmentation_GeodesicDistanceWeighted_HL\",\"Network_fragmentation_GeodesicDistanceWeighted_LH\",\"Network_fragmentation_HL\",\"Network_fragmentation_LH\",\"Path_centrality_HL\",\"Path_centrality_LH\",\"Political_independence_index_HL\",\"Political_independence_index_LH\",\"Radiality_centrality_HL\",\"Radiality_centrality_LH\",\"Random_walk_betweenness_HL\",\"Random_walk_betweenness_LH\",\"Random_walk_closeness_HL\",\"Random_walk_closeness_LH\",\"SALSA_HL\",\"SALSA_LH\",\"Semi_local_centrality_HL\",\"Semi_local_centrality_LH\",\"Shortest_path_betweenness_HL\",\"Shortest_path_betweenness_LH\",\"Shortest_path_closeness_HL\",\"Shortest_path_closeness_LH\",\"Shortest_path_degree_HL\",\"Shortest_path_degree_LH\",\"Strength_weighted_vertex_degree_HL\",\"Strength_weighted_vertex_degree_LH\",\"Stress_centrality_HL\",\"Stress_centrality_LH\",\"Subgraph_HL\",\"Subgraph_LH\",\"Topological_coefficient_HL\",\"Topological_coefficient_LH\")\n"
     ]
    }
   ],
   "source": [
    "k = ''\n",
    "for key in sorted(gkey.keys()):\n",
    "    if(len(k)):\n",
    "        k += ','\n",
    "    k += '\"' + gkey[key] + '\"'\n",
    "    if gkey[key] == 'BottleNeck_centrality_HL':\n",
    "        print('target best mode centrality:', key)\n",
    "\n",
    "k = 'k <- c(' + k + ')'\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_best <- c(82.0,72.0,83.0,79.0,89.0,94.0,91.0,85.0,96.0,73.0,86.0,96.0,82.0,94.0,72.0,76.0,91.0,87.0,93.0,97.0,87.0,90.0,88.0,93.0,81.0,91.0,84.0,79.0,96.0,87.0,86.0,90.0,75.0,82.0,98.0,85.0,92.0,91.0,75.0,79.0,82.0,72.0,83.0,79.0,89.0,94.0,91.0,85.0,96.0,73.0,86.0,96.0,82.0,94.0,72.0,76.0,91.0,87.0,93.0,97.0,87.0,90.0,88.0,93.0,81.0,91.0,84.0,79.0,96.0,87.0,86.0,90.0,75.0,82.0,98.0,85.0,92.0,91.0,75.0,79.0,87.0,89.0,80.0,77.0,94.0,92.0,78.0,90.0,82.0,66.0,86.0,82.0,85.0,96.0,87.0,80.0,86.0,75.0,83.0,88.0,94.0,86.0,75.0,94.0,92.0,89.0,84.0,68.0,102.0,80.0,77.0,99.0,86.0,79.0,95.0,77.0,98.0,77.0,77.0,79.0,87.0,74.0,83.0,79.0,82.0,103.0,107.0,80.0,91.0,85.0,74.0,80.0,85.0,83.0,90.0,68.0,92.0,88.0,85.0,91.0,79.0,87.0,98.0,86.0,86.0,89.0,99.0,83.0,81.0,96.0,81.0,73.0,88.0,87.0,82.0,83.0,88.0,94.0,76.0,86.0,100.0,74.0,86.0,71.0,86.0,75.0,91.0,91.0,76.0,87.0,90.0,73.0,84.0,83.0,76.0,89.0,72.0,80.0,83.0,74.0,87.0,80.0,75.0,96.0,77.0,86.0,82.0,85.0,85.0,77.0,99.0,88.0,78.0,90.0,71.0,82.0,81.0,76.0,87.0,77.0,78.0,81.0,86.0,80.0,78.0,96.0,87.0,99.0,99.0,92.0,97.0,79.0,65.0,75.0,99.0,78.0,101.0,84.0,91.0,89.0,85.0,93.0,79.0,97.0,88.0,77.0,92.0,96.0,102.0,87.0,76.0,99.0,81.0,103.0,104.0,85.0,90.0,88.0,82.0,99.0,81.0,92.0,99.0,80.0,87.0,85.0,78.0,76.0,91.0,87.0,74.0,86.0,94.0,64.0,86.0,89.0,82.0,86.0,71.0,81.0,95.0,87.0,85.0,81.0,76.0,84.0,83.0,85.0,90.0,84.0,92.0,86.0,100.0,81.0,86.0,91.0,79.0,79.0,81.0,82.0,89.0,78.0,78.0,80.0,87.0,80.0,87.0,83.0,74.0,97.0,87.0,76.0,89.0,94.0,69.0,86.0,89.0,80.0,88.0,71.0,79.0,98.0,73.0,87.0,85.0,75.0,84.0,79.0,88.0,90.0,84.0,78.0,78.0,105.0,82.0,85.0,91.0,83.0,76.0,82.0,78.0,89.0,91.0,77.0,94.0,80.0,77.0,81.0,90.0,92.0,109.0,98.0,77.0,90.0,92.0,86.0,78.0,80.0,84.0,87.0,75.0,86.0,93.0,88.0,98.0,84.0,90.0,86.0,81.0,96.0,87.0,99.0,94.0,77.0,106.0,104.0,88.0,97.0,91.0,81.0,85.0,85.0,106.0,81.0,86.0,84.0,77.0,84.0,77.0,79.0,74.0,93.0,93.0,81.0,83.0,96.0,67.0,77.0,82.0,78.0,91.0,65.0,86.0,89.0,74.0,83.0,85.0,77.0,89.0,78.0,83.0,86.0,86.0,77.0,75.0,88.0,89.0,82.0,92.0,85.0,82.0,90.0,86.0,92.0,72.0,78.0,81.0,84.0,76.0,91.0,78.0,79.0,105.0,97.0,93.0,96.0,93.0,74.0,83.0,87.0,90.0,91.0,82.0,76.0,84.0,86.0,99.0,82.0,85.0,82.0,80.0,92.0,91.0,109.0,79.0,75.0,98.0,79.0,105.0,95.0,87.0,88.0,86.0,96.0,97.0,99.0,77.0,80.0,76.0,79.0,75.0,76.0,75.0,97.0,94.0,75.0,81.0,81.0,67.0,76.0,84.0,76.0,92.0,67.0,71.0,96.0,71.0,87.0,83.0,73.0,84.0,82.0,93.0,87.0,87.0,82.0,70.0,92.0,81.0,69.0,90.0,70.0,85.0,77.0,72.0,97.0,90.0,74.0,78.0,79.0,79.0,79.0,89.0,73.0,112.0,96.0,76.0,87.0,96.0,75.0,78.0,93.0,84.0,91.0,73.0,87.0,95.0,79.0,89.0,77.0,87.0,87.0,77.0,84.0,94.0,96.0,82.0,72.0,102.0,79.0,74.0,95.0,82.0,86.0,86.0,87.0,94.0,91.0,79.0,80.0,79.0,76.0,77.0,86.0,78.0,91.0,102.0,88.0,85.0,90.0,64.0,77.0,84.0,81.0,88.0,62.0,83.0,88.0,75.0,95.0,87.0,81.0,98.0,82.0,87.0,90.0,95.0,84.0,80.0,101.0,76.0,81.0,99.0,74.0,85.0,81.0,84.0,96.0,82.0,81.0,84.0,76.0,86.0,74.0,87.0,78.0,97.0,97.0,84.0,84.0,79.0,68.0,85.0,87.0,80.0,87.0,69.0,84.0,81.0,81.0,92.0,95.0,72.0,83.0,76.0,87.0,98.0,85.0,83.0,81.0,101.0,87.0,84.0,87.0,72.0,88.0,84.0,81.0,87.0,82.0,82.0,89.0,86.0,85.0,74.0,79.0,70.0,111.0,99.0,71.0,103.0,97.0,100.0,77.0,93.0,79.0,97.0,65.0,90.0,97.0,76.0,91.0,93.0,78.0,90.0,84.0,93.0,86.0,96.0,91.0,98.0,107.0,78.0,76.0,108.0,72.0,96.0,100.0,91.0,101.0,77.0,79.0,90.0,85.0,80.0,87.0,83.0,74.0,97.0,87.0,76.0,89.0,94.0,69.0,86.0,89.0,80.0,88.0,71.0,79.0,98.0,73.0,87.0,85.0,75.0,84.0,79.0,88.0,90.0,84.0,78.0,78.0,105.0,82.0,85.0,91.0,83.0,76.0,82.0,78.0,89.0,91.0,77.0,94.0,80.0,77.0,81.0,90.0,92.0,109.0,98.0,77.0,90.0,92.0,86.0,78.0,80.0,84.0,87.0,75.0,86.0,93.0,88.0,98.0,84.0,90.0,86.0,81.0,96.0,87.0,99.0,94.0,77.0,106.0,104.0,88.0,97.0,91.0,81.0,85.0,85.0,106.0,81.0,86.0,84.0,77.0,92.0,78.0,87.0,74.0,92.0,89.0,81.0,83.0,95.0,63.0,86.0,92.0,77.0,86.0,74.0,79.0,92.0,86.0,86.0,84.0,74.0,88.0,80.0,84.0,90.0,86.0,80.0,84.0,88.0,79.0,83.0,96.0,80.0,82.0,76.0,81.0,87.0,76.0,75.0,86.0,92.0,91.0,94.0,89.0,80.0,95.0,95.0,85.0,87.0,95.0,77.0,81.0,90.0,94.0,89.0,70.0,84.0,97.0,75.0,88.0,86.0,86.0,91.0,79.0,106.0,81.0,97.0,111.0,84.0,106.0,88.0,94.0,96.0,73.0,89.0,87.0,83.0,91.0,98.0,84.0,82.0,91.0,80.0,89.0,90.0,71.0,98.0,94.0,82.0,91.0,90.0,72.0,82.0,87.0,82.0,89.0,70.0,88.0,91.0,83.0,91.0,87.0,93.0,93.0,76.0,94.0,88.0,85.0,82.0,76.0,94.0,85.0,79.0,98.0,74.0,92.0,84.0,79.0,93.0,85.0,78.0,92.0,80.0,87.0,93.0,83.0,87.0,108.0,97.0,104.0,82.0,88.0,93.0,95.0,94.0,88.0,88.0,76.0,90.0,92.0,75.0,99.0,93.0,88.0,90.0,75.0,97.0,85.0,99.0,100.0,72.0,97.0,100.0,77.0,89.0,76.0,78.0,101.0,90.0,97.0,99.0,81.0,98.0,87.0,82.0,76.0,99.0,70.0,101.0,91.0,82.0,91.0,83.0,67.0,84.0,94.0,78.0,89.0,68.0,85.0,94.0,81.0,86.0,82.0,78.0,83.0,71.0,89.0,82.0,84.0,80.0,74.0,86.0,76.0,77.0,98.0,78.0,82.0,80.0,79.0,94.0,84.0,77.0,79.0,82.0,81.0,79.0,99.0,78.0,93.0,94.0,87.0,96.0,92.0,94.0,92.0,94.0,79.0,90.0,65.0,90.0,97.0,72.0,102.0,89.0,96.0,92.0,75.0,89.0,93.0,90.0,96.0,104.0,89.0,86.0,73.0,96.0,79.0,93.0,77.0,80.0,92.0,80.0,82.0,98.0,81.0,72.0,75.0,85.0,70.0,93.0,95.0,82.0,84.0,82.0,88.0,84.0,94.0,81.0,89.0,71.0,75.0,91.0,82.0,94.0,88.0,80.0,83.0,68.0,91.0,90.0,96.0,86.0,78.0,97.0,81.0,80.0,92.0,81.0,87.0,80.0,79.0,94.0,84.0,76.0,89.0,72.0,80.0,72.0,98.0,79.0,101.0,101.0,93.0,85.0,88.0,77.0,88.0,92.0,79.0,94.0,71.0,90.0,97.0,82.0,92.0,91.0,105.0,89.0,88.0,98.0,100.0,94.0,96.0,89.0,94.0,80.0,97.0,103.0,72.0,76.0,79.0,79.0,98.0,91.0,82.0,80.0,80.0,88.0,85.0,99.0,88.0,108.0,88.0,85.0,95.0,83.0,69.0,87.0,94.0,79.0,94.0,90.0,95.0,84.0,83.0,97.0,96.0,91.0,83.0,83.0,96.0,90.0,90.0,91.0,83.0,93.0,100.0,105.0,95.0,78.0,86.0,84.0,88.0,102.0,82.0,72.0,85.0,88.0,80.0,74.0,79.0,77.0,105.0,87.0,91.0,89.0,88.0,75.0,83.0,86.0,92.0,87.0,67.0,85.0,90.0,87.0,82.0,84.0,90.0,84.0,80.0,93.0,111.0,95.0,87.0,77.0,106.0,82.0,89.0,103.0,73.0,88.0,91.0,87.0,92.0,77.0,83.0,84.0,80.0,87.0,81.0,95.0,70.0,111.0,98.0,86.0,95.0,86.0,86.0,81.0,90.0,88.0,105.0,68.0,93.0,94.0,92.0,96.0,87.0,99.0,88.0,87.0,96.0,95.0,99.0,80.0,85.0,97.0,87.0,76.0,98.0,84.0,95.0,93.0,99.0,106.0,84.0,87.0,95.0,87.0,81.0,74.0,98.0,79.0,90.0,97.0,88.0,85.0,88.0,77.0,89.0,89.0,81.0,92.0,63.0,84.0,83.0,82.0,88.0,86.0,75.0,83.0,79.0,85.0,89.0,91.0,97.0,78.0,89.0,78.0,89.0,86.0,81.0,78.0,85.0,84.0,92.0,78.0,78.0,81.0,81.0,83.0,79.0,75.0,77.0,97.0,88.0,76.0,83.0,93.0,73.0,79.0,89.0,79.0,95.0,67.0,84.0,92.0,75.0,78.0,94.0,79.0,86.0,78.0,93.0,95.0,87.0,99.0,82.0,92.0,78.0,79.0,102.0,77.0,95.0,76.0,91.0,91.0,91.0,83.0,84.0,83.0,89.0,94.0,91.0,83.0,111.0,100.0,82.0,97.0,91.0,95.0,87.0,90.0,81.0,99.0,75.0,81.0,83.0,82.0,89.0,79.0,95.0,97.0,81.0,88.0,87.0,85.0,85.0,83.0,93.0,90.0,74.0,93.0,78.0,96.0,88.0,85.0,93.0,96.0,88.0,86.0,89.0,87.0,79.0,97.0,78.0,92.0,90.0,75.0,81.0,89.0,64.0,86.0,88.0,83.0,88.0,70.0,89.0,89.0,68.0,92.0,93.0,75.0,80.0,80.0,82.0,91.0,96.0,89.0,79.0,88.0,76.0,82.0,91.0,81.0,81.0,85.0,83.0,83.0,95.0,75.0,89.0,87.0,79.0,78.0,78.0,83.0,109.0,98.0,83.0,89.0,98.0,66.0,79.0,91.0,93.0,93.0,64.0,94.0,94.0,91.0,89.0,81.0,93.0,86.0,82.0,99.0,95.0,94.0,85.0,88.0,90.0,99.0,82.0,104.0,75.0,91.0,92.0,84.0,91.0,96.0,81.0,92.0,79.0,87.0,79.0,97.0,78.0,92.0,90.0,75.0,81.0,89.0,64.0,86.0,88.0,83.0,88.0,70.0,89.0,89.0,68.0,92.0,93.0,75.0,80.0,80.0,82.0,91.0,96.0,89.0,79.0,88.0,76.0,82.0,91.0,81.0,81.0,85.0,83.0,83.0,95.0,75.0,89.0,87.0,79.0,78.0,78.0,83.0,109.0,98.0,83.0,89.0,98.0,66.0,79.0,91.0,93.0,93.0,64.0,94.0,94.0,91.0,89.0,81.0,93.0,86.0,82.0,99.0,95.0,94.0,85.0,88.0,90.0,99.0,82.0,104.0,75.0,91.0,92.0,84.0,91.0,96.0,81.0,92.0,79.0,85.0,77.0,83.0,74.0,101.0,89.0,81.0,82.0,92.0,75.0,83.0,85.0,74.0,86.0,65.0,87.0,96.0,79.0,87.0,89.0,75.0,84.0,75.0,92.0,95.0,90.0,91.0,90.0,90.0,79.0,80.0,98.0,71.0,81.0,93.0,84.0,93.0,83.0,86.0,82.0,85.0,75.0,95.0,86.0,93.0,92.0,94.0,89.0,92.0,92.0,68.0,82.0,96.0,86.0,89.0,69.0,79.0,94.0,94.0,87.0,84.0,85.0,81.0,85.0,92.0,88.0,104.0,85.0,91.0,102.0,80.0,74.0,96.0,70.0,89.0,86.0,78.0,93.0,91.0,79.0,80.0,75.0,86.0,78.0,91.0,73.0,85.0,94.0,81.0,90.0,96.0,63.0,80.0,93.0,85.0,85.0,65.0,87.0,92.0,85.0,92.0,92.0,79.0,82.0,80.0,86.0,98.0,87.0,94.0,80.0,99.0,90.0,83.0,88.0,82.0,86.0,79.0,77.0,94.0,87.0,86.0,83.0,86.0,71.0,89.0,83.0,73.0,89.0,97.0,102.0,85.0,92.0,73.0,94.0,88.0,93.0,101.0,76.0,96.0,89.0,92.0,98.0,89.0,96.0,95.0,80.0,84.0,88.0,101.0,97.0,80.0,95.0,76.0,85.0,91.0,71.0,95.0,93.0,86.0,95.0,76.0,87.0,85.0,71.0,76.0,77.0,80.0,77.0,102.0,98.0,82.0,90.0,85.0,69.0,77.0,88.0,96.0,88.0,67.0,83.0,91.0,76.0,88.0,91.0,92.0,89.0,79.0,94.0,86.0,91.0,100.0,72.0,95.0,78.0,97.0,96.0,78.0,92.0,85.0,87.0,91.0,90.0,88.0,91.0,76.0,89.0,77.0,76.0,78.0,97.0,86.0,87.0,95.0,87.0,67.0,86.0,86.0,89.0,88.0,71.0,87.0,95.0,84.0,92.0,78.0,73.0,87.0,82.0,86.0,90.0,83.0,82.0,92.0,92.0,92.0,92.0,100.0,76.0,87.0,106.0,80.0,98.0,82.0,82.0,90.0,89.0,95.0,77.0,82.0,86.0,111.0,101.0,81.0,94.0,94.0,71.0,95.0,86.0,86.0,91.0,66.0,76.0,90.0,82.0,81.0,79.0,87.0,98.0,84.0,86.0,90.0,94.0,102.0,73.0,91.0,91.0,78.0,88.0,88.0,93.0,106.0,85.0,92.0,77.0,80.0,93.0,95.0,90.0,74.0,94.0,84.0,96.0,99.0,83.0,88.0,88.0,63.0,88.0,93.0,81.0,100.0,74.0,83.0,89.0,79.0,93.0,89.0,78.0,83.0,69.0,94.0,96.0,93.0,94.0,74.0,89.0,99.0,76.0,87.0,85.0,81.0,86.0,83.0,97.0,71.0,89.0,83.0,90.0,80.0,72.0,89.0,77.0,97.0,93.0,79.0,84.0,82.0,73.0,77.0,89.0,80.0,87.0,63.0,78.0,90.0,81.0,83.0,87.0,85.0,85.0,76.0,91.0,82.0,87.0,83.0,78.0,87.0,80.0,86.0,99.0,83.0,80.0,83.0,77.0,91.0,86.0,84.0,78.0,80.0,83.0,81.0,91.0,82.0,110.0,107.0,90.0,90.0,81.0,71.0,92.0,88.0,87.0,81.0,72.0,84.0,92.0,94.0,84.0,80.0,91.0,85.0,80.0,86.0,88.0,95.0,94.0,79.0,106.0,76.0,75.0,100.0,73.0,91.0,93.0,88.0,91.0,83.0,75.0,98.0,83.0,84.0,89.0,94.0,72.0,91.0,93.0,89.0,83.0,96.0,69.0,82.0,86.0,84.0,87.0,66.0,71.0,85.0,85.0,94.0,87.0,75.0,82.0,75.0,82.0,91.0,84.0,77.0,71.0,89.0,77.0,88.0,88.0,71.0,85.0,77.0,81.0,87.0,76.0,76.0,84.0,84.0,88.0,90.0,102.0,95.0,106.0,98.0,86.0,92.0,101.0,71.0,86.0,95.0,88.0,98.0,65.0,86.0,88.0,97.0,98.0,98.0,86.0,87.0,81.0,89.0,101.0,103.0,90.0,76.0,99.0,96.0,93.0,96.0,82.0,94.0,105.0,88.0,109.0,102.0,90.0,87.0,88.0,74.0,81.0,88.0,81.0,97.0,93.0,92.0,92.0,87.0,79.0,90.0,100.0,78.0,97.0,81.0,78.0,95.0,84.0,84.0,85.0,84.0,94.0,78.0,99.0,103.0,89.0,97.0,90.0,98.0,87.0,87.0,96.0,75.0,81.0,84.0,87.0,91.0,81.0,76.0,94.0,74.0,88.0,80.0,81.0,80.0,98.0,98.0,79.0,91.0,75.0,80.0,81.0,92.0,89.0,95.0,67.0,86.0,82.0,78.0,90.0,87.0,82.0,84.0,78.0,91.0,85.0,93.0,85.0,76.0,92.0,80.0,76.0,91.0,75.0,91.0,92.0,83.0,95.0,95.0,83.0,104.0,88.0,88.0,86.0,76.0,87.0,95.0,94.0,85.0,82.0,82.0,63.0,88.0,91.0,74.0,94.0,70.0,78.0,90.0,78.0,89.0,94.0,86.0,88.0,80.0,94.0,83.0,90.0,88.0,75.0,98.0,90.0,84.0,95.0,77.0,83.0,81.0,90.0,91.0,92.0,80.0,96.0,88.0,79.0,81.0,91.0,80.0,117.0,97.0,91.0,87.0,99.0,68.0,96.0,87.0,85.0,94.0,70.0,93.0,94.0,85.0,97.0,99.0,85.0,89.0,79.0,111.0,95.0,83.0,80.0,83.0,93.0,91.0,95.0,95.0,72.0,89.0,92.0,82.0,99.0,87.0,81.0,85.0,79.0,77.0,76.0,89.0,72.0,87.0,97.0,77.0,87.0,88.0,76.0,84.0,88.0,82.0,92.0,69.0,80.0,85.0,77.0,90.0,92.0,92.0,98.0,80.0,81.0,80.0,84.0,86.0,73.0,91.0,89.0,82.0,89.0,75.0,90.0,84.0,86.0,91.0,77.0,78.0,83.0,77.0,86.0,82.0,83.0,75.0,100.0,95.0,75.0,95.0,80.0,79.0,94.0,95.0,82.0,93.0,71.0,84.0,90.0,81.0,98.0,86.0,73.0,85.0,71.0,94.0,90.0,86.0,82.0,88.0,96.0,81.0,85.0,103.0,92.0,100.0,85.0,88.0,91.0,80.0,72.0,85.0,86.0,83.0,79.0,75.0,77.0,97.0,88.0,76.0,83.0,93.0,73.0,79.0,89.0,79.0,95.0,67.0,84.0,92.0,75.0,78.0,94.0,79.0,86.0,78.0,93.0,95.0,87.0,99.0,82.0,92.0,78.0,79.0,102.0,77.0,95.0,76.0,91.0,91.0,91.0,83.0,84.0,83.0,89.0,94.0,91.0,83.0,111.0,100.0,82.0,97.0,91.0,95.0,87.0,90.0,81.0,99.0,75.0,81.0,83.0,82.0,89.0,79.0,95.0,97.0,81.0,88.0,87.0,85.0,85.0,83.0,93.0,90.0,74.0,93.0,78.0,96.0,88.0,85.0,93.0,96.0,88.0,86.0,89.0,84.0,89.0,94.0,72.0,91.0,93.0,89.0,83.0,96.0,69.0,82.0,86.0,84.0,87.0,66.0,71.0,85.0,85.0,94.0,87.0,75.0,82.0,75.0,82.0,91.0,84.0,77.0,71.0,89.0,77.0,88.0,88.0,71.0,85.0,77.0,81.0,87.0,76.0,76.0,84.0,84.0,88.0,90.0,102.0,95.0,106.0,98.0,86.0,92.0,101.0,71.0,86.0,95.0,88.0,98.0,65.0,86.0,88.0,97.0,98.0,98.0,86.0,87.0,81.0,89.0,101.0,103.0,90.0,76.0,99.0,96.0,93.0,96.0,82.0,94.0,105.0,88.0,109.0,94.0,90.0,87.0,88.0,76.0,74.0,92.0,73.0,100.0,93.0,82.0,82.0,86.0,79.0,86.0,89.0,86.0,91.0,66.0,85.0,86.0,76.0,84.0,84.0,79.0,88.0,78.0,92.0,92.0,94.0,94.0,86.0,90.0,85.0,81.0,85.0,75.0,79.0,92.0,77.0,99.0,89.0,78.0,83.0,76.0,79.0,97.0,81.0,81.0,100.0,91.0,86.0,90.0,87.0,88.0,90.0,102.0,82.0,92.0,84.0,88.0,84.0,93.0,90.0,90.0,89.0,97.0,85.0,93.0,101.0,91.0,106.0,91.0,93.0,93.0,98.0,97.0,71.0,85.0,93.0,83.0,98.0,90.0,86.0,86.0,79.0,85.0,80.0,72.0,74.0,89.0,105.0,81.0,87.0,94.0,78.0,90.0,89.0,77.0,86.0,68.0,80.0,94.0,80.0,86.0,90.0,74.0,85.0,80.0,80.0,96.0,86.0,79.0,69.0,90.0,79.0,80.0,94.0,80.0,87.0,76.0,82.0,95.0,86.0,79.0,83.0,85.0,81.0,82.0,88.0,71.0,106.0,92.0,88.0,90.0,95.0,70.0,79.0,89.0,73.0,88.0,67.0,93.0,105.0,90.0,92.0,93.0,73.0,85.0,87.0,98.0,95.0,92.0,87.0,87.0,97.0,88.0,88.0,105.0,84.0,101.0,81.0,83.0,92.0,94.0,76.0,94.0,81.0,82.0,79.0,77.0,72.0,97.0,93.0,76.0,85.0,83.0,65.0,80.0,89.0,74.0,89.0,63.0,78.0,90.0,78.0,86.0,87.0,76.0,94.0,77.0,88.0,86.0,84.0,84.0,77.0,87.0,80.0,85.0,94.0,78.0,90.0,86.0,86.0,92.0,94.0,88.0,81.0,82.0,92.0,74.0,97.0,80.0,100.0,89.0,84.0,87.0,83.0,74.0,86.0,86.0,79.0,91.0,67.0,95.0,84.0,71.0,93.0,85.0,83.0,88.0,72.0,98.0,83.0,93.0,101.0,77.0,94.0,87.0,86.0,87.0,70.0,93.0,87.0,80.0,93.0,88.0,83.0,84.0,92.0,80.0,87.0,83.0,74.0,97.0,87.0,76.0,89.0,94.0,69.0,86.0,89.0,80.0,88.0,71.0,79.0,98.0,73.0,87.0,85.0,75.0,84.0,79.0,88.0,90.0,84.0,78.0,78.0,105.0,82.0,85.0,91.0,83.0,76.0,82.0,78.0,89.0,91.0,77.0,94.0,80.0,77.0,81.0,90.0,92.0,109.0,98.0,77.0,90.0,92.0,86.0,78.0,80.0,84.0,87.0,75.0,86.0,93.0,88.0,98.0,84.0,90.0,86.0,81.0,96.0,87.0,99.0,94.0,77.0,106.0,104.0,88.0,97.0,91.0,81.0,85.0,85.0,106.0,81.0,86.0,84.0,77.0,89.0,73.0,82.0,69.0,96.0,87.0,86.0,82.0,94.0,68.0,76.0,85.0,82.0,97.0,65.0,91.0,90.0,85.0,85.0,89.0,75.0,85.0,81.0,87.0,85.0,86.0,78.0,69.0,84.0,86.0,89.0,99.0,86.0,82.0,80.0,87.0,93.0,88.0,82.0,78.0,89.0,82.0,87.0,95.0,90.0,96.0,83.0,76.0,100.0,93.0,68.0,86.0,86.0,86.0,85.0,90.0,84.0,95.0,79.0,87.0,81.0,87.0,84.0,81.0,97.0,85.0,100.0,100.0,86.0,110.0,81.0,99.0,95.0,83.0,83.0,89.0,83.0,93.0,93.0,80.0,82.0,82.0,87.0,76.0,88.0,82.0,93.0,92.0,82.0,87.0,87.0,79.0,84.0,89.0,75.0,92.0,64.0,85.0,87.0,73.0,91.0,88.0,76.0,92.0,77.0,84.0,86.0,85.0,96.0,89.0,99.0,76.0,74.0,91.0,74.0,92.0,83.0,89.0,94.0,81.0,84.0,87.0,87.0,97.0,83.0,80.0,83.0,102.0,103.0,93.0,90.0,103.0,61.0,89.0,90.0,87.0,90.0,64.0,86.0,90.0,81.0,86.0,96.0,94.0,99.0,76.0,96.0,90.0,92.0,86.0,100.0,92.0,94.0,81.0,93.0,80.0,97.0,83.0,80.0,83.0,102.0,103.0,93.0,90.0,86.0,88.0,82.0,82.0,100.0,96.0,93.0,86.0,89.0,79.0,86.0,86.0,76.0,92.0,71.0,81.0,97.0,83.0,83.0,79.0,81.0,97.0,77.0,109.0,84.0,95.0,88.0,69.0,93.0,79.0,81.0,101.0,84.0,81.0,88.0,84.0,93.0,80.0,86.0,83.0,80.0,75.0,82.0,89.0,105.0,100.0,86.0,89.0,88.0,65.0,82.0,92.0,92.0,92.0,65.0,83.0,90.0,78.0,87.0,88.0,81.0,96.0,80.0,89.0,90.0,87.0,89.0,77.0,91.0,86.0,73.0,95.0,85.0,92.0,93.0,85.0,98.0,76.0,78.0,84.0,79.0,90.0,82.0,84.0,106.0,102.0,86.0,91.0,84.0,71.0,76.0,92.0,77.0,86.0,62.0,88.0,89.0,86.0,80.0,89.0,89.0,100.0,77.0,100.0,89.0,98.0,88.0,92.0,102.0,79.0,76.0,101.0,78.0,91.0,77.0,75.0,97.0,90.0,78.0,93.0,91.0,69.0,91.0,68.0,98.0,105.0,81.0,89.0,78.0,70.0,83.0,92.0,83.0,97.0,70.0,87.0,93.0,93.0,90.0,75.0,75.0,84.0,74.0,104.0,84.0,95.0,82.0,94.0,98.0,88.0,97.0,98.0,76.0,93.0,92.0,89.0,105.0,90.0,73.0,89.0,83.0,79.0,79.0,77.0,97.0,87.0,76.0,84.0,93.0,69.0,85.0,87.0,80.0,92.0,67.0,81.0,91.0,83.0,87.0,93.0,80.0,85.0,83.0,93.0,98.0,87.0,97.0,81.0,89.0,78.0,86.0,102.0,77.0,95.0,74.0,86.0,91.0,91.0,78.0,84.0,75.0,77.0,89.0,85.0,105.0,94.0,82.0,100.0,91.0,82.0,82.0,86.0,83.0,92.0,67.0,92.0,82.0,86.0,86.0,97.0,95.0,87.0,72.0,95.0,81.0,93.0,99.0,94.0,93.0,91.0,79.0,99.0,76.0,96.0,76.0,79.0,89.0,85.0,85.0,86.0,81.0,82.0,89.0,72.0,93.0,97.0,84.0,84.0,86.0,63.0,82.0,94.0,81.0,87.0,64.0,78.0,85.0,77.0,83.0,89.0,77.0,82.0,76.0,95.0,88.0,81.0,92.0,92.0,90.0,80.0,88.0,85.0,75.0,80.0,88.0,89.0,93.0,73.0,77.0,80.0,87.0,73.0,99.0,84.0,106.0,94.0,91.0,96.0,89.0,66.0,75.0,90.0,90.0,92.0,65.0,83.0,106.0,80.0,91.0,96.0,99.0,101.0,67.0,89.0,97.0,93.0,85.0,85.0,98.0,89.0,88.0,99.0,87.0,93.0,93.0,83.0,101.0,80.0,83.0,102.0,85.0,76.0,80.0,71.0,88.0,89.0,88.0,84.0,91.0,64.0,85.0,86.0,80.0,90.0,75.0,83.0,82.0,73.0,89.0,84.0,89.0,83.0,68.0,91.0,91.0,81.0,81.0,83.0,97.0,81.0,78.0,96.0,72.0,91.0,75.0,82.0,89.0,77.0,75.0,79.0,88.0,98.0,87.0,79.0,102.0,92.0,91.0,96.0,93.0,70.0,78.0,96.0,89.0,98.0,77.0,86.0,89.0,81.0,89.0,92.0,92.0,89.0,75.0,96.0,88.0,104.0,108.0,90.0,104.0,93.0,84.0,97.0,82.0,84.0,85.0,85.0,97.0,79.0,80.0,86.0,80.0,81.0,95.0,95.0,110.0,96.0,75.0,90.0,89.0,73.0,87.0,91.0,97.0,93.0,80.0,84.0,97.0,79.0,96.0,83.0,90.0,97.0,85.0,87.0,99.0,92.0,99.0,85.0,102.0,91.0,96.0,98.0,78.0,90.0,93.0,89.0,96.0,85.0,81.0,84.0,83.0,73.0,93.0,95.0,101.0,89.0,99.0,92.0,80.0,69.0,88.0,85.0,83.0,104.0,69.0,84.0,91.0,91.0,89.0,78.0,84.0,81.0,72.0,99.0,100.0,103.0,90.0,83.0,91.0,95.0,71.0,92.0,76.0,91.0,85.0,85.0,95.0,90.0,76.0,82.0,71.0,81.0,80.0,75.0,90.0,99.0,76.0,85.0,88.0,68.0,79.0,94.0,75.0,86.0,64.0,86.0,95.0,84.0,88.0,83.0,79.0,82.0,79.0,84.0,89.0,93.0,90.0,80.0,91.0,78.0,92.0,97.0,72.0,78.0,87.0,80.0,96.0,76.0,79.0,74.0,83.0,90.0,88.0,71.0,120.0,101.0,100.0,104.0,98.0,67.0,82.0,89.0,89.0,87.0,99.0,89.0,92.0,89.0,95.0,75.0,101.0,90.0,76.0,100.0,95.0,98.0,77.0,75.0,107.0,80.0,107.0,96.0,76.0,91.0,91.0,90.0,96.0,96.0,84.0,102.0,86.0,80.0,86.0,71.0,92.0,99.0,82.0,87.0,81.0,74.0,79.0,90.0,78.0,91.0,70.0,88.0,82.0,75.0,91.0,94.0,75.0,86.0,68.0,86.0,85.0,92.0,83.0,81.0,98.0,87.0,84.0,98.0,72.0,91.0,84.0,76.0,101.0,87.0,80.0,83.0,90.0,86.0,93.0,76.0,96.0,93.0,85.0,91.0,95.0,76.0,82.0,98.0,91.0,93.0,80.0,78.0,96.0,78.0,93.0,83.0,90.0,87.0,66.0,94.0,86.0,88.0,107.0,81.0,102.0,83.0,78.0,95.0,74.0,85.0,88.0,91.0,93.0,84.0,71.0,79.0,90.0,88.0,85.0,79.0,93.0,88.0,86.0,87.0,84.0,73.0,72.0,91.0,80.0,88.0,64.0,81.0,85.0,80.0,89.0,78.0,76.0,83.0,69.0,96.0,84.0,90.0,88.0,73.0,95.0,79.0,98.0,99.0,93.0,94.0,84.0,80.0,106.0,89.0,86.0,81.0,87.0,87.0,82.0,85.0,97.0,95.0,88.0,92.0,79.0,79.0,78.0,87.0,88.0,87.0,78.0,83.0,89.0,87.0,95.0,86.0,101.0,98.0,74.0,96.0,91.0,101.0,82.0,76.0,100.0,78.0,88.0,91.0,67.0,86.0,98.0,88.0,102.0,92.0,78.0,81.0,83.0,76.0,80.0,68.0,90.0,97.0,85.0,88.0,90.0,69.0,79.0,87.0,79.0,89.0,65.0,79.0,91.0,72.0,89.0,81.0,78.0,82.0,84.0,88.0,91.0,88.0,79.0,72.0,96.0,76.0,81.0,81.0,70.0,75.0,89.0,90.0,99.0,85.0,83.0,90.0,81.0,81.0,100.0,84.0,95.0,99.0,91.0,88.0,81.0,93.0,95.0,88.0,92.0,96.0,72.0,80.0,82.0,94.0,81.0,91.0,87.0,85.0,86.0,90.0,83.0,101.0,97.0,91.0,102.0,79.0,75.0,102.0,74.0,83.0,99.0,87.0,103.0,91.0,70.0,93.0,84.0,82.0,91.0,77.0,103.0,98.0,76.0,86.0,86.0,70.0,87.0,88.0,82.0,85.0,74.0,88.0,97.0,93.0,81.0,78.0,97.0,87.0,80.0,95.0,82.0,84.0,102.0,82.0,95.0,91.0,85.0,98.0,78.0,91.0,80.0,85.0,96.0,89.0,75.0,77.0,82.0,71.0,86.0,73.0,96.0,90.0,80.0,82.0,79.0,68.0,81.0,95.0,77.0,84.0,82.0,77.0,93.0,69.0,100.0,74.0,76.0,85.0,72.0,87.0,99.0,89.0,80.0,73.0,98.0,81.0,79.0,94.0,73.0,90.0,88.0,79.0,88.0,77.0,84.0,83.0,80.0,87.0,83.0,74.0,97.0,87.0,76.0,89.0,94.0,69.0,86.0,89.0,80.0,88.0,71.0,79.0,98.0,73.0,87.0,85.0,75.0,84.0,79.0,88.0,90.0,84.0,78.0,78.0,105.0,82.0,85.0,91.0,83.0,76.0,82.0,78.0,89.0,91.0,77.0,94.0,77.0,81.0,90.0,92.0,109.0,98.0,77.0,90.0,92.0,86.0,78.0,80.0,84.0,87.0,75.0,86.0,93.0,88.0,98.0,84.0,90.0,86.0,81.0,96.0,87.0,99.0,94.0,77.0,106.0,104.0,88.0,97.0,91.0,81.0,85.0,85.0,106.0,81.0,86.0,84.0,85.0,82.0,77.0,79.0,101.0,92.0,77.0,81.0,90.0,64.0,83.0,95.0,81.0,94.0,64.0,81.0,94.0,80.0,92.0,86.0,86.0,86.0,75.0,92.0,85.0,87.0,87.0,80.0,92.0,82.0,90.0,89.0,68.0,84.0,81.0,87.0,94.0,86.0,80.0,79.0,78.0,74.0,99.0,70.0,104.0,94.0,75.0,89.0,91.0,86.0,88.0,96.0,79.0,95.0,70.0,92.0,102.0,89.0,88.0,93.0,88.0,85.0,84.0,99.0,90.0,100.0,96.0,76.0,96.0,90.0,79.0,93.0,87.0,87.0,79.0,91.0,90.0,82.0,77.0,88.0,83.0,79.0,79.0,77.0,97.0,87.0,76.0,84.0,93.0,69.0,85.0,87.0,80.0,92.0,67.0,81.0,91.0,83.0,87.0,93.0,80.0,85.0,83.0,93.0,98.0,87.0,97.0,81.0,89.0,78.0,86.0,102.0,77.0,95.0,74.0,86.0,91.0,91.0,78.0,84.0,75.0,77.0,89.0,85.0,105.0,94.0,82.0,100.0,91.0,82.0,82.0,86.0,83.0,92.0,67.0,92.0,82.0,86.0,86.0,97.0,95.0,87.0,72.0,95.0,81.0,93.0,99.0,94.0,93.0,91.0,79.0,99.0,76.0,96.0,76.0,79.0,89.0,85.0,85.0,86.0,78.0,74.0,88.0,71.0,99.0,99.0,75.0,87.0,83.0,65.0,77.0,93.0,87.0,87.0,72.0,82.0,91.0,89.0,86.0,93.0,85.0,83.0,79.0,97.0,87.0,89.0,89.0,76.0,92.0,87.0,71.0,101.0,80.0,79.0,89.0,80.0,99.0,93.0,81.0,82.0,87.0,74.0,93.0,89.0,90.0,98.0,81.0,95.0,79.0,65.0,89.0,92.0,77.0,96.0,65.0,88.0,92.0,89.0,92.0,84.0,97.0,86.0,74.0,97.0,83.0,91.0,87.0,75.0,93.0,88.0,91.0,97.0,93.0,83.0,77.0,82.0,88.0,78.0,81.0,96.0,82.0,74.0,81.0,78.0,93.0,99.0,85.0,86.0,101.0,69.0,86.0,92.0,77.0,85.0,70.0,76.0,85.0,76.0,86.0,89.0,75.0,82.0,75.0,91.0,102.0,86.0,92.0,76.0,93.0,86.0,87.0,96.0,74.0,85.0,85.0,83.0,90.0,79.0,81.0,82.0,77.0,82.0,90.0,74.0,106.0,94.0,90.0,89.0,83.0,73.0,92.0,87.0,73.0,97.0,90.0,91.0,89.0,80.0,92.0,95.0,89.0,90.0,81.0,93.0,112.0,89.0,86.0,98.0,97.0,78.0,110.0,98.0,89.0,90.0,78.0,89.0,102.0,85.0,76.0,86.0,84.0,77.0,79.0,74.0,93.0,93.0,81.0,83.0,96.0,67.0,77.0,82.0,78.0,91.0,65.0,86.0,89.0,74.0,83.0,85.0,77.0,89.0,78.0,83.0,86.0,86.0,77.0,75.0,88.0,89.0,82.0,92.0,85.0,82.0,90.0,86.0,92.0,72.0,78.0,81.0,76.0,91.0,78.0,79.0,105.0,97.0,93.0,96.0,93.0,74.0,83.0,87.0,90.0,91.0,82.0,76.0,84.0,86.0,99.0,82.0,85.0,82.0,80.0,92.0,91.0,109.0,79.0,75.0,98.0,79.0,105.0,95.0,87.0,88.0,86.0,96.0,97.0,99.0,77.0,80.0,80.0,87.0,83.0,74.0,97.0,87.0,76.0,89.0,94.0,69.0,86.0,89.0,80.0,88.0,71.0,79.0,98.0,73.0,87.0,85.0,75.0,84.0,79.0,88.0,90.0,84.0,78.0,78.0,105.0,82.0,85.0,91.0,83.0,76.0,82.0,78.0,89.0,91.0,77.0,94.0,77.0,81.0,90.0,92.0,109.0,98.0,77.0,90.0,92.0,86.0,78.0,80.0,84.0,87.0,75.0,86.0,93.0,88.0,98.0,84.0,90.0,86.0,81.0,96.0,87.0,99.0,94.0,77.0,106.0,104.0,88.0,97.0,91.0,81.0,85.0,85.0,106.0,81.0,86.0,84.0,85.0,77.0,83.0,74.0,101.0,89.0,81.0,82.0,92.0,75.0,83.0,85.0,74.0,86.0,65.0,87.0,96.0,79.0,87.0,89.0,75.0,84.0,75.0,92.0,95.0,90.0,91.0,90.0,90.0,79.0,80.0,98.0,71.0,81.0,93.0,84.0,93.0,83.0,86.0,82.0,75.0,95.0,86.0,93.0,92.0,94.0,89.0,92.0,92.0,68.0,82.0,96.0,86.0,89.0,69.0,79.0,94.0,94.0,87.0,84.0,85.0,81.0,85.0,92.0,88.0,104.0,85.0,91.0,102.0,80.0,74.0,96.0,70.0,89.0,86.0,78.0,93.0,91.0,79.0,80.0,85.0,77.0,83.0,74.0,101.0,89.0,81.0,82.0,92.0,75.0,83.0,85.0,74.0,86.0,65.0,87.0,96.0,79.0,87.0,89.0,75.0,84.0,75.0,92.0,95.0,90.0,91.0,90.0,90.0,79.0,80.0,98.0,71.0,81.0,93.0,84.0,93.0,83.0,86.0,82.0,75.0,95.0,86.0,93.0,92.0,94.0,89.0,92.0,92.0,68.0,82.0,96.0,86.0,89.0,69.0,79.0,94.0,94.0,87.0,84.0,85.0,81.0,85.0,92.0,88.0,104.0,85.0,91.0,102.0,80.0,74.0,96.0,70.0,89.0,86.0,78.0,93.0,91.0,79.0,80.0,86.0,74.0,82.0,73.0,94.0,85.0,82.0,82.0,83.0,72.0,81.0,88.0,81.0,85.0,71.0,87.0,89.0,82.0,82.0,93.0,71.0,84.0,77.0,83.0,86.0,85.0,78.0,82.0,87.0,86.0,71.0,92.0,83.0,83.0,81.0,81.0,91.0,93.0,82.0,85.0,75.0,78.0,91.0,81.0,98.0,92.0,80.0,85.0,82.0,70.0,75.0,85.0,92.0,96.0,69.0,73.0,88.0,82.0,86.0,83.0,85.0,82.0,74.0,96.0,104.0,100.0,85.0,75.0,101.0,99.0,75.0,97.0,82.0,91.0,84.0,83.0,90.0,82.0,78.0,90.0,86.0,79.0,95.0,88.0,102.0,96.0,87.0,96.0,96.0,66.0,80.0,92.0,82.0,84.0,70.0,80.0,92.0,92.0,89.0,87.0,74.0,81.0,75.0,82.0,86.0,85.0,89.0,77.0,89.0,80.0,85.0,93.0,77.0,79.0,79.0,82.0,101.0,75.0,75.0,82.0,80.0,83.0,96.0,81.0,104.0,98.0,90.0,94.0,87.0,72.0,93.0,89.0,87.0,97.0,87.0,90.0,102.0,84.0,103.0,86.0,88.0,97.0,68.0,103.0,85.0,88.0,94.0,85.0,97.0,97.0,86.0,103.0,82.0,91.0,78.0,82.0,103.0,78.0,83.0,83.0,97.0,71.0,82.0,84.0,110.0,94.0,91.0,93.0,93.0,68.0,77.0,96.0,84.0,91.0,73.0,78.0,88.0,83.0,102.0,88.0,84.0,91.0,75.0,92.0,103.0,90.0,106.0,75.0,100.0,92.0,78.0,98.0,89.0,95.0,96.0,83.0,107.0,96.0,78.0,87.0,77.0,72.0,84.0,68.0,90.0,94.0,82.0,89.0,89.0,75.0,85.0,85.0,80.0,85.0,64.0,87.0,95.0,79.0,94.0,84.0,93.0,83.0,82.0,85.0,85.0,96.0,92.0,73.0,104.0,88.0,82.0,95.0,87.0,92.0,86.0,86.0,98.0,84.0,80.0,84.0)\n",
      "\n",
      "g_best <- as.factor(c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,54,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,58,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,60,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,63,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,65,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,66,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,67,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,68,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,69,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,70,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,71,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,72,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,74,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,75,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,77,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,79,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,81,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,83,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,87,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,88,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,89,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,90,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,91,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,92,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,93,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,94,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,95,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,96,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,97,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,98,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,101,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,102,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,103,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,104,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,105,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,106,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,107,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,108,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,109,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,110,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,112,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,113,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114,114))\n"
     ]
    }
   ],
   "source": [
    "# Extract variables for R analysis\n",
    "y = ''\n",
    "g = ''\n",
    "\n",
    "tmpY = ''\n",
    "tmpG = ''\n",
    "\n",
    "\n",
    "gkey = {}\n",
    "\n",
    "modeScore = {} # list of centralities for each modal edges cut value\n",
    "\n",
    "# this is to set the CONTROL for the R statistical tests (control = first centrality data that has to go in)\n",
    "\n",
    "# not sure - this would probably be the Leverage_Centrality_HL which has technically\n",
    "# the best modal score\n",
    "whichIDToKeepAsZero = 10\n",
    "\n",
    "for i_key, key in enumerate(list(centralities.keys())):\n",
    "    if(i_key < whichIDToKeepAsZero):\n",
    "        gkey[i_key + 1] = key\n",
    "    elif(i_key == whichIDToKeepAsZero):\n",
    "        gkey[0] = key\n",
    "    else:\n",
    "        gkey[i_key] = key\n",
    "        \n",
    "    centrality = centralities[key]\n",
    "    \n",
    "    # extract Edges Cut mode value\n",
    "    #UNCOMMENT THESE TO ENABLE MODE SCORE\n",
    "    #modescore = centrality.modeScores[2].split(':')\n",
    "    #mecut = float(modescore[0]) # value of mode of edges cut\n",
    "    #mcount = int(modescore[1]) # number of experiments with this modal value of edges cut\n",
    "    \n",
    "        \n",
    "    # store each centrality based on their modal value of edges cut\n",
    "    #overallmodescore = mecut / mcount\n",
    "    \n",
    "    # UNCOMMENT THIS TO ENABLE MODE SCORE\n",
    "    #overallmodescore = mecut\n",
    "\n",
    "    ## COMMENT THIS OUT IF WE DON?T WANT AVERAGE!!\n",
    "    #centrality.loadScores()\n",
    "    #centrality.computeStatsScore()\n",
    "    overallmodescore = centrality.avgScores[2]\n",
    "    \n",
    "    if overallmodescore in modeScore:\n",
    "        modeScore[overallmodescore].append(key)\n",
    "    else:\n",
    "        modeScore[overallmodescore] = [key]    \n",
    "    for i, score in enumerate(centrality.scores):\n",
    "        edges_cut = score[2]\n",
    "        \n",
    "        if(i_key == whichIDToKeepAsZero):\n",
    "            if(len(tmpY)):\n",
    "                tmpY += ','\n",
    "            tmpY += str(edges_cut)\n",
    "            if(len(tmpG)):\n",
    "                tmpG += ','\n",
    "            tmpG += str(0)\n",
    "            \n",
    "        else:        \n",
    "            if(len(y)):\n",
    "                y += ','\n",
    "            y += str(edges_cut)\n",
    "            if(len(g)):\n",
    "                g += ','\n",
    "            g += str(i_key)\n",
    "            #g += '\"' + str(i_key) + '\"'\n",
    "            if(i == 40):\n",
    "                break\n",
    "\n",
    "y = \"Y_best <- c(\" + tmpY + ',' + y + \")\"\n",
    "g = \"g_best <- as.factor(c(\" + tmpG + ',' + g + \"))\"\n",
    "print(y)\n",
    "print(\"\")\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target best mode centrality: 61\n",
      "k_best <- c(\"BottleNeck_centrality_LH\",\"AA_random\",\"Alpha_HL\",\"Alpha_LH\",\"Average_distance_HL\",\"Average_distance_LH\",\"Barycenter_centrality_HL\",\"Barycenter_centrality_LH\",\"Betweenness_HL\",\"Betweenness_LH\",\"BottleNeck_centrality_HL\",\"Bridging_centrality_HL\",\"Bridging_centrality_LH\",\"Centroid_centrality_HL\",\"Centroid_centrality_LH\",\"Closeness_Freeman_HL\",\"Closeness_Freeman_LH\",\"Closeness_VariantLatora_HL\",\"Closeness_VariantLatora_LH\",\"ClusterRank_HL\",\"ClusterRank_LH\",\"Communicability_betweenness_centrality_HL\",\"Communicability_betweenness_centrality_LH\",\"Community_centrality_HL\",\"Community_centrality_LH\",\"Core_decomposition_HL\",\"Core_decomposition_LH\",\"Cross_clique_centrality_LH\",\"Cross_clique_connectivity_HL\",\"Current_flow_closeness_centrality_HL\",\"Current_flow_closeness_centrality_LH\",\"Dangalchev_closeness_centrality_HL\",\"Dangalchev_closeness_centrality_LH\",\"Decay_centrality_HL\",\"Decay_centrality_LH\",\"Degree_centrality_HL\",\"Degree_centrality_LH\",\"Diffusion_degree_HL\",\"Diffusion_degree_LH\",\"DMNC_centrality_HL\",\"DMNC_centrality_LH\",\"Eccentricity_HL\",\"Eccentricity_LH\",\"Effectiveness_centrality_HL\",\"Effectiveness_centrality_LH\",\"Eigenvector_HL\",\"Eigenvector_LH\",\"Entropy_centrality_HL\",\"Entropy_centrality_LH\",\"EPC_HL\",\"EPC_LH\",\"Flow_betweenness_centrality_HL\",\"Flow_betweenness_centrality_LH\",\"Information_centrality_HL\",\"Information_centrality_LH\",\"Kleinbergs_centrality_HITS_HL\",\"Kleinbergs_centrality_HITS_LH\",\"LAC_HL\",\"LAC_LH\",\"Lapacian_centrality_HL\",\"Lapacian_centrality_LH\",\"Leverage_centrality_HL\",\"Leverage_centrality_LH\",\"Lin_centrality_HL\",\"Lin_centrality_LH\",\"Load_centrality_HL\",\"Load_centrality_LH\",\"Lobby_index_HL\",\"Lobby_index_LH\",\"Local_assortativity_HL\",\"Local_assortativity_LH\",\"Local_clustering_coefficients_HL\",\"Local_clustering_coefficients_LH\",\"Markov_centrality_HL\",\"Markov_centrality_LH\",\"MCC_centrality_HL\",\"MCC_centrality_LH\",\"MNC_centrality_HL\",\"MNC_centrality_LH\",\"Neighborhood_connectivity_HL\",\"Neighborhood_connectivity_LH\",\"Network_centrality_HL\",\"Network_centrality_LH\",\"Network_fragmentation_GeodesicDistanceWeighted_HL\",\"Network_fragmentation_GeodesicDistanceWeighted_LH\",\"Network_fragmentation_HL\",\"Network_fragmentation_LH\",\"Path_centrality_HL\",\"Path_centrality_LH\",\"Political_independence_index_HL\",\"Political_independence_index_LH\",\"Radiality_centrality_HL\",\"Radiality_centrality_LH\",\"Random_walk_betweenness_HL\",\"Random_walk_betweenness_LH\",\"Random_walk_closeness_HL\",\"Random_walk_closeness_LH\",\"SALSA_HL\",\"SALSA_LH\",\"Semi_local_centrality_HL\",\"Semi_local_centrality_LH\",\"Shortest_path_betweenness_HL\",\"Shortest_path_betweenness_LH\",\"Shortest_path_closeness_HL\",\"Shortest_path_closeness_LH\",\"Shortest_path_degree_HL\",\"Shortest_path_degree_LH\",\"Strength_weighted_vertex_degree_HL\",\"Strength_weighted_vertex_degree_LH\",\"Stress_centrality_HL\",\"Stress_centrality_LH\",\"Subgraph_HL\",\"Subgraph_LH\",\"Topological_coefficient_HL\",\"Topological_coefficient_LH\")\n"
     ]
    }
   ],
   "source": [
    "k = ''\n",
    "for key in sorted(gkey.keys()):\n",
    "    if(len(k)):\n",
    "        k += ','\n",
    "    k += '\"' + gkey[key] + '\"'\n",
    "    if gkey[key] == 'Leverage_centrality_HL':\n",
    "        print('target best mode centrality:', key)\n",
    "\n",
    "k = 'k_best <- c(' + k + ')'\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\t0.179643894705\t-0.116625988565\t0.137879900366\n",
      "0.179643894705\t1.0\t-0.0582464256174\t0.0155607029261\n",
      "-0.116625988565\t-0.0582464256174\t1.0\t-0.000613779411357\n",
      "0.137879900366\t0.0155607029261\t-0.000613779411357\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Kendall Tau code\n",
    "\n",
    "#edges cut, TCV, modularity and loneliness\n",
    "\n",
    "metricList = []\n",
    "metricList.append([])  # edges cut\n",
    "metricList.append([])  # edges cut\n",
    "metricList.append([])  # edges cut\n",
    "metricList.append([])  # edges cut\n",
    "\n",
    "\n",
    "for i_key, key in enumerate(list(centralities.keys())):        \n",
    "    centrality = centralities[key]\n",
    "    \n",
    "    # edges\n",
    "    modescore = centrality.modeScores[2].split(':')\n",
    "    metric = float(modescore[0]) # value of mode of edges cut\n",
    "    metricList[0].append(metric)\n",
    "\n",
    "    # TCV\n",
    "    modescore = centrality.modeScores[3].split(':')\n",
    "    metric = float(modescore[0]) # value of mode of edges cut\n",
    "    metricList[1].append(metric)    \n",
    "    \n",
    "    # Qds\n",
    "    modescore = centrality.modeScores[4].split(':')\n",
    "    metric = float(modescore[0]) # value of mode of edges cut\n",
    "    metricList[2].append(metric)\n",
    "    \n",
    "    # loneliness\n",
    "    modescore = centrality.modeScores[5].split(':')\n",
    "    metric = float(modescore[0]) # value of mode of edges cut\n",
    "    metricList[3].append(metric)\n",
    "\n",
    "taus = []\n",
    "pvals = []\n",
    "\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "for i in range(0, 4):\n",
    "    taus.append([])\n",
    "    pvals.append([])\n",
    "    for e in range(0, 4):\n",
    "        tau, pvalue = kendalltau(metricList[i], metricList[e])\n",
    "        #print(i, e, tau, pvalue)\n",
    "        taus[i].append(tau)\n",
    "        pvals[i].append(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\t0.179643894705\t-0.116625988565\t0.137879900366\n",
      "0.179643894705\t1.0\t-0.0582464256174\t0.0155607029261\n",
      "-0.116625988565\t-0.0582464256174\t1.0\t-0.000613779411357\n",
      "0.137879900366\t0.0155607029261\t-0.000613779411357\t1.0\n",
      "1.53871593044e-56\t0.00442255427753\t0.0646226393117\t0.0289171943463\n",
      "0.00442255427753\t1.53871593044e-56\t0.356072286027\t0.805257442494\n",
      "0.0646226393117\t0.356072286027\t1.53871593044e-56\t0.992240759871\n",
      "0.0289171943463\t0.805257442494\t0.992240759871\t1.53871593044e-56\n"
     ]
    }
   ],
   "source": [
    "for row in taus:\n",
    "    s = ''\n",
    "    for item in row:\n",
    "        if len(s) > 0:\n",
    "            s += \"\\t\"\n",
    "        s += str(item)\n",
    "    print(s)\n",
    "    \n",
    "for row in pvals:\n",
    "    s = ''\n",
    "    for item in row:\n",
    "        if len(s) > 0:\n",
    "            s += \"\\t\"\n",
    "        s += str(item)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# metrics important = \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def findBin(value, edges):\n",
    "    previousEdge = 0.0\n",
    "    for i, edge in enumerate(edges):\n",
    "        if i != 0:\n",
    "            if value >= previousEdge and value < edge:\n",
    "                return i\n",
    "        previousEdge = edge\n",
    "    return len(edges)\n",
    "\n",
    "def binScore(bin_id, num_bins, low_is_max = True):\n",
    "    half = int(num_bins * 0.5)\n",
    "    diff = 0\n",
    "    if(low_is_max):\n",
    "        if(bin_id > half):\n",
    "            return 0\n",
    "        diff = (half + 1 - bin_id)\n",
    "    else:\n",
    "        if(bin_id <= half):\n",
    "            return 0\n",
    "        diff = bin_id - half\n",
    "    return diff * 25 / half\n",
    "            \n",
    "        \n",
    "stats_metrics = [2, 3, 4, 5] # \"EDGES CUT\", \"TOTAL COMM VOLUME\", \"MODULARITY\", \"LONELINESS\"\n",
    "max_to_low_metrics = [4]\n",
    "\n",
    "means = {}\n",
    "stds = {}\n",
    "skews = {}\n",
    "\n",
    "means_hist = {}\n",
    "means_binedges = {}\n",
    "stds_hist = {}\n",
    "stds_binedges = {}\n",
    "skews_hist = {}\n",
    "skews_binedges = {}\n",
    "\n",
    "\n",
    "\n",
    "for stat in stats_metrics:\n",
    "    means[stat] = []\n",
    "    stds[stat] = []\n",
    "    skews[stat] = []\n",
    "    means_hist[stat] = {}\n",
    "    means_binedges[stat] = {}\n",
    "    stds_hist[stat] = {}\n",
    "    stds_binedges[stat] = {}\n",
    "    skews_hist[stat] = {}\n",
    "    skews_binedges[stat] = {}\n",
    "\n",
    "\n",
    "for key in list(centralities.keys()):\n",
    "    centrality = centralities[key]\n",
    "    centralityCode = centrality.centralityType + \":\" + centrality.orderType\n",
    "    \n",
    "    centrality.loadScores()\n",
    "    centrality.computeStatsScore()\n",
    "    \n",
    "    for smetric in stats_metrics:\n",
    "        means[smetric].append(centrality.avgScores[smetric])\n",
    "        stds[smetric].append(centrality.stdScores[smetric])\n",
    "        skews[smetric].append(centrality.skewnessScores[smetric])\n",
    "\n",
    "\n",
    "        \n",
    "for stat in stats_metrics:\n",
    "    means[stat] = np.array(means[stat])\n",
    "    stds[stat] = np.array(stds[stat])\n",
    "    skews[stat] = np.array(skews[stat])\n",
    "    \n",
    "    means_hist[stat], means_binedges[stat] = np.histogram(means[stat], bins='auto')\n",
    "    stds_hist[stat], stds_binedges[stat] = np.histogram(stds[stat], bins='auto')\n",
    "    skews_hist[stat], skews_binedges[stat] = np.histogram(skews[stat], bins='auto')\n",
    "\n",
    "rank = {}\n",
    "\n",
    "for key in list(centralities.keys()):\n",
    "    # compute scores for this statistic for each centrality\n",
    "    centrality = centralities[key]\n",
    "\n",
    "    centrality.totalScore = 0.0\n",
    "\n",
    "    for smetric in stats_metrics:\n",
    "        mu = centrality.avgScores[smetric]\n",
    "        std = centrality.stdScores[smetric]\n",
    "        skew = centrality.skewnessScores[smetric]\n",
    "\n",
    "        mean_bins = len(means_hist[stat])\n",
    "        std_bins = len(stds_hist[stat])\n",
    "        skew_bins = len(skews_hist[stat])\n",
    "\n",
    "        low_is_max = True\n",
    "        if smetric in max_to_low_metrics:\n",
    "            low_is_max = False\n",
    "\n",
    "        # mean should either be max or min\n",
    "        mu_score = binScore(findBin(mu, means_binedges[smetric]), mean_bins, low_is_max)\n",
    "        # std score should always be minimized\n",
    "        std_score = binScore(findBin(std, stds_binedges[smetric]), std_bins)\n",
    "        skew_score = binScore(findBin(skew, skews_binedges[smetric]), skew_bins, low_is_max)\n",
    "        \n",
    "        # override skew score\n",
    "        skew_score = 0.0\n",
    "        \n",
    "        centrality.totalScore += mu_score + std_score + skew_score\n",
    "    print(centrality.centralityType + \":\" + centrality.orderType, centrality.totalScore)\n",
    "    if centrality.totalScore in rank:\n",
    "        rank[centrality.totalScore].append(centrality.centralityType + \":\" + centrality.orderType)\n",
    "    else:\n",
    "        rank[centrality.totalScore] = [centrality.centralityType + \":\" + centrality.orderType]\n",
    "\n",
    "count = 0\n",
    "for key in sorted(rank, reverse=True):\n",
    "    for item in rank[key]:\n",
    "        count += 1\n",
    "        print(count, key, item)\n",
    "        if count == 20:\n",
    "            print(\"===================\")\n",
    "        \n",
    "for stat in stats_metrics:\n",
    "    break\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ax1 = fig.add_subplot(1,3,1)\n",
    "    ax1.hist(means[stat])\n",
    "\n",
    "    ax2 = fig.add_subplot(1,3,2)\n",
    "    ax2.hist(stds[stat])\n",
    "\n",
    "    ax3 = fig.add_subplot(1,3,3)\n",
    "    ax3.hist(skews[stat])\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "randomCentrality = centralities[\"AA_random\"]\n",
    "\n",
    "mu_stats = {}\n",
    "std_stats = {}\n",
    "\n",
    "for stat in stats_metrics:\n",
    "    mu_stats[stat] = np.mean(means[stat])\n",
    "    std_stats[stat] = np.std(means[stat])\n",
    "    \n",
    "# z - scores\n",
    "for key in list(centralities.keys()):\n",
    "    # compute scores for this statistic for each centrality\n",
    "    centrality = centralities[key]\n",
    "    if key == \"AA_random\":\n",
    "        continue\n",
    "    \n",
    "    # compute z-score\n",
    "    stats_metrics = [2, 3, 4, 5] # \"EDGES CUT\", \"TOTAL COMM VOLUME\", \"MODULARITY\", \"LONELINESS\"\n",
    "\n",
    "    print(\"Z-SCORE: \", centrality.centralityType + \":\" + centrality.orderType)\n",
    "    \n",
    "    for stat in stats_metrics:\n",
    "        x = centrality.avgScores[stat]\n",
    "        \n",
    "        zscore = (x - mu_stats[stat]) / std_stats[stat]\n",
    "        tabs = \"\\t\\t\"\n",
    "        if stat == 3:\n",
    "            tabs = \"\\t\"\n",
    "        print(\"   \", cols[stat], tabs, \"{0:.5f}\".format(zscore), \"\\t\", \"{0:.5f}\".format(sstats.norm.cdf(zscore)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
