{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['partition']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import platform\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from graph_partitioning import GraphPartitioning, utils\n",
    "\n",
    "cols = [\"WASTE\", \"CUT RATIO\", \"EDGES CUT\", \"TOTAL COMM VOLUME\", \"MODULARITY\", \"LONELINESS\", \"NETWORK PERMANENCE\", \"NORM. MUTUAL INFO\"]\n",
    "pwd = %pwd\n",
    "\n",
    "\n",
    "# parametrized config\n",
    "parametrized_config = {\n",
    "    \"DATA_FILENAME\": os.path.join(pwd, \"data\", \"predition_model_tests\", \"network\", \"network_#networkID#.txt\"),\n",
    "    \"OUTPUT_DIRECTORY\": os.path.join(pwd, \"output\"),\n",
    "\n",
    "    # Set which algorithm is run for the PREDICTION MODEL.\n",
    "    # Either: 'FENNEL' or 'SCOTCH'\n",
    "    \"PREDICTION_MODEL_ALGORITHM\": \"\",\n",
    "\n",
    "    # Alternativly, read input file for prediction model.\n",
    "    # Set to empty to generate prediction model using algorithm value above.\n",
    "    \"PREDICTION_MODEL\": \"\",\n",
    "\n",
    "    \n",
    "    \"PARTITIONER_ALGORITHM\": \"\",\n",
    "\n",
    "    # File containing simulated arrivals. This is used in simulating nodes\n",
    "    # arriving at the shelter. Nodes represented by line number; value of\n",
    "    # 1 represents a node as arrived; value of 0 represents the node as not\n",
    "    # arrived or needing a shelter.\n",
    "    \"SIMULATED_ARRIVAL_FILE\": os.path.join(pwd,\n",
    "                                           \"data\",\n",
    "                                           \"predition_model_tests\",\n",
    "                                           \"dataset_1_shift_rotate\",\n",
    "                                           \"simulated_arrival_list\",\n",
    "                                           \"percentage_of_prediction_correct_#correctedness#\",\n",
    "                                           \"arrival_#correctedness#_#networkID#.txt\"\n",
    "                                          ),\n",
    "    \n",
    "    # File containing the prediction of a node arriving. This is different to the\n",
    "    # simulated arrivals, the values in this file are known before the disaster.\n",
    "    \"PREDICTION_LIST_FILE\": os.path.join(pwd,\n",
    "                                         \"data\",\n",
    "                                         \"predition_model_tests\",\n",
    "                                         \"dataset_1_shift_rotate\",\n",
    "                                         \"prediction_list\",\n",
    "                                         \"prediction_#networkID#.txt\"\n",
    "                                        ),\n",
    "\n",
    "    # File containing the geographic location of each node, in \"x,y\" format.\n",
    "    \"POPULATION_LOCATION_FILE\": os.path.join(pwd,\n",
    "                                             \"data\",\n",
    "                                             \"predition_model_tests\",\n",
    "                                             \"coordinates\",\n",
    "                                             \"coordinates_#networkID#.txt\"\n",
    "                                            ),\n",
    "\n",
    "    # Number of shelters\n",
    "    \"num_partitions\": 6,\n",
    "\n",
    "    # The number of iterations when making prediction model\n",
    "    \"num_iterations\": 1,\n",
    "\n",
    "    # Percentage of prediction model to use before discarding\n",
    "    # When set to 0, prediction model is discarded, useful for one-shot\n",
    "    \"prediction_model_cut_off\": 0.10,\n",
    "\n",
    "    # Alpha value used in one-shot (when restream_batches set to 1)\n",
    "    \"one_shot_alpha\": 0.5,\n",
    "\n",
    "    # Number of arrivals to batch before recalculating alpha and restreaming.\n",
    "    # When set to 1, one-shot is used with alpha value from above\n",
    "    \"restream_batches\": 10,\n",
    "\n",
    "    # When the batch size is reached: if set to True, each node is assigned\n",
    "    # individually as first in first out. If set to False, the entire batch\n",
    "    # is processed and empty before working on the next batch.\n",
    "    \"sliding_window\": False,\n",
    "\n",
    "    # Create virtual nodes based on prediction model\n",
    "    \"use_virtual_nodes\": False,\n",
    "\n",
    "    # Virtual nodes: edge weight\n",
    "    \"virtual_edge_weight\": 1.0,\n",
    "\n",
    "    # Loneliness score parameter. Used when scoring a partition by how many\n",
    "    # lonely nodes exist.\n",
    "    \"loneliness_score_param\": 1.2,\n",
    "\n",
    "    ####\n",
    "    # GRAPH MODIFICATION FUNCTIONS\n",
    "\n",
    "    # Also enables the edge calculation function.\n",
    "    \"graph_modification_functions\": True,\n",
    "\n",
    "    # If set, the node weight is set to 100 if the node arrives at the shelter,\n",
    "    # otherwise the node is removed from the graph.\n",
    "    \"alter_arrived_node_weight_to_100\": False,\n",
    "\n",
    "    # Uses generalized additive models from R to generate prediction of nodes not\n",
    "    # arrived. This sets the node weight on unarrived nodes the the prediction\n",
    "    # given by a GAM.\n",
    "    # Needs POPULATION_LOCATION_FILE to be set.\n",
    "    \"alter_node_weight_to_gam_prediction\": False,\n",
    "\n",
    "    # The value of 'k' used in the GAM will be the number of nodes arrived until\n",
    "    # it reaches this max value.\n",
    "    \"gam_k_value\": 100,\n",
    "\n",
    "    # Alter the edge weight for nodes that haven't arrived. This is a way to\n",
    "    # de-emphasise the prediction model for the unknown nodes.\n",
    "    \"prediction_model_emphasis\": 1.0,\n",
    "    \n",
    "    # This applies the prediction_list_file node weights onto the nodes in the graph\n",
    "    # when the prediction model is being computed and then removes the weights\n",
    "    # for the cutoff and batch arrival modes\n",
    "    \"apply_prediction_model_weights\": True,\n",
    "    \n",
    "    # Path to the scotch shared library\n",
    "    \"SCOTCH_LIB_PATH\": os.path.join(pwd, \"libs/scotch/macOS/libscotch.dylib\")\n",
    "    if 'Darwin' in platform.system()\n",
    "    else \"/usr/local/lib/libscotch.so\",\n",
    "    \n",
    "    # Path to the PaToH shared library\n",
    "    \"PATOH_LIB_PATH\": os.path.join(pwd, \"libs/patoh/lib/macOS/libpatoh.dylib\")\n",
    "    if 'Darwin' in platform.system()\n",
    "    else os.path.join(pwd, \"libs/patoh/lib/linux/libpatoh.so\"),\n",
    "    \n",
    "    \"PATOH_ITERATIONS\": 5,\n",
    "\n",
    "    # Alters how much information to print. Keep it at 1 for this notebook.\n",
    "    # 0 - will print nothing, useful for batch operations.\n",
    "    # 1 - prints basic information on assignments and operations.\n",
    "    # 2 - prints more information as it batches arrivals.\n",
    "    \"verbose\": 0\n",
    "}\n",
    "\n",
    "#gp = GraphPartitioning(config)\n",
    "\n",
    "# Optional: shuffle the order of nodes arriving\n",
    "# Arrival order should not be shuffled if using GAM to alter node weights\n",
    "#random.shuffle(gp.arrival_order)\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getOutFileName(algorithm, partition, correctedness, cutoff, networkID, sliding, virtualNodes, gam):\n",
    "    fn = algorithm + \"_p\" + str(partition) + \"_c\" + str(correctedness) + \"_cutoff\" + str(int(cutoff * 100))\n",
    "    fn += \"_sw\" + str(int(sliding)) + \"_vn\" + str(int(virtualNodes)) + \"_gam\" + str(int(gam)) + \"_\" + str(networkID)\n",
    "    return fn + \".txt\"\n",
    "\n",
    "def getConfig(parametrized_config, algorithm, partition, correctedness, cutoff, networkID, sliding, virtualNodes, gam):\n",
    "    newConfig = parametrized_config.copy()\n",
    "    for confKey in list(newConfig.keys()):\n",
    "        changed = False\n",
    "        conf = newConfig[confKey]\n",
    "        try:\n",
    "            if \"#networkID#\" in str(conf):\n",
    "                conf = conf.replace(\"#networkID#\", str(networkID))\n",
    "                changed = True\n",
    "            if \"#correctedness#\" in str(conf):\n",
    "                conf = conf.replace(\"#correctedness#\", str(correctedness))\n",
    "                changed = True\n",
    "        except Excpetion as err:\n",
    "            pass\n",
    "        if changed:\n",
    "            newConfig[confKey] = conf\n",
    "    newConfig[\"PREDICTION_MODEL_ALGORITHM\"] = algorithm\n",
    "    newConfig[\"PARTITIONER_ALGORITHM\"] = algorithm\n",
    "    newConfig[\"prediction_model_cut_off\"] = cutoff\n",
    "    newConfig[\"sliding_window\"] = sliding\n",
    "    newConfig[\"use_virtual_nodes\"] = virtualNodes\n",
    "    newConfig[\"alter_node_weight_to_gam_prediction\"] = gam\n",
    "    return newConfig\n",
    "\n",
    "def experimentParentDir():\n",
    "    return os.path.join(parametrized_config[\"OUTPUT_DIRECTORY\"], datetime.datetime.now().strftime('%y_%m_%d').replace(\"/\", \"\"))\n",
    "\n",
    "def experimentDir():\n",
    "    return os.path.join(experimentParentDir(), datetime.datetime.now().strftime('%H_%M_%S'))\n",
    "\n",
    "def purgeEmptyDir(directory):\n",
    "    for dirpath, dirnames, files in os.walk(directory):\n",
    "        if not files:\n",
    "            os.rmdir(directory)\n",
    "\n",
    "def cutoffValueFunc(val):\n",
    "    return val * 0.05\n",
    "\n",
    "def times10(val):\n",
    "    return val * 10\n",
    "\n",
    "def fillRange(minN, maxN, valueFunc = None):\n",
    "    values = []\n",
    "    for p in range(minN, maxN):\n",
    "        if valueFunc is None:\n",
    "            values.append(p)\n",
    "        else:\n",
    "            values.append(valueFunc(p))\n",
    "    return values\n",
    "\n",
    "class OutFile:\n",
    "    def __init__(self, filePath):\n",
    "        self.contents = []\n",
    "        self.filePath = filePath\n",
    "    \n",
    "    def write(self, moreContent):\n",
    "        self.contents.append(moreContent)\n",
    "\n",
    "    def save(self):\n",
    "        with open(self.filePath, 'w+') as f:\n",
    "            for content in self.contents:\n",
    "                f.write(content)\n",
    "\n",
    "def writeConfig(outFile, config, numPartitions, networkID):\n",
    "    outFile.write(\"PREDICTION_MODEL_ALGORITHM = \" + str(config[\"PREDICTION_MODEL_ALGORITHM\"]) + \"\\n\")\n",
    "    outFile.write(\"PARTITIONER_ALGORITHM = \" + str(config[\"PARTITIONER_ALGORITHM\"]) + \"\\n\")\n",
    "    outFile.write(\"partitions = \" + str(numPartitions) + \"\\n\")\n",
    "    outFile.write(\"networkID = \" + str(networkID) + \"\\n\")\n",
    "    outFile.write(\"prediction_model_cut_off = \" + str(config[\"prediction_model_cut_off\"]) + \"\\n\")\n",
    "    outFile.write(\"sliding_window = \" + str(config[\"sliding_window\"]) + \"\\n\")\n",
    "    outFile.write(\"virtual_nodes = \" + str(config[\"use_virtual_nodes\"]) + \"\\n\")\n",
    "    outFile.write(\"gam = \" + str(config[\"alter_node_weight_to_gam_prediction\"]) + \"\\n\")\n",
    "\n",
    "def writeArray(outFile, arrayName, array, valuesPerLine = 50):\n",
    "    outFile.write(\"\\nSTARTARRAY-\" + arrayName + \"\\n[\")\n",
    "    \n",
    "    line = \"\"\n",
    "    count = 0\n",
    "    isFirst = True\n",
    "    for value in array:\n",
    "        if(len(line)):\n",
    "            # add comma to separate from previous\n",
    "            line += \", \"\n",
    "        # add new line if we've reached valuesPerLine\n",
    "        if(count == valuesPerLine):\n",
    "            count = 0;\n",
    "            line += \"\\n\"\n",
    "        line += str(value)\n",
    "        count += 1\n",
    "    if len(line) > 0:\n",
    "        outFile.write(line)\n",
    "    outFile.write(\"]\\nENDARRAY\\n\")\n",
    "\n",
    "def writePartitionStats(outFile, section, gp, m):\n",
    "    #print(\"writePartitionStats\", outFile.contents)\n",
    "    writeArray(outFile, section, gp.assignments)\n",
    "    \n",
    "    population = utils.get_partition_population(gp.G, gp.assignments, gp.num_partitions)\n",
    "\n",
    "    outFile.write(\"\\nSTARTSTATS FOR \" + section + \"\\n\")\n",
    "    outFile.write(\"Partitions - nodes (weight)\\n\\n\")\n",
    "    for p in population:\n",
    "        outFile.write(\"P{}: {} ({})\\n\".format(p, population[p][0], population[p][1]))\n",
    "\n",
    "    # print dataframe stats now\n",
    "    outFile.write(\"\\nWASTE, CUT RATIO, EDGES CUT, TOTAL COMM VOLUME, MODULARITY, LONELINESS, NETWORK PERMANENCE, NORM. MUTUAL INFO\\n\\n\")\n",
    "    for row in m:\n",
    "        line = \"\"\n",
    "        for value in row:\n",
    "            if len(line) > 0:\n",
    "                line += \", \"\n",
    "            line += str(value)\n",
    "        outFile.write(line + \"\\n\")\n",
    "    outFile.write(\"ENDSTATS\\n\")\n",
    "    \n",
    "\n",
    "def runPartitioning(config, outFilePath, numPartitions, networkID):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    gp = GraphPartitioning(config)\n",
    "    \n",
    "    outFile = OutFile(outFilePath)\n",
    "    writeConfig(outFile, config, numPartitions, networkID)\n",
    "    \n",
    "    gp.load_network()\n",
    "    gp.init_partitioner()\n",
    "    \n",
    "    m = gp.prediction_model()\n",
    "    writePartitionStats(outFile, \"prediction_model\", gp, m)\n",
    "        \n",
    "    m = gp.assign_cut_off()\n",
    "    writePartitionStats(outFile, \"cutof\", gp, m)\n",
    "\n",
    "    m = gp.batch_arrival()\n",
    "    writePartitionStats(outFile, \"batch_arrivals\", gp, m)\n",
    "    \n",
    "    outFile.write(\"Experiment duration = \" + str(time.time() - start_time))\n",
    "    outFile.save()\n",
    "    \n",
    "    del m\n",
    "    del gp\n",
    "    del outFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# All possible ways to run the experiments\n",
    "all_algorithms = [\"FENNEL\", \"SCOTCH\", \"PATOH\"]\n",
    "\n",
    "all_correctedness = fillRange(0, 11, times10)\n",
    "all_partitions = fillRange(4, 13)\n",
    "all_networks = fillRange(1, 1001)\n",
    "all_predictionModelCutoff = fillRange(0, 21, cutoffValueFunc)\n",
    "\n",
    "storeResults = True\n",
    "\n",
    "all_slidingWindow = [True, False]\n",
    "all_virtualNodes = [True, False]\n",
    "all_GAMModel = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-eeaa8a92687e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m                                 \u001b[0;31m#with open(outfPath, 'w+') as experimentFile:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                                     \u001b[0;31m# run experiment and store results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                                 \u001b[0mrunPartitioning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                                 \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-2a5ede41fdff>\u001b[0m in \u001b[0;36mrunPartitioning\u001b[0;34m(config, outFilePath, numPartitions, networkID)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mwritePartitionStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"batch_arrivals\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0moutFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Experiment duration = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0moutFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT 1: how does changing the cutoff on prediction model, alter how well partitions can be made\n",
    "\n",
    "# todo avoid double experiments, cutoff, size of batch\n",
    "# todo check edgescut = subset of population\n",
    "\n",
    "# pick a subset of settings, if needed\n",
    "algorithms = all_algorithms\n",
    "partitions = [4, 6, 8]\n",
    "correctedness = [100]\n",
    "predictionModelCutoff = [0.2]\n",
    "networks = [1]\n",
    "slidingWindows = [False]\n",
    "virtualNodes = [False]\n",
    "GAMModels = [False]\n",
    "\n",
    "outputDir = experimentDir()\n",
    "if not os.path.exists(outputDir):\n",
    "    os.makedirs(outputDir)\n",
    "\n",
    "experimentCount = 0\n",
    "experimentTimes = []\n",
    "\n",
    "dontRunExperiments = False # safety net to avoid overwriting experiments\n",
    "for algorithm in algorithms:\n",
    "    # run the experiment separately for each algorithm\n",
    "    if dontRunExperiments == True:\n",
    "        break\n",
    "        \n",
    "    for partition in partitions:\n",
    "        # run the experiment with differnt number of partitions\n",
    "        for correct in correctedness:\n",
    "            # run the experiment for different correctedness predictions\n",
    "            for cutoff in predictionModelCutoff:\n",
    "                # this is the real experiment - different cutoff values\n",
    "                for network in networks:\n",
    "                    # sliding window\n",
    "                    for sliding in slidingWindows:\n",
    "                        # virtual nodes\n",
    "                        for virtualNode in virtualNodes:\n",
    "                            # GAM\n",
    "                            for GAMModel in GAMModels:\n",
    "                                start_time = time.time()\n",
    "\n",
    "                                # setup the experiment\n",
    "                                config = getConfig(parametrized_config, algorithm, partition, correct, cutoff, network, sliding, virtualNode, GAMModel)\n",
    "\n",
    "                                outFN = getOutFileName(algorithm, partition, correct, cutoff, network, sliding, virtualNode, GAMModel)\n",
    "                                outfPath = os.path.join(outputDir, outFN)\n",
    "                                #with open(outfPath, 'w+') as experimentFile:\n",
    "                                    # run experiment and store results\n",
    "                                runPartitioning(config, outfPath, partition, network)\n",
    "                                \n",
    "                                elapsed_time = time.time() - start_time\n",
    "                                print(\"Experiment\", experimentCount, elapsed_time, outFN)\n",
    "                                experimentTimes.append(elapsed_time)\n",
    "                                experimentCount += 1\n",
    "\n",
    "purgeEmptyDir(outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
