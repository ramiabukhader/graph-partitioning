{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import platform\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from graph_partitioning import GraphPartitioning, utils\n",
    "\n",
    "cols = [\"WASTE\", \"CUT RATIO\", \"EDGES CUT\", \"TOTAL COMM VOLUME\", \"MODULARITY\", \"LONELINESS\", \"NETWORK PERMANENCE\", \"NORM. MUTUAL INFO\", \"EDGE CUT WEIGHT\", \"FSCORE\", \"FSCORE RELABEL IMPROVEMENT\"]\n",
    "pwd = %pwd\n",
    "\n",
    "\n",
    "# [] send: experiement plots, ask what was expected output/behaviour + new experiments list\n",
    "# [] test size & density of networks: test if fennel is better always or certain network setups\n",
    "# [] edge expansion off - is it off for patoh as well?\n",
    "\n",
    "# [] networkkit PermanenceCentrality - check maxperm works with sorted nodes: permanence gives out the same score\n",
    "# make maxperm work\n",
    "# community detection -> permanence score\n",
    "\n",
    "# [] randomize order of people, everyone arrives if no file there\n",
    "# [] setup computer ready\n",
    "\n",
    "\n",
    "# [] STATS fennel reoerdering centrality = minimal population size\n",
    "# [] centrality: impact on SCOTCH + PATOH\n",
    "# [] centrality: everyone people batch, 1.0 node and edge weight, everyone arrives\n",
    "\n",
    "\n",
    "# [] (scale virtual node weight * percentage of highest partition score at the moment and update the virtual node weight)\n",
    "# [] stability?\n",
    "# [] automatic detection of edgelist/metis\n",
    "\n",
    "\n",
    "# [x] edge weights for people + new metric for cost of cutting valuable edges\n",
    "# [x] generate edge weights\n",
    "# [x] hyperedge expansion for patoh\n",
    "# [x] NDA/IP\n",
    "# [x] add f-score before relabeling + fscore after relabeling metric (delta between the two)\n",
    "# [x] add Random generated dataset\n",
    "\n",
    "\n",
    "# 18.45 - 19.45 start\n",
    "\n",
    "'''\n",
    "1. edge weights\n",
    "2. new metrics - + random generated datasets\n",
    "3. experiments\n",
    "4. centrality stuff - stats functions/equations used at the moment to compute the scores for centralities\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# parametrized config\n",
    "parametrized_config = {\n",
    "    \"DATA_FILENAME\": os.path.join(pwd, \"data\", \"predition_model_tests\", \"network\", \"network_#networkID#.txt\"),\n",
    "    \"OUTPUT_DIRECTORY\": os.path.join(pwd, \"output\"),\n",
    "\n",
    "    # Set which algorithm is run for the PREDICTION MODEL.\n",
    "    # Either: 'FENNEL' or 'SCOTCH'\n",
    "    \"PREDICTION_MODEL_ALGORITHM\": \"\",\n",
    "\n",
    "    # Alternativly, read input file for prediction model.\n",
    "    # Set to empty to generate prediction model using algorithm value above.\n",
    "    \"PREDICTION_MODEL\": \"\",\n",
    "\n",
    "    \n",
    "    \"PARTITIONER_ALGORITHM\": \"\",\n",
    "\n",
    "    # File containing simulated arrivals. This is used in simulating nodes\n",
    "    # arriving at the shelter. Nodes represented by line number; value of\n",
    "    # 1 represents a node as arrived; value of 0 represents the node as not\n",
    "    # arrived or needing a shelter.\n",
    "    \"SIMULATED_ARRIVAL_FILE\": os.path.join(pwd,\n",
    "                                           \"data\",\n",
    "                                           \"predition_model_tests\",\n",
    "                                           \"dataset_1_shift_rotate\",\n",
    "                                           \"simulated_arrival_list\",\n",
    "                                           \"percentage_of_prediction_correct_#correctedness#\",\n",
    "                                           \"arrival_#correctedness#_#networkID#.txt\"\n",
    "                                          ),\n",
    "    \n",
    "    # File containing the prediction of a node arriving. This is different to the\n",
    "    # simulated arrivals, the values in this file are known before the disaster.\n",
    "    \"PREDICTION_LIST_FILE\": os.path.join(pwd,\n",
    "                                         \"data\",\n",
    "                                         \"predition_model_tests\",\n",
    "                                         \"dataset_1_shift_rotate\",\n",
    "                                         \"prediction_list\",\n",
    "                                         \"prediction_#networkID#.txt\"\n",
    "                                        ),\n",
    "\n",
    "    # File containing the geographic location of each node, in \"x,y\" format.\n",
    "    \"POPULATION_LOCATION_FILE\": os.path.join(pwd,\n",
    "                                             \"data\",\n",
    "                                             \"predition_model_tests\",\n",
    "                                             \"coordinates\",\n",
    "                                             \"coordinates_#networkID#.txt\"\n",
    "                                            ),\n",
    "\n",
    "    # Number of shelters\n",
    "    \"num_partitions\": 6,\n",
    "\n",
    "    # The number of iterations when making prediction model\n",
    "    \"num_iterations\": 1,\n",
    "\n",
    "    # Percentage of prediction model to use before discarding\n",
    "    # When set to 0, prediction model is discarded, useful for one-shot\n",
    "    \"prediction_model_cut_off\": 0.10,\n",
    "\n",
    "    # Alpha value used in one-shot (when restream_batches set to 1)\n",
    "    \"one_shot_alpha\": 0.5,\n",
    "\n",
    "    # Number of arrivals to batch before recalculating alpha and restreaming.\n",
    "    # When set to 1, one-shot is used with alpha value from above\n",
    "    \"restream_batches\": 10,\n",
    "\n",
    "    # When the batch size is reached: if set to True, each node is assigned\n",
    "    # individually as first in first out. If set to False, the entire batch\n",
    "    # is processed and empty before working on the next batch.\n",
    "    \"sliding_window\": False,\n",
    "\n",
    "    # Create virtual nodes based on prediction model\n",
    "    \"use_virtual_nodes\": False,\n",
    "\n",
    "    # Virtual nodes: edge weight\n",
    "    \"virtual_edge_weight\": 1.0,\n",
    "\n",
    "    # Loneliness score parameter. Used when scoring a partition by how many\n",
    "    # lonely nodes exist.\n",
    "    \"loneliness_score_param\": 1.2,\n",
    "\n",
    "    ####\n",
    "    # GRAPH MODIFICATION FUNCTIONS\n",
    "\n",
    "    # Also enables the edge calculation function.\n",
    "    \"graph_modification_functions\": True,\n",
    "\n",
    "    # If set, the node weight is set to 100 if the node arrives at the shelter,\n",
    "    # otherwise the node is removed from the graph.\n",
    "    \"alter_arrived_node_weight_to_100\": False,\n",
    "\n",
    "    # Uses generalized additive models from R to generate prediction of nodes not\n",
    "    # arrived. This sets the node weight on unarrived nodes the the prediction\n",
    "    # given by a GAM.\n",
    "    # Needs POPULATION_LOCATION_FILE to be set.\n",
    "    \"alter_node_weight_to_gam_prediction\": False,\n",
    "\n",
    "    # Enables edge expansion when graph_modification_functions is set to true\n",
    "    \"edge_expansion_enabled\": True,\n",
    "    \n",
    "    # The value of 'k' used in the GAM will be the number of nodes arrived until\n",
    "    # it reaches this max value.\n",
    "    \"gam_k_value\": 100,\n",
    "\n",
    "    # Alter the edge weight for nodes that haven't arrived. This is a way to\n",
    "    # de-emphasise the prediction model for the unknown nodes.\n",
    "    \"prediction_model_emphasis\": 1.0,\n",
    "    \n",
    "    # This applies the prediction_list_file node weights onto the nodes in the graph\n",
    "    # when the prediction model is being computed and then removes the weights\n",
    "    # for the cutoff and batch arrival modes\n",
    "    \"apply_prediction_model_weights\": True,\n",
    "    \n",
    "    # Path to the scotch shared library\n",
    "    \"SCOTCH_LIB_PATH\": os.path.join(pwd, \"libs/scotch/macOS/libscotch.dylib\")\n",
    "    if 'Darwin' in platform.system()\n",
    "    else \"/usr/local/lib/libscotch.so\",\n",
    "    \n",
    "    # Path to the PaToH shared library\n",
    "    \"PATOH_LIB_PATH\": os.path.join(pwd, \"libs/patoh/lib/macOS/libpatoh.dylib\")\n",
    "    if 'Darwin' in platform.system()\n",
    "    else os.path.join(pwd, \"libs/patoh/lib/linux/libpatoh.so\"),\n",
    "    \n",
    "    \"PATOH_ITERATIONS\": 5,\n",
    "\n",
    "    # Expansion modes: 'avg_node_weight', 'total_node_weight', 'smallest_node_weight'\n",
    "    # 'largest_node_weight'\n",
    "    # add '_squared' or '_sqrt' at the end of any of the above for ^2 or sqrt(weight)\n",
    "    # i.e. 'avg_node_weight_squared\n",
    "    \"PATOH_HYPEREDGE_EXPANSION_MODE\": 'avg_node_weight',\n",
    "\n",
    "\n",
    "    # Alters how much information to print. Keep it at 1 for this notebook.\n",
    "    # 0 - will print nothing, useful for batch operations.\n",
    "    # 1 - prints basic information on assignments and operations.\n",
    "    # 2 - prints more information as it batches arrivals.\n",
    "    \"verbose\": 0\n",
    "}\n",
    "\n",
    "#gp = GraphPartitioning(config)\n",
    "\n",
    "# Optional: shuffle the order of nodes arriving\n",
    "# Arrival order should not be shuffled if using GAM to alter node weights\n",
    "#random.shuffle(gp.arrival_order)\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import experiments.io as expIO\n",
    "import experiments.utils as expUtils\n",
    "\n",
    "def runPartitioning(config, outFilePath, numPartitions, networkID):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    gp = GraphPartitioning(config)\n",
    "    \n",
    "    outFile = expIO.OutFile(outFilePath)\n",
    "    expIO.writeConfig(outFile, config, numPartitions, networkID)\n",
    "    \n",
    "    gp.load_network()\n",
    "    gp.init_partitioner()\n",
    "    \n",
    "    m = gp.prediction_model()\n",
    "    expIO.writePartitionStats(outFile, \"prediction_model\", gp, m)\n",
    "        \n",
    "    m = gp.assign_cut_off()\n",
    "    expIO.writePartitionStats(outFile, \"cutoff\", gp, m)\n",
    "\n",
    "    m = gp.batch_arrival()\n",
    "    expIO.writePartitionStats(outFile, \"batch_arrivals\", gp, m)\n",
    "    \n",
    "    outFile.write(\"Experiment duration = \" + str(time.time() - start_time))\n",
    "    outFile.save()\n",
    "    \n",
    "    del m\n",
    "    del gp\n",
    "    del outFile\n",
    "    \n",
    "def runPartitioningNoStorage(config, numPartitions, networkID):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    gp = GraphPartitioning(config)    \n",
    "    gp.load_network()\n",
    "    gp.init_partitioner()\n",
    "    \n",
    "    m = gp.prediction_model()\n",
    "    m = gp.assign_cut_off()\n",
    "    m = gp.batch_arrival()\n",
    "        \n",
    "    del m\n",
    "    del gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "import time \n",
    "\n",
    "def relabel(array, v1, v2):\n",
    "    newArr = []\n",
    "    for val in array:\n",
    "        if(val == v1):\n",
    "            newArr.append(v2)\n",
    "        elif (val == v2):\n",
    "            newArr.append(v1)\n",
    "        else:\n",
    "            newArr.append(val)\n",
    "    return newArr\n",
    "\n",
    "#test = [0,0,1,1,2,2]\n",
    "#print(relabel(test, 0, 0))\n",
    "\n",
    "testNMIRelabeling = True\n",
    "if testNMIRelabeling:\n",
    "    num_partitions = 4\n",
    "    config = expUtils.getConfig(parametrized_config, \"PATOH\", num_partitions, 100, 0.0, 1, False, False, False)\n",
    "    \n",
    "    gp = GraphPartitioning(config)    \n",
    "    gp.load_network()\n",
    "    gp.init_partitioner()\n",
    "\n",
    "    m = gp.prediction_model()\n",
    "\n",
    "    predictionModel = np.array(gp.assignments, copy=True)\n",
    "\n",
    "    m = gp.assign_cut_off()\n",
    "    m = gp.batch_arrival()\n",
    "    \n",
    "    batchModel = np.array(gp.assignments, copy=True)\n",
    "    \n",
    "    pm = []\n",
    "    batch = []\n",
    "    for i, partition in enumerate(batchModel):\n",
    "        if partition >= 0:\n",
    "            pm.append(predictionModel[i])\n",
    "            batch.append(partition)\n",
    "            \n",
    "    prediction = np.array(pm)\n",
    "    batch = np.array(batch)\n",
    "    \n",
    "    startt = time.time()\n",
    "    \n",
    "    print(\"Prediction Model\", prediction)\n",
    "    print(\"Batch Arrivals\", batch)\n",
    "    \n",
    "    print(\"NMI:\", normalized_mutual_info_score(prediction, batch))\n",
    "    print(\"fscore:\",f1_score(prediction, batch, average='weighted'))\n",
    "\n",
    "    fscores = []\n",
    "    fscores_correct = []\n",
    "\n",
    "    for i in range(0, num_partitions):\n",
    "        fi = []\n",
    "        fi_correct = []\n",
    "        for j in range(0, num_partitions):\n",
    "            batch_ij = relabel(batch, i, j)\n",
    "            fi.append(1.0 - f1_score(prediction, batch_ij, average='weighted'))\n",
    "            fi_correct.append(f1_score(prediction, batch_ij, average='weighted'))\n",
    "        fscores.append(fi)\n",
    "        fscores_correct.append(fi_correct)\n",
    "        \n",
    "    \n",
    "    print('fscore Matrix:', fscores_correct)\n",
    "\n",
    "    cost = np.array(fscores) \n",
    "    row_ind, col_ind = linear_sum_assignment(cost)\n",
    "    print('Hungarian rows', row_ind)\n",
    "    print('Hungarian cols', col_ind)\n",
    "    \n",
    "    relabelled_batch = batch\n",
    "    \n",
    "    relabel_done = {}\n",
    "    for i, row in enumerate(row_ind):\n",
    "        # check if done already        \n",
    "        col = col_ind[i]\n",
    "        if col == row:\n",
    "            continue\n",
    "\n",
    "        if(col < row):\n",
    "            if col in relabel_done:\n",
    "                #if row in relabel_done[col]:\n",
    "                continue\n",
    "            relabel_done[col] = row\n",
    "        else:\n",
    "            if row in relabel_done:\n",
    "                continue\n",
    "            relabel_done[row] = col\n",
    "        \n",
    "            \n",
    "        print(row, '->', col)\n",
    "        relabelled_batch = relabel(relabelled_batch, row, col_ind[i])\n",
    "        print(\"nmi:\", normalized_mutual_info_score(prediction, relabelled_batch))\n",
    "        print(\"relabelled batch:\", np.array(relabelled_batch))\n",
    "        print(\"fscore relabelled:\",f1_score(prediction, relabelled_batch, average='weighted'))\n",
    "    print(\"elapsed = \", time.time() - startt)\n",
    "\n",
    "        \n",
    "    print(\"NMI relabelled:\", normalized_mutual_info_score(prediction, relabelled_batch))\n",
    "    print(\"fscore relabelled:\",f1_score(prediction, relabelled_batch, average='weighted'))\n",
    "\n",
    "    del gp\n",
    "    del m\n",
    "    del predictionModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# All possible ways to run the experiments\n",
    "all_algorithms = [\"FENNEL\", \"SCOTCH\", \"PATOH\"]\n",
    "\n",
    "all_correctedness = expUtils.fillRange(0, 11, expUtils.times10)\n",
    "all_partitions = expUtils.fillRange(4, 13)\n",
    "all_networks = expUtils.fillRange(1, 1001)\n",
    "all_predictionModelCutoff = expUtils.fillRange(0, 21, expUtils.cutoffValueFunc)\n",
    "\n",
    "storeResults = True\n",
    "\n",
    "all_slidingWindow = [True, False]\n",
    "all_virtualNodes = [True, False]\n",
    "all_GAMModel = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# EXPERIMENT 1: how does changing the cutoff on prediction model, alter how well partitions can be made\n",
    "\n",
    "# todo avoid double experiments, cutoff, size of batch\n",
    "# todo check edgescut = subset of population\n",
    "\n",
    "# pick a subset of settings, if needed\n",
    "algorithms = all_algorithms\n",
    "#partitions = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "partitions = [4]\n",
    "correctedness = [100]\n",
    "predictionModelCutoff = [0.0]\n",
    "#predictionModelCutoff = expUtils.fillRange(0, 21, expUtils.cutoffValueFunc)\n",
    "networks = [1]\n",
    "slidingWindows = [False]\n",
    "virtualNodes = [True, False]\n",
    "#GAMModels = [True, False]\n",
    "\n",
    "outputDir = expUtils.experimentDir(parametrized_config)\n",
    "if not os.path.exists(outputDir):\n",
    "    os.makedirs(outputDir)\n",
    "\n",
    "experimentCount = 0\n",
    "experimentTimes = []\n",
    "\n",
    "dontRunExperiments = False # safety net to avoid overwriting experiments\n",
    "for algorithm in algorithms:\n",
    "    # run the experiment separately for each algorithm\n",
    "    if dontRunExperiments == True:\n",
    "        break\n",
    "        \n",
    "    for partition in partitions:\n",
    "        # run the experiment with differnt number of partitions\n",
    "        for correct in correctedness:\n",
    "            # run the experiment for different correctedness predictions\n",
    "            for cutoff in predictionModelCutoff:\n",
    "                # this is the real experiment - different cutoff values\n",
    "                for network in networks:\n",
    "                    # sliding window\n",
    "                    for sliding in slidingWindows:\n",
    "                        # virtual nodes\n",
    "                        for virtualNode in virtualNodes:\n",
    "                            # GAM\n",
    "                            for GAMModel in GAMModels:\n",
    "                                start_time = time.time()\n",
    "\n",
    "                                # setup the experiment\n",
    "                                config = expUtils.getConfig(parametrized_config, algorithm, partition, correct, cutoff, network, sliding, virtualNode, GAMModel)\n",
    "\n",
    "                                outFN = expUtils.getOutFileName(algorithm, partition, correct, cutoff, network, sliding, virtualNode, GAMModel)\n",
    "                                outfPath = os.path.join(outputDir, outFN)\n",
    "                                #with open(outfPath, 'w+') as experimentFile:\n",
    "                                    # run experiment and store results\n",
    "                                runPartitioning(config, outfPath, partition, network)\n",
    "                                \n",
    "                                elapsed_time = time.time() - start_time\n",
    "                                print(\"Experiment\", experimentCount, elapsed_time, outFN)\n",
    "                                experimentTimes.append(elapsed_time)\n",
    "                                experimentCount += 1\n",
    "\n",
    "expUtils.purgeEmptyDir(outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/voreno/Development/CSAP/graph-partitioning/output/17_04_27/14_49_14/FENNEL_p4_c100_cutoff0_sw0_vn0_gam0_1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a1b53c520c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                                 \u001b[0moutFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                                 \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictionModelMetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/voreno/Development/CSAP/graph-partitioning/experiments/io.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpredictionModelData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mbatchModelData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mmetricsFoundCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mmetricsEndCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/voreno/Development/CSAP/graph-partitioning/output/17_04_27/14_49_14/FENNEL_p4_c100_cutoff0_sw0_vn0_gam0_1.txt'"
     ]
    }
   ],
   "source": [
    "# experiment for prediction model cutoff\n",
    "\n",
    "algorithms = all_algorithms\n",
    "correctedness = [100]\n",
    "networks = [1]\n",
    "slidingWindows = [False]\n",
    "virtualNodes = [False]\n",
    "GAMModels = [False]\n",
    "\n",
    "\n",
    "'''\n",
    "resultsDir = os.path.join(parametrized_config['OUTPUT_DIRECTORY'], \"17_04_27\", \"10_56_16\")\n",
    "partitions = [4]\n",
    "predictionModelCutoff = expUtils.fillRange(0, 21, expUtils.cutoffValueFunc)\n",
    "xlabel = \"Prediction Model Cut-off\"\n",
    "x = []\n",
    "for p in predictionModelCutoff:\n",
    "    x.append(p * 10)\n",
    "\n",
    "# experiment for partition size - no prediction model\n",
    "resultsDir = os.path.join(parametrized_config['OUTPUT_DIRECTORY'], \"17_04_27\", \"11_04_09\")\n",
    "partitions = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "predictionModelCutoff = [0.0]\n",
    "xlabel = \"Number of Partitions\"\n",
    "x=partitions\n",
    "'''\n",
    "\n",
    "\n",
    "# experiment for virtual nodes\n",
    "resultsDir = os.path.join(parametrized_config['OUTPUT_DIRECTORY'], \"17_04_27\", \"14_49_14\")\n",
    "partitions = [4]\n",
    "predictionModelCutoff = [0.0]\n",
    "xlabel = \"Virtual Nodes on/off\"\n",
    "virtualNodes = [False, True]\n",
    "x=[0, 1]\n",
    "\n",
    "\n",
    "'''\n",
    "# experiment for virtual nodes\n",
    "resultsDir = os.path.join(parametrized_config['OUTPUT_DIRECTORY'], \"17_04_27\", \"11_28_07\")\n",
    "partitions = [4]\n",
    "predictionModelCutoff = [0.5]\n",
    "xlabel = \"Virtual Nodes on/off\"\n",
    "virtualNodes = [False, True]\n",
    "x=[0, 1]\n",
    "\n",
    "# experiment for virtual nodes\n",
    "resultsDir = os.path.join(parametrized_config['OUTPUT_DIRECTORY'], \"17_04_27\", \"11_31_20\")\n",
    "partitions = [4]\n",
    "predictionModelCutoff = [0.5]\n",
    "xlabel = \"GAM Model on/off\"\n",
    "GAMModels = [False, True]\n",
    "x=[0, 1]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "class ExperimentData:\n",
    "    def __init__(self, name, path, algorithm, partitions, correctedness, cutoff, networkID, slidingWindow, virtualNodes, GAMModel):\n",
    "        self.name = name\n",
    "        self.path = path\n",
    "        \n",
    "        self.algorithm = algorithm\n",
    "        self.partitions = partitions\n",
    "        self.correctedness = correctedness\n",
    "        self.cutoff = cutoff\n",
    "        self.networkID = networkID\n",
    "        self.slidingWindow = slidingWindow\n",
    "        self.virtualNodes = virtualNodes\n",
    "        self.gamModel = GAMModel\n",
    "        \n",
    "        self.predictionModelMetrics = []\n",
    "        self.batchMetrics = []\n",
    "\n",
    "\n",
    "def aggregatePredictionData(experiments, metricID):\n",
    "    data = []\n",
    "    for experiment in experiments:\n",
    "        if(metricID >= 0 and metricID < len(experiment.predictionModelMetrics)):\n",
    "            data.append(experiment.predictionModelMetrics[metricID])\n",
    "    return data\n",
    "\n",
    "def aggregateBatchData(experiments, metricID):\n",
    "    data = []\n",
    "    for experiment in experiments:\n",
    "        # get the last row\n",
    "        if(len(experiment.batchMetrics)):\n",
    "            rowData = experiment.batchMetrics[len(experiment.batchMetrics) - 1]\n",
    "            if(metricID >= 0 and metricID < len(rowData)):\n",
    "                data.append(rowData[metricID])\n",
    "    return data\n",
    "\n",
    "def plotData(x, dataset, xlabel, ylabel):\n",
    "    plt.plot(x , dataset[0], 'r--', label=\"FENNEL\")\n",
    "    plt.plot(x , dataset[1], 'b--', label=\"SCOTCH\")\n",
    "    plt.plot(x , dataset[2], 'g--', label=\"PATOH\")\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "edgesCut = []\n",
    "tcv = []\n",
    "modularity = []\n",
    "lonliness = []\n",
    "nmi = []\n",
    "# load the expected experiments\n",
    "for algorithm in algorithms:\n",
    "    # run the experiment separately for each algorithm        \n",
    "    experiments = []\n",
    "    for partition in partitions:\n",
    "        # run the experiment with differnt number of partitions\n",
    "        for correct in correctedness:\n",
    "            # run the experiment for different correctedness predictions\n",
    "            for cutoff in predictionModelCutoff:\n",
    "                # this is the real experiment - different cutoff values\n",
    "                for network in networks:\n",
    "                    # sliding window\n",
    "                    for sliding in slidingWindows:\n",
    "                        # virtual nodes\n",
    "                        for virtualNode in virtualNodes:\n",
    "                            # GAM\n",
    "                            for GAMModel in GAMModels:\n",
    "                                outFN = expUtils.getOutFileName(algorithm, partition, correct, cutoff, network, sliding, virtualNode, GAMModel)\n",
    "                                outfPath = os.path.join(resultsDir, outFN)\n",
    "\n",
    "                                experiment = ExperimentData(outFN, outfPath, algorithm, partition, correct, cutoff, network, sliding, virtualNode, GAMModel)\n",
    "                                \n",
    "                                outFile = expIO.OutFile(outfPath)\n",
    "                                data = outFile.load()\n",
    "                                \n",
    "                                experiment.predictionModelMetrics = data[0]\n",
    "                                experiment.batchMetrics = data[1]\n",
    "                                \n",
    "                                experiments.append(experiment)\n",
    "\n",
    "    edgesCut.append(aggregateBatchData(experiments, 2))\n",
    "    tcv.append(aggregateBatchData(experiments, 3))\n",
    "    modularity.append(aggregateBatchData(experiments, 4))\n",
    "    lonliness.append(aggregateBatchData(experiments, 5))\n",
    "    nmi.append(aggregateBatchData(experiments, 7))\n",
    "\n",
    "\n",
    "\n",
    "plotData(x, edgesCut, xlabel, \"Edges Cut\")\n",
    "plotData(x, tcv, xlabel, \"Total Comm. Volumne\")\n",
    "plotData(x, modularity, xlabel, \"Modularity\")\n",
    "plotData(x, lonliness, xlabel, \"Lonliness\")\n",
    "plotData(x, nmi, xlabel, \"NMI\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
