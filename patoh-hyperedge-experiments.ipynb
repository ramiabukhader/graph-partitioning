{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import platform\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from graph_partitioning import GraphPartitioning, utils\n",
    "\n",
    "run_metrics = True\n",
    "\n",
    "cols = [\"WASTE\", \"CUT RATIO\", \"EDGES CUT\", \"TOTAL COMM VOLUME\", \"MODULARITY\", \"LONELINESS\", \"NETWORK PERMANENCE\", \"NORM. MUTUAL INFO\", \"EDGE CUT WEIGHT\", \"FSCORE\", \"FSCORE RELABEL IMPROVEMENT\"]\n",
    "pwd = %pwd\n",
    "\n",
    "config = {\n",
    "    \"DATA_FILENAME\": os.path.join(pwd, \"data\", \"predition_model_tests\", \"network\", \"rand_edge_weights\", \"network_1.txt\"),\n",
    "    #\"DATA_FILENAME\": os.path.join(pwd, \"data\", \"predition_model_tests\", \"network\", \"network_1.txt\"),\n",
    "    \"OUTPUT_DIRECTORY\": os.path.join(pwd, \"output\"),\n",
    "\n",
    "    # Set which algorithm is run for the PREDICTION MODEL.\n",
    "    # Either: 'FENNEL' or 'SCOTCH'\n",
    "    \"PREDICTION_MODEL_ALGORITHM\": \"PATOH\",\n",
    "\n",
    "    # Alternativly, read input file for prediction model.\n",
    "    # Set to empty to generate prediction model using algorithm value above.\n",
    "    \"PREDICTION_MODEL\": \"\",\n",
    "\n",
    "    \"PARTITIONER_ALGORITHM\": \"PATOH\",\n",
    "\n",
    "    # File containing simulated arrivals. This is used in simulating nodes\n",
    "    # arriving at the shelter. Nodes represented by line number; value of\n",
    "    # 1 represents a node as arrived; value of 0 represents the node as not\n",
    "    # arrived or needing a shelter.\n",
    "    \"SIMULATED_ARRIVAL_FILE\": os.path.join(pwd,\n",
    "                                           \"data\",\n",
    "                                           \"predition_model_tests\",\n",
    "                                           \"dataset_1_shift_rotate\",\n",
    "                                           \"simulated_arrival_list\",\n",
    "                                           \"percentage_of_prediction_correct_100\",\n",
    "                                           \"arrival_100_1.txt\"\n",
    "                                          ),\n",
    "    \n",
    "    # File containing the prediction of a node arriving. This is different to the\n",
    "    # simulated arrivals, the values in this file are known before the disaster.\n",
    "    \"PREDICTION_LIST_FILE\": os.path.join(pwd,\n",
    "                                         \"data\",\n",
    "                                         \"predition_model_tests\",\n",
    "                                         \"dataset_1_shift_rotate\",\n",
    "                                         \"prediction_list\",\n",
    "                                         \"prediction_1.txt\"\n",
    "                                        ),\n",
    "\n",
    "    # File containing the geographic location of each node, in \"x,y\" format.\n",
    "    \"POPULATION_LOCATION_FILE\": os.path.join(pwd,\n",
    "                                             \"data\",\n",
    "                                             \"predition_model_tests\",\n",
    "                                             \"coordinates\",\n",
    "                                             \"coordinates_1.txt\"\n",
    "                                            ),\n",
    "\n",
    "    # Number of shelters\n",
    "    \"num_partitions\": 4,\n",
    "\n",
    "    # The number of iterations when making prediction model\n",
    "    \"num_iterations\": 1,\n",
    "\n",
    "    # Percentage of prediction model to use before discarding\n",
    "    # When set to 0, prediction model is discarded, useful for one-shot\n",
    "    \"prediction_model_cut_off\": 1.0,\n",
    "\n",
    "    # Alpha value used in one-shot (when restream_batches set to 1)\n",
    "    \"one_shot_alpha\": 0.5,\n",
    "\n",
    "    # Number of arrivals to batch before recalculating alpha and restreaming.\n",
    "    # When set to 1, one-shot is used with alpha value from above\n",
    "    \"restream_batches\": 1000,\n",
    "\n",
    "    # When the batch size is reached: if set to True, each node is assigned\n",
    "    # individually as first in first out. If set to False, the entire batch\n",
    "    # is processed and empty before working on the next batch.\n",
    "    \"sliding_window\": False,\n",
    "\n",
    "    # Create virtual nodes based on prediction model\n",
    "    \"use_virtual_nodes\": False,\n",
    "\n",
    "    # Virtual nodes: edge weight\n",
    "    \"virtual_edge_weight\": 1.0,\n",
    "\n",
    "    # Loneliness score parameter. Used when scoring a partition by how many\n",
    "    # lonely nodes exist.\n",
    "    \"loneliness_score_param\": 1.2,\n",
    "\n",
    "    ####\n",
    "    # GRAPH MODIFICATION FUNCTIONS\n",
    "\n",
    "    # Also enables the edge calculation function.\n",
    "    \"graph_modification_functions\": True,\n",
    "\n",
    "    # If set, the node weight is set to 100 if the node arrives at the shelter,\n",
    "    # otherwise the node is removed from the graph.\n",
    "    \"alter_arrived_node_weight_to_100\": False,\n",
    "\n",
    "    # Uses generalized additive models from R to generate prediction of nodes not\n",
    "    # arrived. This sets the node weight on unarrived nodes the the prediction\n",
    "    # given by a GAM.\n",
    "    # Needs POPULATION_LOCATION_FILE to be set.\n",
    "    \"alter_node_weight_to_gam_prediction\": False,\n",
    "\n",
    "    # Enables edge expansion when graph_modification_functions is set to true\n",
    "    \"edge_expansion_enabled\": True,\n",
    "\n",
    "    # The value of 'k' used in the GAM will be the number of nodes arrived until\n",
    "    # it reaches this max value.\n",
    "    \"gam_k_value\": 100,\n",
    "\n",
    "    # Alter the edge weight for nodes that haven't arrived. This is a way to\n",
    "    # de-emphasise the prediction model for the unknown nodes.\n",
    "    \"prediction_model_emphasis\": 1.0,\n",
    "    \n",
    "    # This applies the prediction_list_file node weights onto the nodes in the graph\n",
    "    # when the prediction model is being computed and then removes the weights\n",
    "    # for the cutoff and batch arrival modes\n",
    "    \"apply_prediction_model_weights\": True,\n",
    "\n",
    "    \"SCOTCH_LIB_PATH\": os.path.join(pwd, \"libs/scotch/macOS/libscotch.dylib\")\n",
    "    if 'Darwin' in platform.system()\n",
    "    else \"/usr/local/lib/libscotch.so\",\n",
    "    \n",
    "    # Path to the PaToH shared library\n",
    "    \"PATOH_LIB_PATH\": os.path.join(pwd, \"libs/patoh/lib/macOS/libpatoh.dylib\")\n",
    "    if 'Darwin' in platform.system()\n",
    "    else os.path.join(pwd, \"libs/patoh/lib/linux/libpatoh.so\"),\n",
    "    \n",
    "    \"PATOH_ITERATIONS\": 5,\n",
    "        \n",
    "    # Expansion modes: 'no_expansion', 'avg_node_weight', 'total_node_weight', 'smallest_node_weight'\n",
    "    # 'largest_node_weight', 'product_node_weight'\n",
    "    # add '_squared' or '_sqrt' at the end of any of the above for ^2 or sqrt(weight)\n",
    "    # add '_complete' for applying the complete algorithm\n",
    "    #    for hyperedge with weights: A, B, C, D\n",
    "    #      new weights are computed\n",
    "    #       (A*B)^2 = H0\n",
    "    #       (A*C)^2 = H1, ... Hn-1\n",
    "    #      then normal hyperedge expansion computed on H0...Hn-1\n",
    "    # i.e. 'avg_node_weight_squared\n",
    "    \"PATOH_HYPEREDGE_EXPANSION_MODE\": 'total_node_weight_sqrt_complete',\n",
    "\n",
    "    # Alters how much information to print. Keep it at 1 for this notebook.\n",
    "    # 0 - will print nothing, useful for batch operations.\n",
    "    # 1 - prints basic information on assignments and operations.\n",
    "    # 2 - prints more information as it batches arrivals.\n",
    "    \"verbose\": 1\n",
    "}\n",
    "\n",
    "#gp = GraphPartitioning(config)\n",
    "\n",
    "# Optional: shuffle the order of nodes arriving\n",
    "# Arrival order should not be shuffled if using GAM to alter node weights\n",
    "#random.shuffle(gp.arrival_order)\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode no_expansion Iteration 0\n",
      "DescribeResult(nobs=1042, minmax=(1, 1), mean=1.0, variance=0.0, skewness=0.0, kurtosis=-3.0)\n",
      "ModeResult(mode=array([1]), count=array([1042]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 1), mean=1.0, variance=0.0, skewness=0.0, kurtosis=-3.0)\n",
      "ModeResult(mode=array([1]), count=array([1042]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 1), mean=1.0, variance=0.0, skewness=0.0, kurtosis=-3.0)\n",
      "ModeResult(mode=array([1]), count=array([1042]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 1), mean=1.0, variance=0.0, skewness=0.0, kurtosis=-3.0)\n",
      "ModeResult(mode=array([1]), count=array([1042]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 1), mean=1.0, variance=0.0, skewness=0.0, kurtosis=-3.0)\n",
      "ModeResult(mode=array([1]), count=array([1042]))\n",
      "EC_PM,no_expansion,137.0,0.0,137\n",
      "TCV_PM,no_expansion,156.0,0.0,156\n",
      "EC_BM,no_expansion,43.0,0.0,43\n",
      "TCV_BM,no_expansion,55.0,0.0,55\n",
      "Mode avg_node_weight Iteration 0\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=29.602687140115162, variance=1230.6777257214289, skewness=0.6674281543775488, kurtosis=-1.210544912506003)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=29.602687140115162, variance=1230.6777257214289, skewness=0.6674281543775488, kurtosis=-1.210544912506003)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=29.602687140115162, variance=1230.6777257214289, skewness=0.6674281543775488, kurtosis=-1.210544912506003)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=29.602687140115162, variance=1230.6777257214289, skewness=0.6674281543775488, kurtosis=-1.210544912506003)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=29.602687140115162, variance=1230.6777257214289, skewness=0.6674281543775488, kurtosis=-1.210544912506003)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "EC_PM,avg_node_weight,203.0,0.0,203\n",
      "TCV_PM,avg_node_weight,208.0,0.0,208\n",
      "EC_BM,avg_node_weight,26.0,0.0,26\n",
      "TCV_BM,avg_node_weight,34.0,0.0,34\n",
      "Mode total_node_weight Iteration 0\n",
      "DescribeResult(nobs=1042, minmax=(1, 630), mean=100.80614203454894, variance=17118.25825234484, skewness=1.14126568745794, kurtosis=0.27020804318871106)\n",
      "ModeResult(mode=array([3]), count=array([195]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 630), mean=100.80614203454894, variance=17118.25825234484, skewness=1.14126568745794, kurtosis=0.27020804318871106)\n",
      "ModeResult(mode=array([3]), count=array([195]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 630), mean=100.80614203454894, variance=17118.25825234484, skewness=1.14126568745794, kurtosis=0.27020804318871106)\n",
      "ModeResult(mode=array([3]), count=array([195]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 630), mean=100.80614203454894, variance=17118.25825234484, skewness=1.14126568745794, kurtosis=0.27020804318871106)\n",
      "ModeResult(mode=array([3]), count=array([195]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 630), mean=100.80614203454894, variance=17118.25825234484, skewness=1.14126568745794, kurtosis=0.27020804318871106)\n",
      "ModeResult(mode=array([3]), count=array([195]))\n",
      "EC_PM,total_node_weight,173.0,0.0,173\n",
      "TCV_PM,total_node_weight,204.0,0.0,204\n",
      "EC_BM,total_node_weight,27.0,0.0,27\n",
      "TCV_BM,total_node_weight,40.0,0.0,40\n",
      "Mode smallest_node_weight Iteration 0\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=25.196737044145873, variance=1200.600066192075, skewness=0.9360350400104708, kurtosis=-0.8227983000012005)\n",
      "ModeResult(mode=array([1]), count=array([665]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=25.196737044145873, variance=1200.600066192075, skewness=0.9360350400104708, kurtosis=-0.8227983000012005)\n",
      "ModeResult(mode=array([1]), count=array([665]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=25.196737044145873, variance=1200.600066192075, skewness=0.9360350400104708, kurtosis=-0.8227983000012005)\n",
      "ModeResult(mode=array([1]), count=array([665]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=25.196737044145873, variance=1200.600066192075, skewness=0.9360350400104708, kurtosis=-0.8227983000012005)\n",
      "ModeResult(mode=array([1]), count=array([665]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=25.196737044145873, variance=1200.600066192075, skewness=0.9360350400104708, kurtosis=-0.8227983000012005)\n",
      "ModeResult(mode=array([1]), count=array([665]))\n",
      "EC_PM,smallest_node_weight,130.0,0.0,130\n",
      "TCV_PM,smallest_node_weight,164.0,0.0,164\n",
      "EC_BM,smallest_node_weight,51.0,0.0,51\n",
      "TCV_BM,smallest_node_weight,58.0,0.0,58\n",
      "Mode largest_node_weight Iteration 0\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=34.059500959692897, variance=1505.6660047459161, skewness=0.4777067303621478, kurtosis=-1.5681146081177233)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=34.059500959692897, variance=1505.6660047459161, skewness=0.4777067303621478, kurtosis=-1.5681146081177233)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=34.059500959692897, variance=1505.6660047459161, skewness=0.4777067303621478, kurtosis=-1.5681146081177233)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=34.059500959692897, variance=1505.6660047459161, skewness=0.4777067303621478, kurtosis=-1.5681146081177233)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 90), mean=34.059500959692897, variance=1505.6660047459161, skewness=0.4777067303621478, kurtosis=-1.5681146081177233)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "EC_PM,largest_node_weight,188.0,0.0,188\n",
      "TCV_PM,largest_node_weight,220.0,0.0,220\n",
      "EC_BM,largest_node_weight,46.0,0.0,46\n",
      "TCV_BM,largest_node_weight,58.0,0.0,58\n",
      "Mode product_node_weight_sqrt Iteration 0\n",
      "DescribeResult(nobs=1042, minmax=(1, 19440000), mean=68766.69577735124, variance=904853095147.63562, skewness=17.324153758686514, kurtosis=311.54445876786417)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 19440000), mean=68766.69577735124, variance=904853095147.63562, skewness=17.324153758686514, kurtosis=311.54445876786417)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 19440000), mean=68766.69577735124, variance=904853095147.63562, skewness=17.324153758686514, kurtosis=311.54445876786417)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 19440000), mean=68766.69577735124, variance=904853095147.63562, skewness=17.324153758686514, kurtosis=311.54445876786417)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 19440000), mean=68766.69577735124, variance=904853095147.63562, skewness=17.324153758686514, kurtosis=311.54445876786417)\n",
      "ModeResult(mode=array([1]), count=array([570]))\n",
      "EC_PM,product_node_weight_sqrt,196.0,0.0,196\n",
      "TCV_PM,product_node_weight_sqrt,236.0,0.0,236\n",
      "EC_BM,product_node_weight_sqrt,25.0,0.0,25\n",
      "TCV_BM,product_node_weight_sqrt,38.0,0.0,38\n",
      "Mode avg_node_weight_complete Iteration 0\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=199.89923224568139, variance=89354.159864923917, skewness=1.195296180687326, kurtosis=-0.1548830767837286)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=199.89923224568139, variance=89354.159864923917, skewness=1.195296180687326, kurtosis=-0.1548830767837286)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=199.89923224568139, variance=89354.159864923917, skewness=1.195296180687326, kurtosis=-0.1548830767837286)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=199.89923224568139, variance=89354.159864923917, skewness=1.195296180687326, kurtosis=-0.1548830767837286)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=199.89923224568139, variance=89354.159864923917, skewness=1.195296180687326, kurtosis=-0.1548830767837286)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "EC_PM,avg_node_weight_complete,226.0,0.0,226\n",
      "TCV_PM,avg_node_weight_complete,239.0,0.0,239\n",
      "EC_BM,avg_node_weight_complete,40.0,0.0,40\n",
      "TCV_BM,avg_node_weight_complete,53.0,0.0,53\n",
      "Mode total_node_weight_sqrt_complete Iteration 0\n",
      "DescribeResult(nobs=1042, minmax=(1, 130), mean=18.302303262955853, variance=645.85376990602185, skewness=1.356975055801687, kurtosis=0.9665512955163265)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 130), mean=18.302303262955853, variance=645.85376990602185, skewness=1.356975055801687, kurtosis=0.9665512955163265)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 130), mean=18.302303262955853, variance=645.85376990602185, skewness=1.356975055801687, kurtosis=0.9665512955163265)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 130), mean=18.302303262955853, variance=645.85376990602185, skewness=1.356975055801687, kurtosis=0.9665512955163265)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 130), mean=18.302303262955853, variance=645.85376990602185, skewness=1.356975055801687, kurtosis=0.9665512955163265)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "EC_PM,total_node_weight_sqrt_complete,88.0,0.0,88\n",
      "TCV_PM,total_node_weight_sqrt_complete,123.0,0.0,123\n",
      "EC_BM,total_node_weight_sqrt_complete,32.0,0.0,32\n",
      "TCV_BM,total_node_weight_sqrt_complete,47.0,0.0,47\n",
      "Mode smallest_node_weight_complete Iteration 0\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=187.09692898272553, variance=87531.455533307148, skewness=1.309787407072723, kurtosis=0.12410396257733547)\n",
      "ModeResult(mode=array([1]), count=array([603]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=187.09692898272553, variance=87531.455533307148, skewness=1.309787407072723, kurtosis=0.12410396257733547)\n",
      "ModeResult(mode=array([1]), count=array([603]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=187.09692898272553, variance=87531.455533307148, skewness=1.309787407072723, kurtosis=0.12410396257733547)\n",
      "ModeResult(mode=array([1]), count=array([603]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=187.09692898272553, variance=87531.455533307148, skewness=1.309787407072723, kurtosis=0.12410396257733547)\n",
      "ModeResult(mode=array([1]), count=array([603]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=187.09692898272553, variance=87531.455533307148, skewness=1.309787407072723, kurtosis=0.12410396257733547)\n",
      "ModeResult(mode=array([1]), count=array([603]))\n",
      "EC_PM,smallest_node_weight_complete,220.0,0.0,220\n",
      "TCV_PM,smallest_node_weight_complete,228.0,0.0,228\n",
      "EC_BM,smallest_node_weight_complete,49.0,0.0,49\n",
      "TCV_BM,smallest_node_weight_complete,50.0,0.0,50\n",
      "Mode largest_node_weight_complete Iteration 0\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=221.5834932821497, variance=103224.76391554704, skewness=1.0450603710994961, kurtosis=-0.6186618923474803)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=221.5834932821497, variance=103224.76391554704, skewness=1.0450603710994961, kurtosis=-0.6186618923474803)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=221.5834932821497, variance=103224.76391554704, skewness=1.0450603710994961, kurtosis=-0.6186618923474803)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=221.5834932821497, variance=103224.76391554704, skewness=1.0450603710994961, kurtosis=-0.6186618923474803)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "DescribeResult(nobs=1042, minmax=(1, 810), mean=221.5834932821497, variance=103224.76391554704, skewness=1.0450603710994961, kurtosis=-0.6186618923474803)\n",
      "ModeResult(mode=array([1]), count=array([574]))\n",
      "EC_PM,largest_node_weight_complete,189.0,0.0,189\n",
      "TCV_PM,largest_node_weight_complete,207.0,0.0,207\n",
      "EC_BM,largest_node_weight_complete,34.0,0.0,34\n",
      "TCV_BM,largest_node_weight_complete,44.0,0.0,44\n"
     ]
    }
   ],
   "source": [
    "iterations = 1\n",
    "#modes = ['largest_node_weight_complete']\n",
    "modes = ['no_expansion', 'avg_node_weight', 'total_node_weight', 'smallest_node_weight','largest_node_weight', 'product_node_weight_sqrt', 'avg_node_weight_complete', 'total_node_weight_sqrt_complete', 'smallest_node_weight_complete','largest_node_weight_complete']\n",
    "\n",
    "for mode in modes:\n",
    "\n",
    "    metricsDataPrediction = []\n",
    "    metricsDataAssign = []\n",
    "\n",
    "    config['PATOH_HYPEREDGE_EXPANSION_MODE'] = mode\n",
    "\n",
    "    for i in range(0, iterations):\n",
    "        print('Mode', mode, 'Iteration', str(i))\n",
    "        gp = GraphPartitioning(config)\n",
    "        gp.verbose = 0\n",
    "        gp.load_network()\n",
    "        gp.init_partitioner()\n",
    "\n",
    "        m = gp.prediction_model()\n",
    "        metricsDataPrediction.append(m[0])\n",
    "\n",
    "        m = gp.assign_cut_off()\n",
    "        metricsDataAssign.append(m[0])\n",
    "\n",
    "    ec = ''\n",
    "    tcv = ''\n",
    "    ecB = ''\n",
    "    tcvB = ''\n",
    "\n",
    "    dataEC = []\n",
    "    dataTCV = [] \n",
    "\n",
    "    dataECB = []\n",
    "    dataTCVB = [] \n",
    "\n",
    "    import scipy\n",
    "\n",
    "    for i in range(0, iterations):\n",
    "        dataEC.append(metricsDataPrediction[i][2])\n",
    "        dataTCV.append(metricsDataPrediction[i][3])\n",
    "        dataECB.append(metricsDataAssign[i][2])\n",
    "        dataTCVB.append(metricsDataAssign[i][3])\n",
    "\n",
    "        if(len(ec)):\n",
    "            ec = ec + ','\n",
    "        ec = ec + str(metricsDataPrediction[i][2])\n",
    "        if(len(tcv)):\n",
    "            tcv = tcv + ','\n",
    "        tcv = tcv + str(metricsDataPrediction[i][3])\n",
    "\n",
    "        if(len(ecB)):\n",
    "            ecB = ecB + ','\n",
    "        ecB = ecB + str(metricsDataAssign[i][2])\n",
    "        if(len(tcvB)):\n",
    "            tcvB = tcvB + ','\n",
    "        tcvB = tcvB + str(metricsDataAssign[i][3])\n",
    "\n",
    "    ec = 'EC_PM,' + config['PATOH_HYPEREDGE_EXPANSION_MODE'] + ',' + str(scipy.mean(dataEC)) + ',' + str(scipy.std(dataEC)) + ',' + ec\n",
    "    tcv = 'TCV_PM,' + config['PATOH_HYPEREDGE_EXPANSION_MODE'] + ',' + str(scipy.mean(dataTCV)) + ',' + str(scipy.std(dataTCV)) + ',' + tcv\n",
    "    ecB = 'EC_BM,' + config['PATOH_HYPEREDGE_EXPANSION_MODE'] + ',' + str(scipy.mean(dataECB)) + ',' + str(scipy.std(dataECB)) + ',' + ecB\n",
    "    tcvB = 'TCV_BM,' + config['PATOH_HYPEREDGE_EXPANSION_MODE'] + ',' + str(scipy.mean(dataTCVB)) + ',' + str(scipy.std(dataTCVB)) + ',' + tcvB\n",
    "\n",
    "    print(ec)\n",
    "    print(tcv)\n",
    "    print(ecB)\n",
    "    print(tcvB)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gp.load_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gp.PATOH_HYPEREDGE_EXPANSION_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gp.init_partitioner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m = gp.prediction_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rows = list(range(1, len(m)+1))\n",
    "df = pd.DataFrame(m, index=rows, columns=cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m = gp.assign_cut_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rows = list(range(1, len(m)+1))\n",
    "df = pd.DataFrame(m, index=rows, columns=cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m = gp.batch_arrival()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rows = list(range(1, len(m)+1))\n",
    "df = pd.DataFrame(m, index=rows, columns=cols).astype(float)\n",
    "print(df)\n",
    "\n",
    "if len(df) > 1:\n",
    "    df.plot(y=['EDGES CUT', 'TOTAL COMM VOLUME'], xticks=rows, figsize=(5,4))\n",
    "\n",
    "    fig, axs = plt.subplots(1,6)\n",
    "    df.plot(y=['CUT RATIO'], title='Cut ratio', xticks=rows, figsize=(12,2), legend=False, ax=axs[0])\n",
    "    df.plot(y=['MODULARITY'], title='Modularity', xticks=rows, figsize=(12,2), legend=False, ax=axs[1])\n",
    "    df.plot(y=['LONELINESS'], title='Loneliness', xticks=rows, figsize=(12,2), legend=False, ax=axs[2])\n",
    "    df.plot(y=['NETWORK PERMANENCE'], title='Network permanence', xticks=rows, figsize=(12,2), legend=False, ax=axs[3])\n",
    "    df.plot(y=['NORM. MUTUAL INFO'], title='Norm. Mutual Info', xticks=rows, figsize=(12,2), legend=False, ax=axs[4])\n",
    "    df.plot(y=['FSCORE'], title='Fscore', xticks=rows, figsize=(12,2), legend=False, ax=axs[5])\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"\\n\\nNot enough data points to plot charts. There is only one row.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
